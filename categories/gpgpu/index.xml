<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GPGPU on Cory Code</title><link>https://huweim.github.io/categories/gpgpu/</link><description>Recent content in GPGPU on Cory Code</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© Athul</copyright><lastBuildDate>Sun, 14 Nov 2021 20:42:52 +0800</lastBuildDate><atom:link href="https://huweim.github.io/categories/gpgpu/index.xml" rel="self" type="application/rss+xml"/><item><title>GPGPU-Sim中的CTA &amp; warp scheduling</title><link>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim%E4%B8%AD%E7%9A%84cta-warp-scheduling/</link><pubDate>Sun, 14 Nov 2021 20:42:52 +0800</pubDate><guid>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim%E4%B8%AD%E7%9A%84cta-warp-scheduling/</guid><description>CTA Scheduling CTA/Thread Block/Work Group
调度发生在 shader_core_ctx::issue_block2core(...)，shader_core_config::max_cta(...) 计算 core 中能容纳的 max CTA。这个取决于各硬件资源的短板，在报告中能看到是被什么限制了。
printf(&amp;#34;GPGPU-Sim uArch: CTA/core = %u, limited by:&amp;#34;, result); if (result == result_thread) printf(&amp;#34; threads&amp;#34;); if (result == result_shmem) printf(&amp;#34; shmem&amp;#34;); if (result == result_regs) printf(&amp;#34; regs&amp;#34;); if (result == result_cta) printf(&amp;#34; cta_limit&amp;#34;); 在矩阵乘法代码中 create, verify are both limited by thread, multiple is limited by regs.
When each thread finishes, the SIMT core calls register_cta_thread_exit(...) to update the active thread block&amp;rsquo;s state.</description></item><item><title>Software Design of GPGPU-Sim</title><link>https://huweim.github.io/posts/%E6%96%87%E6%A1%A3_software-design-of-gpgpu-sim/</link><pubDate>Sun, 14 Nov 2021 20:35:44 +0800</pubDate><guid>https://huweim.github.io/posts/%E6%96%87%E6%A1%A3_software-design-of-gpgpu-sim/</guid><description>4 Software Design of GPGPU-Sim
所有标题都可以升一级，整个文档全是 manual 的第 4 章
1. File list and brief description cuda-sim - The functional simulator that executes PTX kernels generated by NVCC or OpenCL compiler gpgpu-sim - The performance simulator that simulates the timing behavior of a GPU (or other many core accelerator architectures) intersim - The interconnection network simulator adopted from Bill Dally&amp;rsquo;s BookSim 1.1 Overall/Utilities abstract_hardware_model.h abstract_hardware_model.cc Provide a set of classes that interface between functional and timing simulator.</description></item><item><title>GPU_benchmark说明（转）</title><link>https://huweim.github.io/posts/%E5%8D%9A%E5%AE%A2_gpu_benchmark%E8%AF%B4%E6%98%8E%E8%BD%AC/</link><pubDate>Sun, 14 Nov 2021 20:34:48 +0800</pubDate><guid>https://huweim.github.io/posts/%E5%8D%9A%E5%AE%A2_gpu_benchmark%E8%AF%B4%E6%98%8E%E8%BD%AC/</guid><description>Introduction 本文内容主要系摘录翻译自Ang Li的博士毕业论文。
1.Perfect Power Efficiency Revolution for Embedded Computing
http://hpc.pnl.gov/PERFECT/
Application Domains Kernels PERFECT Application 1 Discrete Wavelet Transform 2D Convolution Histogram Equalization Space Time Adaptive Processing System Solver Inner Product Outer Product Synthetic Aperture Radar Interpolation 1 Interpolation 2 Back Projection (Non-Fourier SAR) Wide Area Motion Imaging Debayer Image Registration Change Detection Required Kernels Sort FFT 1D FFT 2D 2.</description></item><item><title>GPGPU-Sim源码阅读</title><link>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Tue, 28 Sep 2021 15:51:46 +0800</pubDate><guid>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>Shader.cc shader_core_stats 类型含有非常多的数据统计，包括 cycle 数，m_num_decoded_insn, m_num_FPdecoded_insn, m_num_loadqueued_insn, m_num_INTdecoded_insn 等等
m_stats 也就是 shader_core_stats 类型的变量
num_shaer 就是 n_simt_clusters*n_simt_cores_per_cluster，也就是 SIMT Core 的数量
tw_get_oracle_CPL_counter 计算 warp 的 CPL counter 值
shader_core_ctx::decode 函数 检查 fetch buffer 中的指令是否有效，如有效则进入循环。获得当前指令的 pc，并取指令。
指令用变量 pI1 存储，调用函数 ibuffer_fill, 将 pI 装进对应 warp id 的 I-Buffer, 并将 valid bit 置为1
随后会取下一条指令，用变量 pI2 存储，注意下一条指令的 pc = pc + pI1 -&amp;gt; isize。也就是我们常说的 pc = pc + 1, 这里的1实际上是一条指令的长度
每个 warp 有两个 ibuffer slot, 也就是 ibuffer_fill 中的0和1</description></item><item><title>文档_GPGPU-sim - Performance Simulation Engine</title><link>https://huweim.github.io/posts/%E6%96%87%E6%A1%A3_gpgpu-sim-performance-simulation-engine/</link><pubDate>Tue, 28 Sep 2021 14:59:35 +0800</pubDate><guid>https://huweim.github.io/posts/%E6%96%87%E6%A1%A3_gpgpu-sim-performance-simulation-engine/</guid><description>GPGPU-sim - Performance Simulation Engine
1 Performance Model Software Objects ldst_unit *m_ldst_unit; 前面的 m 可能表示这个类型的变量
1.2 SIMT Core Class SIMT Core 中的微架构在 shader.h/cc 的类 shader_core_ctx 中实现
shd_warp_t objects 的集合用于建模每个 warp 在 core 中的状态 simt_stack object, 处理每个 warp 的分支 set of scheduler_unit obj, 选择 set 中 warp 的一条 or 多条指令发射执行 Scoreboard obj 处理 data hazard opndcoll_rfu_t obj, model operand collector set of simd_function_unit obj 实现 ALU pipeline ldst_unit 实现 memory pipeline shader_memroy_interface 将 SIMT Core 连接到相应的 SIMT Core Cluster 每个 core cycle, 调用 shader_core_ctx::cycle() 来模拟 SIMT Core 的一个 cycle。cycle function 以按从下往上的顺序 (也就是从 writeback() 到 fetch()) 调用下列函数</description></item><item><title>GPGPU-Sim 运行机制</title><link>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim-%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/</link><pubDate>Tue, 28 Sep 2021 13:39:14 +0800</pubDate><guid>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim-%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/</guid><description>0. 前言 在 GPGPU-Sim 跑一些比较大的 benchmark, 或者想要同时跑很多组 benchmark 的时候，在自己的电脑上跑，或者在虚拟机上运行的话速度肯定达不到要求，会成为工作中瓶颈。因此了解一下如何在服务器上跑 simulation, 以及如何提高运行 benchmark 的速度。
1. GPGPU-Sim 运行机制 首先要理解 application 是如何运行在 real machine 以及 GPGPU-Sim 上的，他们的区别在哪里？这里以 CUDA 代码为例。
GPGPU-Sim_vs_Real_Machine
1.1 Real Machine CUDA application 分为 host code and device code, 使用 nvcc 编译 .cu 代码时, 会将 host code 和 device code 分开。device code 被编译为 .ptx 文件，再通过 ptxas 编译为 cubin.bin 文件。host code, libcuda.a, cubin.bin 文件由 C/C++编译器编译了解生成可执行文件。
如何运行 CUDA application? 调用 libcuda 内的接口以在 GPU 上运行 device code.</description></item><item><title>搭建GPGPU-Sim实验环境</title><link>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_%E6%90%AD%E5%BB%BAgpgpu-sim%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/</link><pubDate>Mon, 27 Sep 2021 22:54:06 +0800</pubDate><guid>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_%E6%90%AD%E5%BB%BAgpgpu-sim%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/</guid><description>0. 前言 第一个思路是
服务器OS-&amp;gt;Docker Container-&amp;gt;Ubuntu中运行GPGPU-Sim。 Docker Container update Docker Image-&amp;gt;Docker Image-&amp;gt;XXX.tar-&amp;gt;复制到你的电脑Windows-&amp;gt;复制到你的虚拟机Ubuntu-&amp;gt;XXX.tar-&amp;gt;Docker Image-&amp;gt;Docker Container-&amp;gt;Ubuntu中运行GPGPU-Sim-&amp;gt;修改GPGPU-Sim 然后同样使用上述过程移植到服务器，运行 这样是有问题的。首先这个过程没有意义，如果这样在你自己的虚拟机里面运行Docker, 那么仍然是命令行界面，和在服务器上运行的区别在哪？
这样实现了Docker的其中一个作用
我在服务器上能跑，在我自己的虚拟机上也能跑。实现了在不同的环境下运行，而且无需安装多余的依赖。因为本质上我用的是 Docker 中的 Ubuntu 14 但我没有实现自己的目的 我的目的是什么？
在自己的Ubuntu上使用VScode修改模拟器，简单地编译测试性能。修改后需要跑大量benchmark, 这个时候我不能用自己的电脑跑了，我需要移植了。
把跑benchmark需要用到的东西放在服务器上，用服务器的计算资源运行。需要用到的东西是什么？
benchmark: 一般是一些 .cu/.cl 代码编译后生成的可执行文件
编译成功gpgpusim以后，实际上主要是生成了一个libcudart.so。
那么就需要这个 libcudart.so
所以理论上来说如果我使用一台固定的服务器，好像不需要一直更新Docker?无需安装 gcc4.5.1, cuda4.2。每次把这几个文件拷贝过去即可。
0.1 测试 在 gpgpu-sim_distribution 目录下只放置 lib 文件夹 也是可以 Run 的，说明程序运行时只会 call libcudart.so 这个文件</description></item><item><title>SIMT_Core</title><link>https://huweim.github.io/posts/%E6%96%87%E6%A1%A3_simt_core/</link><pubDate>Sat, 04 Sep 2021 19:04:57 +0800</pubDate><guid>https://huweim.github.io/posts/%E6%96%87%E6%A1%A3_simt_core/</guid><description>0. 前言 搞懂 SIMT Core 对于理解 GPGPU 的指令 fetch、指令发射、内存访问、数据传输等步骤非常重要，按照 GPGPU-Sim 的官方文档进行一个简单的梳理
SIMT Core 的微架构模型中有几个比较重要的硬件单元，接下来会一一介绍他们的作用，
000 放一个硬件概念对应表 1. Front End Instruction cache access Instruction buffer logic Scoreboard Scheduling logic SIMT stack 1.1 Fetch and Decode 这里介绍整个指令 Fetch and Decode 阶段，涉及到的硬件单元主要是 Fetch, I-Cache, Decode, I-Buffer, ScoreBoard
I. Fetch Fetch 单元是一个调度器，作用
根据 PC 的值，从 I-Cache 中取指令，即发送内存请求。 对于一个 warp，如果在 I-Buffer 中没有任何 valid 指令 (valid bit 作用在 III. I-Buffer 中有介绍)，那么这个 warp 就可以进行 instruction fetch。</description></item><item><title>GPGPU_Architecture</title><link>https://huweim.github.io/posts/gpgpu_architecture/</link><pubDate>Sat, 24 Jul 2021 16:35:27 +0800</pubDate><guid>https://huweim.github.io/posts/gpgpu_architecture/</guid><description>GPGPU Architecture 从有缩进的那一段开始成为第一段
1. Introduction 1.1 The Landspace Of Computation Accelerators 1 提升性能不能光依赖于摩尔定律了，需要从 Computer Arch 中去寻找提升
2 GPU 的性能优势, vector HW
3 专用的硬件对应用的性能提升帮助很大，如谷歌 TPU
4 modern GPUs support a Turing Complete programming model, 这是人们对 GPU 感兴趣的一大原因
By Turing Complete, we mean that any computation can be run given enough time and memory.
1.2 GPU Hardware Basic 1 API for GPUs,
These APIs function by providing convenient interfaces that hide the complexity of managing communication between the CPU and GPU rather than eliminating the need for a CPU entirely.</description></item><item><title>Ubuntu 20.04 下安装运行 GPGPU-Sim</title><link>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_ubuntu-20.04-%E4%B8%8B%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C-gpgpu-sim/</link><pubDate>Mon, 10 May 2021 15:17:51 +0800</pubDate><guid>https://huweim.github.io/posts/%E7%BC%96%E7%A8%8B_ubuntu-20.04-%E4%B8%8B%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C-gpgpu-sim/</guid><description>0. 前言 最近因为课程 Project 需要使用 GPGPU-Sim 复现一篇 paper，在之后的课题中可能也会用到这个模拟器。所以收集了相关资料以搭建 GPGPU-Sim 的环境并运行 Demo。GPGPU-Sim 的参考资料实在是不多，主要参考了官方文档、Github 中 README 文件，还有一些相关的 Blog。
本次只跑了一个非常简单的 Demo，关于 CUDA 实例可以参考 Textbook 《CUDA by Example》。里面提供了一些 CUDA 编程的源码介绍。有人在 Github 上提供了《CUDA by Example》的源代码。
不过自己搭建 GPGPU-Sim 的环境坑比较多，一定要注意 gcc/g++ 版本问题以及链接库。所以我个人还是建议如果不是长期使用，可以直接下载官方提供的 fully setup virtual machine 。在 http://gpgpu-sim.org/ 下载，然后导入 Virtual Box 使用。他们提供的虚拟机已经配置好了环境，可以直接使用 GPGPU-Sim 编译 .cu 文件然后在模拟器上运行。具体步骤可以参考 UCR 给的流程。
1. 介绍 GPGPU-sim能够在Linux系统下，提供对GPU的功能模拟和性能仿真，让你在没有装NVIDIA显卡的情况下可以编译并运行CUDA程序。当然它更重要的意义是，可以通过修改仿真参数，让开发者修改GPU内部架构，并进行性能仿真，以针对自己的项目需求进行更好的代码设计，获得更好的性能表现。
我使用的环境是
Ubuntu 20.04 CUDA Toolkit 11.1 gcc/g++ 5 ⚠️ 注意：在 Build GPGPU-Sim 之前最好就确保使用 gcc/g++ 5 版本 当时 GPGPU-Sim 作者测试时使用的是 CUDA 4.</description></item></channel></rss>