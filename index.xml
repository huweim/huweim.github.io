<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cory</title><link>https://huweim.github.io/</link><description>Recent content on Cory</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 23 Mar 2023 11:00:42 +0800</lastBuildDate><atom:link href="https://huweim.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>About</title><link>https://huweim.github.io/about/</link><pubDate>Thu, 08 Jul 2021 17:46:31 +0800</pubDate><guid>https://huweim.github.io/about/</guid><description>&lt;p>oh man, I love computer science and coding.&lt;/p>
&lt;p>一个计算机体系结构方向的学生，喜欢体系结构，喜欢编程，喜欢篮球。目前的课题主要关注 GPU/GPGPU。&lt;/p>
&lt;p>不确定自己是否喜欢折腾，是否喜欢新鲜事物，是否擅长编程。希望在一步一步探索中找到自己真正感兴趣的事情，或者确定这就是自己真正感兴趣的事情。&lt;/p></description></item><item><title>Makefile学习和实践</title><link>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_makefile%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 23 Mar 2023 11:00:42 +0800</pubDate><guid>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_makefile%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%AE%9E%E8%B7%B5/</guid><description>&lt;h1 id="1-简介和基础知识">1. 简介和基础知识&lt;/h1>
&lt;p>C语言中文网 &lt;a href="http://c.biancheng.net/view/7096.html">http://c.biancheng.net/view/7096.html&lt;/a>&lt;/p>
&lt;h2 id="11-makefile文件是什么">1.1 Makefile文件是什么？&lt;/h2>
&lt;h3 id="111-definition">1.1.1 Definition&lt;/h3>
&lt;p>Makefile是什么？&lt;/p>
&lt;ul>
&lt;li>用于描述编译规则的工程文件
&lt;ul>
&lt;li>即哪些文件先编译，哪些文件无需编译&lt;/li>
&lt;li>使得项目的编译自动化，不需要每次都手动输入一堆源文件和参数。&lt;/li>
&lt;li>可以理解为一个脚本语言，类似 Shell, Perl, Python&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Windows 下的集成开发环境（IDE）已经内置了 Makefile，或者说会自动生成 Makefile，无需手写&lt;/p>
&lt;p>对于 Linux，不懂 Makefile，就操作不了多文件编程，就完成不了相对于大的工程项目的操作。如果你想在 Linux(Unix) 环境下做开发的话，Makefile 是必须掌握的一项技能。&lt;/p>
&lt;h3 id="112-case">1.1.2 Case&lt;/h3>
&lt;p>比如多文件编译生成一个文件&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>gcc -o outfile name1.c name2.c ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>文件数量多了，就会有问题&lt;/p>
&lt;h3 id="113-链接库">1.1.3 链接库&lt;/h3>
&lt;ul>
&lt;li>C语言，编译的时候 gcc 只会默认链接一些基本的C语言标准库，很多源文件依赖的标准库都需要我们手动链接。&lt;/li>
&lt;li>name1.c 用到了数学计算库 math 中的函数，我们得手动添加参数 -Im；&lt;/li>
&lt;li>name5.c 使用到了线程，我们需要去手动添加参数 -lpthread。
&lt;ul>
&lt;li>这个情况在写 CUDA 的时候就遇到了&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>可以把要链接的库文件放在 Makefile 中，制定相应的规则和对应的链接顺序。这样只需要执行 make 命令，工程就会自动编译。&lt;/li>
&lt;/ul>
&lt;p>编译大的工程会花费很长的时间&lt;/p>
&lt;ul>
&lt;li>Makefile 支持多线程并发操作，会极大的缩短我们的编译时间，&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>具体操作应该是 &lt;code>make -j8&lt;/code>，使用八个线程&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>并且当我们修改了源文件之后，编译整个工程的时候，make 命令只会编译我们修改过的文件，没有修改的文件不用重新编译，也极大的解决了我们耗费时间的问题。&lt;/li>
&lt;/ul>
&lt;h2 id="12-makefile-文件结构">1.2 Makefile 文件结构&lt;/h2>
&lt;h3 id="121-目标依赖-targetprerequisite">1.2.1 目标，依赖 target，prerequisite&lt;/h3>
&lt;p>它的规则主要是两个部分组成，分别是依赖的关系和执行的命令，其结构如下所示：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">targets &lt;/span>&lt;span style="color:#f92672">:&lt;/span> prerequisites
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>or&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">targets &lt;/span>&lt;span style="color:#f92672">:&lt;/span> prerequisites; command
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>targets：规则的目标，可以是 Object File（一般称它为中间文件），也可以是可执行文件，还可以是一个标签；
&lt;ul>
&lt;li>也就是 command 的输出&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>prerequisites：是我们的依赖文件，要生成 targets 需要的文件或者是目标。可以是&lt;strong>多个&lt;/strong>，也可以是没有
&lt;ul>
&lt;li>a &amp;ldquo;prerequisite&amp;rdquo; is a file or target that must exist before a particular target can be built；&lt;/li>
&lt;li>构造 target 的前置条件&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>command：make 需要执行的命令（任意的 shell 命令）。可以有多条命令，每一条命令占一行。&lt;/li>
&lt;li>recipe：a series of commands that are executed to create or update a target&lt;/li>
&lt;/ul>
&lt;p>&amp;#x2757; Notion：我们的目标和依赖文件之间要使用冒号分隔开，命令的开始一定要使用&lt;code>Tab&lt;/code>键。&lt;/p>
&lt;ul>
&lt;li>使用了空格就会报错&lt;/li>
&lt;li>&lt;code>Makefile:2: *** 缺失分隔符。 停止。&lt;/code>&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>2022-11-25 19:55:02。这个特点和 shell 文件类似，空格的标准是一开始很容易出错而意识不到的地方&lt;/p>
&lt;/blockquote>
&lt;h4 id="1211-case">1.2.1.1 Case&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">main &lt;/span>&lt;span style="color:#f92672">:&lt;/span> main.c fun1.c fun2.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc -o main main.c fun1.c fun2.c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>实际情况中一行规则是肯定不够用的&lt;/p>
&lt;h2 id="13-变量">1.3 变量&lt;/h2>
&lt;h3 id="131-变量定义">1.3.1 变量定义&lt;/h3>
&lt;p>基本语法&amp;#x2757;&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>变量的名称 &lt;span style="color:#f92672">=&lt;/span> 值列表
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>变量的名称可以由大小写字母、阿拉伯数字和下划线构成。&lt;/p>
&lt;p>&amp;#x2757;等号左右的空白符没有明确的要求，因为在执行 make 的时候多余的空白符会被自动的删除。&lt;/p>
&lt;blockquote>
&lt;p>2022-11-25 19:54:29。shell 赋值的话，在 &lt;code>=&lt;/code> 两边不能留有空白。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>这一点很重要，因为 gcc 之前是必须用 &lt;code>Tab&lt;/code>，而变量赋值无需&lt;/li>
&lt;/ul>
&lt;p>至于值列表，既可以是零项，又可以是一项或者是多项。
调用变量的时候可以用 &amp;ldquo;$(VALUE_LIST)&amp;rdquo; 或者是 &amp;ldquo;${VALUE_LIST}&amp;rdquo; 来替换，这就是变量的引用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>OBJ&lt;span style="color:#f92672">=&lt;/span>main.o test.o test1.o test2.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>OBJ&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc -o test &lt;span style="color:#66d9ef">$(&lt;/span>OBJ&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="132-变量的基本赋值">1.3.2 变量的基本赋值&lt;/h3>
&lt;ul>
&lt;li>简单赋值 ( := ) 编程语言中常规理解的赋值方式，只对当前语句的变量有效。&lt;/li>
&lt;li>递归赋值 ( = ) 赋值语句可能影响多个变量，所有目标变量相关的其他变量都受影响。&lt;/li>
&lt;li>条件赋值 ( ?= ) 如果变量未定义，则使用符号中的值定义变量。如果该变量已经赋值，则该赋值语句无效。&lt;/li>
&lt;li>追加赋值 ( += ) 原变量用空格隔开的方式追加一个新值。&lt;/li>
&lt;/ul>
&lt;p>详细说明如下：&lt;/p>
&lt;h4 id="1321-简单赋值-">1.3.2.1 简单赋值 :=&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">:=&lt;/span>foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">:=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>x&lt;span style="color:#66d9ef">)&lt;/span>b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">:=&lt;/span>new
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">test：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;y=&amp;gt;$(y)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;x=&amp;gt;$(x)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 shell 命令行执行&lt;code>make test&lt;/code>我们会看到:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">=&lt;/span>&amp;gt;foob
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">=&lt;/span>&amp;gt;new
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1322-递归赋值-">1.3.2.2 递归赋值 =&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">=&lt;/span>foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>x&lt;span style="color:#66d9ef">)&lt;/span>b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">=&lt;/span>new
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">test：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;y=&amp;gt;$(y)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;x=&amp;gt;$(x)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 shell 命令行执行&lt;code>make test&lt;/code>我们会看到:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">=&lt;/span>&amp;gt;newb &lt;span style="color:#75715e">#理解为当某变量 x 更新后，所以和 x 相关的变量都会更新&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">=&lt;/span>&amp;gt;new
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1323-条件赋值-">1.3.2.3 条件赋值 ?=&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">:=&lt;/span>foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">:=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>x&lt;span style="color:#66d9ef">)&lt;/span>b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">?=&lt;/span>new
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">test：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;y=&amp;gt;$(y)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;x=&amp;gt;$(x)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 shell 命令行执行&lt;code>make test&lt;/code>我们会看到:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">=&lt;/span>&amp;gt;foob
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">=&lt;/span>&amp;gt;foo &lt;span style="color:#75715e"># x 已经定位为 foo 所以忽略掉 new 的赋值&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1324-追加赋值-">1.3.2.4 追加赋值 +=&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">:=&lt;/span>foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">:=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>x&lt;span style="color:#66d9ef">)&lt;/span>b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">+=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>y&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">test：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;y=&amp;gt;$(y)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#960050;background-color:#1e0010">@echo&lt;/span> &lt;span style="color:#e6db74">&amp;#34;x=&amp;gt;$(x)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 shell 命令行执行&lt;code>make test&lt;/code>我们会看到:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>y&lt;span style="color:#f92672">=&lt;/span>&amp;gt;foob
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x&lt;span style="color:#f92672">=&lt;/span>&amp;gt;foo foob &lt;span style="color:#75715e">#为什么有空格？&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="133-通配符">1.3.3 通配符&lt;/h3>
&lt;p>回想一下数据库的知识&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>通配符&lt;/th>
&lt;th>使用说明&lt;/th>
&lt;th>自动变量&lt;/th>
&lt;th>说明&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>*&lt;/td>
&lt;td>匹配0个或者是任意个字符&lt;/td>
&lt;td>$&amp;lt;&lt;/td>
&lt;td>第一个依赖文件&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>？&lt;/td>
&lt;td>匹配任意一个字符 # 注意是 1 个&lt;/td>
&lt;td>$@&lt;/td>
&lt;td>目标&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[]&lt;/td>
&lt;td>我们可以指定匹配的字符放在 &amp;ldquo;[]&amp;rdquo; 中&lt;/td>
&lt;td>$^&lt;/td>
&lt;td>所有不重复的依赖文件，以空格分开&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="1331-case-1">1.3.3.1 Case 1&lt;/h4>
&lt;p>测试可用 &amp;#x2b07;&amp;#xfe0f;&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span>*.c gcc -o $@ $^
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个实例可以说明我们的通配符不仅可以使用在规则的命令中，还可以使用在规则中。用来表示生所有的以 .c 结尾的文件。&lt;/p>
&lt;ul>
&lt;li>表示所有以 .c 结尾的文件同时编译，生成 test 文件&lt;/li>
&lt;/ul>
&lt;h4 id="1332-case-2">1.3.3.2 Case 2&lt;/h4>
&lt;p>&amp;#x26a0;&amp;#xfe0f; 讲述变量和通配符不要混用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>OBJ&lt;span style="color:#f92672">=&lt;/span>*.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>OBJ&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc -o $@ $^
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;#x2b50;我们去执行这个命令的时候会出现错误，提示我们没有 &amp;ldquo;*.c&amp;rdquo; 文件，实例中我们相要表示的是当前目录下所有的 &amp;ldquo;.c&amp;rdquo; 文件，但是我们在使用的时候并没有展开，而是直接识别成了一个文件。文件名是 &amp;ldquo;*.c&amp;rdquo;。&lt;/p>
&lt;p>&amp;#x1f17f;&amp;#xfe0f; 不过自己测试的时候可以成功编译，这可能是 makefile 自己做了优化&lt;/p>
&lt;h3 id="134-wildcard-函数">1.3.4 wildcard 函数&lt;/h3>
&lt;p>如果我们就是相要通过引用变量的话，我们要使用一个函数 &amp;ldquo;wildcard&amp;rdquo;，这个函数在我们引用变量的时候，会帮我们展开。我们把上面的代码修改一下就可以使用了。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>OBJ&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>wildcard *.c&lt;span style="color:#66d9ef">)&lt;/span>test:&lt;span style="color:#66d9ef">$(&lt;/span>OBJ&lt;span style="color:#66d9ef">)&lt;/span> gcc -o $@ $^
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样我们再去使用的时候就可以了。调用函数的时候，会帮我们自动展开函数。&lt;/p>
&lt;p>还有一个和通配符 &amp;ldquo;*&amp;rdquo; 相类似的字符，这个字符是 &amp;ldquo;%&amp;quot;，也是匹配任意个字符，使用在我们的的规则当中。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span>test.o test1.o gcc -o $@ $^%.o:%.c gcc -o $@ $^
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;ldquo;%.o&amp;rdquo; 把我们需要的所有的 &amp;ldquo;.o&amp;rdquo; 文件组合成为一个列表，从列表中挨个取出的每一个文件，&amp;rdquo;%&amp;quot; 表示取出来文件的文件名（不包含后缀），然后找到文件中和 &amp;ldquo;%&amp;ldquo;名称相同的 &amp;ldquo;.c&amp;rdquo; 文件，然后执行下面的命令，直到列表中的文件全部被取出来为止。&lt;/p>
&lt;h2 id="14-简单实例">1.4 简单实例&lt;/h2>
&lt;p>来自知乎 &lt;a href="https://www.zhihu.com/question/23792247/answer/600773044">https://www.zhihu.com/question/23792247/answer/600773044&lt;/a>&lt;/p>
&lt;h3 id="141-第一版">1.4.1 第一版&lt;/h3>
&lt;p>测试过，可以 work&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">main &lt;/span>&lt;span style="color:#f92672">:&lt;/span> main.c fun1.c fun2.c gcc -o main main.c fun1.c fun2.c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;#x2757; 缺点&lt;/p>
&lt;ul>
&lt;li>对于简单代码还好，而对于大型项目，具有成千上万代码来说，仅用一行规则是完全不够的，即使够的话也需要写很长的一条规则&lt;/li>
&lt;li>任何文件只要稍微做了修改就需要整个项目完整的重要编译
&lt;ul>
&lt;li>Which means 有办法在修改一部分时只编译那一小部分&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>2023-03-23 10:28:52，自己的理解：这样写的话，所有的 .c 文件都是 &lt;code>main&lt;/code> 的依赖，那么任意改其中一个 .c 文件，&lt;code>main&lt;/code> 都需要重新编译，src code 之间的独立性不强。&lt;/p>
&lt;h3 id="142-第二版">1.4.2 第二版&lt;/h3>
&lt;p>为了避免改动任何代码就需要重新编译整个项目的问题，我们将主规则的各个依赖替换成各自的中间文件
即main.c &amp;ndash;&amp;gt; main.o，fun1.c &amp;ndash;&amp;gt; fun1.o，fun2.c &amp;ndash;&amp;gt; fun2.o，再对每个中间文件的生成分别写一条规则
比如对于main.o，规则为：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">main.o&lt;/span>&lt;span style="color:#f92672">:&lt;/span> main.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc -c main.c -o main.o
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样做的好处是，当有一个文件发生改动时，只需重新编译此文件即可，而无需重新编译整个项目。完整Makefile如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">app &lt;/span>&lt;span style="color:#f92672">:&lt;/span> main.o fun1.o fun2.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc main.o fun1.o fun2.o -o app
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">main.o &lt;/span>&lt;span style="color:#f92672">:&lt;/span> main.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc -c main.c -o main.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">fun1.o &lt;/span>&lt;span style="color:#f92672">:&lt;/span> fun1.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc -c fun1.c -o fun1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">fun2.o &lt;/span>&lt;span style="color:#f92672">:&lt;/span> fun2.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gcc -c fun2.c -o fun2.o
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;#x26a0;&amp;#xfe0f; 注意不要加多余的空格，(gcc) 命令的开始一定要使用&lt;code>Tab&lt;/code>键，不能是空格&lt;/p>
&lt;p>&amp;#x2757; 缺点&lt;/p>
&lt;ul>
&lt;li>里面存在一些重复的内容，可以考虑用变量代替；&lt;/li>
&lt;li>后面三条规则非常类似，可以考虑用一条模式规则代替。
&lt;ul>
&lt;li>说白了也就是有重复&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>2023-03-23 10:31:39，但是这里的重复只是写法上的重复，而 &lt;code>app&lt;/code> 对 src code 的依赖关系已经独立开来，能够提升重新编译的效率。&lt;/p>
&lt;h3 id="143-第三版">1.4.3 第三版&lt;/h3>
&lt;p>引入了变量的概念&lt;/p>
&lt;p>在第三版Makefile中，我们使用变量及模式规则使Makefile更加简洁。使用的三个变量如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>obj &lt;span style="color:#f92672">=&lt;/span> main.o fun1.o fun2.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>target &lt;span style="color:#f92672">=&lt;/span> app
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CC &lt;span style="color:#f92672">=&lt;/span> gcc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>使用的模式规则为：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">%.o&lt;/span>&lt;span style="color:#f92672">:&lt;/span> %.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>CC&lt;span style="color:#66d9ef">)&lt;/span> -c $&amp;lt; -o $@
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Means -&amp;gt; 所有的.o文件都由对应的.c文件生成。在规则里，我们又看到了两个自动变量：&lt;code>$&amp;lt;&lt;/code> 和 &lt;code>$@&lt;/code>。
其实自动变量有很多，常用的有三个：&lt;/p>
&lt;ul>
&lt;li>&lt;code>$&amp;lt;&lt;/code>：第一个依赖文件；&lt;/li>
&lt;li>&lt;code>$@&lt;/code>：目标；&lt;/li>
&lt;li>&lt;code>$^&lt;/code>：所有不重复的依赖文件，以空格分开&lt;/li>
&lt;/ul>
&lt;p>直接复制过来的源码是有问题的，需要手动调整一下 Tab。&amp;#x2b07;&amp;#xfe0f; 是可以使用的。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>obj &lt;span style="color:#f92672">=&lt;/span> main.o fun1.o fun2.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>target &lt;span style="color:#f92672">=&lt;/span> app
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CC &lt;span style="color:#f92672">=&lt;/span> gcc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">$(target)&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>obj&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>CC&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>obj&lt;span style="color:#66d9ef">)&lt;/span> -o &lt;span style="color:#66d9ef">$(&lt;/span>target&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">%.o&lt;/span>&lt;span style="color:#f92672">:&lt;/span> %.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>CC&lt;span style="color:#66d9ef">)&lt;/span> -c $&amp;lt; -o $@ &lt;span style="color:#75715e">#这个 百分号% 就类似于数据库中的匹配 所有以 .o 结尾的是 target 以 .c 结尾的是 prerequisites&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;#x2757; 缺点&lt;/p>
&lt;ul>
&lt;li>obj对应的文件需要一个个输入，工作量大；&lt;/li>
&lt;li>文件数目比较少时还好，文件数目一旦很多的话，obj将很长；&lt;/li>
&lt;li>而且每增加/删除一个文件，都需要修改Makefile。&lt;/li>
&lt;/ul>
&lt;p>2023-03-23 10:35:37，这里的意思应该是要事先准备好所有需要的 .o 文件，而 .o 文件需要从 .c 文件编译得到。其中仍然是存在将所有 .c 编译成对应的 .o 文件的过程，不够自动化。&lt;/p>
&lt;h3 id="144-第四版">1.4.4 第四版&lt;/h3>
&lt;p>在第四版Makefile中，推出了两个函数：&lt;strong>wildcard&lt;/strong> 和 &lt;strong>patsubst&lt;/strong>。&lt;/p>
&lt;h4 id="1441-wildcard">1.4.4.1 wildcard&lt;/h4>
&lt;p>作用：扩展通配符，搜索指定文件。在此我们使用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>src &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>wildcard ./*.c&lt;span style="color:#66d9ef">)&lt;/span>，#代表在当前目录下搜索所有的.c文件，并赋值给src。函数执行结束后，src的值为：main.c fun1.c fun2.c。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1442-patsubst">1.4.4.2 patsubst&lt;/h4>
&lt;p>作用：替换通配符，按指定规则做替换。在此我们使用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>obj &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>patsubst %.c, %.o, &lt;span style="color:#66d9ef">$(&lt;/span>src&lt;span style="color:#66d9ef">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>代表将src里的每个文件都由.c替换成.o。函数执行结束后，&lt;code>obj&lt;/code> 的值为 &lt;code>main.o fun1.o fun2.o&lt;/code>，其实跟第三版 Makefile 的 obj 值一模一样，只不过在这里它更智能一些，也更灵活。&lt;/p>
&lt;p>除了使用 &lt;code>patsubst&lt;/code> 函数外，我们也可以使用模式规则达到同样的效果，比如：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>obj &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>src:%.c&lt;span style="color:#f92672">=&lt;/span>%.o&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>也是代表将src里的每个文件都由.c替换成.o。&lt;/p>
&lt;p>几乎每个 Makefile 里都会有一个 &lt;strong>伪目标&lt;/strong> clean，这样我们通过执行make clean命令就是将中间文件如 .o 文件及目标文件全部删除，留下干净的空间。一般是如下写法：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">.PHONY&lt;/span>&lt;span style="color:#f92672">:&lt;/span> clean clean: rm -rf &lt;span style="color:#66d9ef">$(&lt;/span>obj&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>target&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>.PHONY代表声明clean是一个 &lt;strong>伪目标&lt;/strong>，这样每次执行 &lt;code>make clean&lt;/code> 时，下面的规则都会被执行。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>src &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>wildcard ./*.c&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>obj &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>patsubst %.c, %.o, &lt;span style="color:#66d9ef">$(&lt;/span>src&lt;span style="color:#66d9ef">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>obj &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>src:%.c&lt;span style="color:#f92672">=&lt;/span>%.o&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>target &lt;span style="color:#f92672">=&lt;/span> app
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CC &lt;span style="color:#f92672">=&lt;/span> gcc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">$(target)&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>obj&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>CC&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>obj&lt;span style="color:#66d9ef">)&lt;/span> -o &lt;span style="color:#66d9ef">$(&lt;/span>target&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">%.o&lt;/span>&lt;span style="color:#f92672">:&lt;/span> %.c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>CC&lt;span style="color:#66d9ef">)&lt;/span> -c $&amp;lt; -o $@
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">.PHONY&lt;/span>&lt;span style="color:#f92672">:&lt;/span> clean
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">clean&lt;/span>&lt;span style="color:#f92672">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rm -rf &lt;span style="color:#66d9ef">$(&lt;/span>obj&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>target&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="2-常用的编译选项-cli-option">2. 常用的编译选项 CLI option&lt;/h1>
&lt;p>给出几个自己用到过的选项&lt;/p>
&lt;h2 id="21--n-打印所有编译命令但并不执行">2.1 -n 打印所有编译命令，但并不执行&lt;/h2>
&lt;p>&lt;code>make -n mlp_learning_an_image&lt;/code>&lt;/p>
&lt;h2 id="22--s--f">2.2 -s -f&lt;/h2>
&lt;p>&lt;code>-s&lt;/code>：禁止输出编译命令信息 -s。
&lt;code>-f&lt;/code>：用于指定 makefile 文件的名称或路径。它告诉 make 命令使用指定的 makefile 文件而不是默认的 Makefile 文件来执行编译。&lt;/p>
&lt;p>下面的代码中，Makefile 文件是 &lt;code>build.make&lt;/code>，因为 &lt;code>make&lt;/code> 命令默认是找目录下的名为 &lt;code>Makefile&lt;/code> 文件。这里的 Makefile 并非默认的名称，因此需要用 &lt;code>-f&lt;/code> 选项来指定文件。而 &lt;code>make&lt;/code> target 是 &lt;code>dependencies/fmt/CMakeFiles/fmt.dir/build&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">make&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">-s&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">-f&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">dependencies/fmt/CMakeFiles/fmt.dir/build.make&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">dependencies/fmt/CMakeFiles/fmt.dir/build&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="3-变量-variable">3. 变量 variable&lt;/h1>
&lt;h1 id="4-条件语句和函数-conditional-syntax-and-functions">4. 条件语句和函数 conditional syntax and functions&lt;/h1>
&lt;h1 id="5-关键字-built-in-targets">5. 关键字 built-in targets&lt;/h1>
&lt;h2 id="51-phony">5.1 .PHONY&lt;/h2>
&lt;blockquote>
&lt;p>In a Makefile, .PHONY is a special target that is used to declare a target that doesn&amp;rsquo;t represent an actual file. Instead, it is used to specify a target that is always considered out of date, and therefore, its recipe will always be executed whenever it is requested.&lt;/p>
&lt;/blockquote>
&lt;p>也就是说在对于 .PHONY 关键字后面的内容，只要有请求，就会执行。还是很绕，直接看例子吧。使用 .PHONY 声明了 CMakeFiles/tiny-cuda-nn.dir/depend，也就是说只要输入命令 &lt;code>make CMakeFiles/tiny-cuda-nn.dir/depend&lt;/code>，就会执行其命令行，不管有哪种依赖&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Makefile" data-lang="Makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">CMakeFiles/tiny-cuda-nn.dir/depend&lt;/span>&lt;span style="color:#f92672">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cd /home/wmhu/work/tiny-cuda-nn/build &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>CMAKE_COMMAND&lt;span style="color:#66d9ef">)&lt;/span> -E cmake_depends &lt;span style="color:#e6db74">&amp;#34;Unix Makefiles&amp;#34;&lt;/span> /home/wmhu/work/tiny-cuda-nn /home/wmhu/work/tiny-cuda-nn /home/wmhu/work/tiny-cuda-nn/build /home/wmhu/work/tiny-cuda-nn/build /home/wmhu/work/tiny-cuda-nn/build/CMakeFiles/tiny-cuda-nn.dir/DependInfo.cmake --color&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>COLOR&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">.PHONY &lt;/span>&lt;span style="color:#f92672">:&lt;/span> CMakeFiles/tiny-cuda-nn.dir/depend
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>再来一个例子，关于 clean。声明之后，不管 .o 文件和 bin 文件是不是存在，只要 &lt;code>make clean&lt;/code>，就会执行 &lt;code>rm -f *.o myprogram&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-Makefile" data-lang="Makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">.PHONY&lt;/span>&lt;span style="color:#f92672">:&lt;/span> clean
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">clean&lt;/span>&lt;span style="color:#f92672">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rm -f *.o myprogram
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="52-default">5.2 .DEFAULT&lt;/h2>
&lt;h1 id="6-应用技巧">6. 应用技巧&lt;/h1>
&lt;p>这一章描述一些实践过程中的技巧，可以参考 chatgpt 给的大纲，查缺补漏，细细完善。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>Makefile 基础知识
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>什么是 Makefile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 的工作原理
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 的基本语法
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 中的变量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 中的目标和依赖关系
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 的常用命令
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make 命令
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>clean 命令
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>distclean 命令
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>install 命令
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>uninstall 命令
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 的高级应用
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 中的条件语句
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 中的函数
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 中的自动化变量
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 中的模式规则
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 中的多目标规则
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>实际问题和解决方案
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何在 Makefile 中设置编译器和编译选项
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何在 Makefile 中编译和链接多个源文件
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何在 Makefile 中编译和链接静态库和动态库
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何在 Makefile 中定义和使用宏定义
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何在 Makefile 中使用条件编译
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 的调试技巧
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何使用 Makefile 的调试选项
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何输出 Makefile 中的变量和宏定义
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何查看 Makefile 中的依赖关系
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何查看 Makefile 中的编译和链接命令
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile 的最佳实践
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何编写可移植的 Makefile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何编写可维护的 Makefile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何编写高效的 Makefile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>如何组织 Makefile 的目录结构
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>以上是一些可以作为 Makefile 笔记的主题和子主题，你可以根据自己的需要进行扩充和调整。在整理笔记的过程中，你可以结合自己的实际学习和应用情况，将理论知识和实践问题结合起来，这样能够使笔记更加丰富和实用。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="7-通过实例学习">7. 通过实例学习&lt;/h1>
&lt;h2 id="71-cutlass-实例">7.1 cutlass 实例&lt;/h2>
&lt;h3 id="712-make-中的选项">7.1.2 make 中的选项&lt;/h3>
&lt;p>&lt;code>make -s -f CMakeFiles/Makefile2 samples/CMakeFiles/mlp_learning_an_image.dir/all&lt;/code>&lt;/p>
&lt;p>这一句命令表示使用 CMakeFiles/Makefile2 文件中定义的规则来编译 samples/CMakeFiles/mlp_learning_an_image.dir/all 目标。-s 选项指示 make 命令在执行编译过程时不显示编译命令。&lt;/p>
&lt;p>all 是一个伪目标，指示 make 命令编译所有的目标。在这个上下文中，samples/CMakeFiles/mlp_learning_an_image.dir/all 是一个特殊的目标，它实际上是由 CMake 自动生成的一个中间目标。它的作用是将 samples/CMakeFiles/mlp_learning_an_image.dir 目录中所有的源文件编译成目标文件，并将它们链接为一个可执行文件。&lt;/p>
&lt;p>在 Makefile 中，通常会定义一个名为 all 的伪目标，用于编译所有的目标。all 目标通常是默认目标，也就是在不指定目标的情况下，make 命令将会编译它。当然，开发者也可以定义其他的伪目标来执行指定的编译任务。&lt;/p>
&lt;p>什么是伪目标？&lt;/p>
&lt;p>实际目标指的是编译生成的文件或其他需要执行的任务。
伪目标则是指用来控制 Makefile 中规则执行顺序的目标，不生成对应的文件。&lt;/p>
&lt;p>伪目标的作用是在执行 make 命令时，告诉 make 命令要执行哪些规则。它通常用来控制 Makefile 中规则的执行顺序，或者执行一些特定的任务，如清除生成的文件等。&lt;/p>
&lt;p>在 Makefile 中，伪目标的特征是没有对应的文件名，并且在规则中使用了 .PHONY 声明，以告诉 make 命令它是一个伪目标。例如：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">.PHONY&lt;/span>&lt;span style="color:#f92672">:&lt;/span> clean
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">clean&lt;/span>&lt;span style="color:#f92672">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rm -f *.o
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在上面的例子中，clean 是一个伪目标，它的作用是删除当前目录下的所有 .o 文件。.PHONY 声明告诉 make 命令 clean 是一个伪目标，不对应任何文件，只是一个控制规则执行顺序的目标。&lt;/p>
&lt;p>需要注意的是，如果不使用 .PHONY 声明声明一个伪目标，那么当在当前目录下存在一个与目标同名的文件时，make 命令会将其误认为是实际目标，导致错误的行为。因此，定义伪目标时一定要加上 .PHONY 声明。&lt;/p>
&lt;hr>
&lt;h1 id="0-cmake-和-makefile-异同">0. Cmake 和 Makefile 异同&lt;/h1>
&lt;p>这一章参考 &lt;a href="https://www.zhihu.com/question/27455963/answer/36722992">知乎文章&lt;/a>&lt;/p>
&lt;h2 id="01-功能描述">0.1 功能描述&lt;/h2>
&lt;ul>
&lt;li>&lt;code>make&lt;/code> command 是用来执行 Makefile 的&lt;/li>
&lt;li>Makefile 是类 UNIX 环境下(比如Linux)的类似于批处理的&amp;quot;脚本&amp;quot;文件。
其基本语法是: &lt;strong>目标+依赖+命令&lt;/strong>，只有在&lt;strong>目标&lt;/strong>文件不存在，或&lt;strong>目标&lt;/strong>比&lt;strong>依赖&lt;/strong>的文件更旧，&lt;strong>命令&lt;/strong>才会被执行。由此可见，Makefile和make可适用于任意工作，不限于编程。比如，可以用来管理latex。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>2022-11-25 19:47:20，从这个描述来看，猜测判断 &lt;strong>目标&lt;/strong> 是否 &lt;code>Already Update..&lt;/code> 的依据是系统时间。判断 &lt;strong>目标&lt;/strong> 的修改时间是否晚于 &lt;strong>依赖&lt;/strong> 文件的修改时间。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>
&lt;p>Makefile+make可理解为类unix环境下的项目管理工具，但它太基础了，抽象程度不高，而且在windows下不太友好(针对visual studio用户)，于是就有了跨平台项目管理工具cmake&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cmake是跨平台项目管理工具，它用更抽象的语法来组织项目。虽然，仍然是目标，依赖之类的东西，但更为抽象和友好，比如你可用math表示数学库，而不需要再具体指定到底是math.dll还是libmath.so，在windows下它会支持生成visual studio的工程，在linux下它会生成Makefile，甚至它还能生成eclipse工程文件。也就是说，从同一个抽象规则出发，它为各个编译器定制工程文件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cmake是抽象层次更高的项目管理工具，cmake命令执行的CMakeLists.txt文件&lt;/p>
&lt;/li>
&lt;li>
&lt;p>cmake 抽象程度更高&lt;/p>
&lt;/li>
&lt;li>
&lt;p>qmake是Qt专用的项目管理工具，对应的工程文件是*.pro，在Linux下面它也会生成Makefile，当然，在命令行下才会需要手动执行qmake，完全可以在qtcreator这个专用的IDE下面打开*.pro文件，使用qmake命令的繁琐细节不用你管了。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>总结&lt;/strong>&lt;/p>
&lt;p>总结一下，make用来执行Makefile，cmake用来执行CMakeLists.txt，qmake用来处理*.pro工程文件。Makefile的抽象层次最低，cmake和qmake在Linux等环境下最后还是会生成一个Makefile。cmake和qmake支持跨平台，cmake的做法是生成指定编译器的工程文件，而qmake完全自成体系。&lt;/p>
&lt;h2 id="02-个人理解">0.2 个人理解&lt;/h2>
&lt;ul>
&lt;li>&amp;#x2b50; ​具体使用时，Linux下，小工程可手动写Makefile，
&lt;ul>
&lt;li>所以学会自己手写 Makefile 对于一些测试工作也是比较重要的&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>大工程用automake来帮你生成Makefile，&lt;/li>
&lt;li>要想跨平台，就用cmake。&lt;/li>
&lt;li>如果GUI用了Qt，也可以用qmake+*.pro来管理工程，这也是跨平台的。当然，cmake中也有针对Qt的一些规则，并代替qmake帮你将qt相关的命令整理好了。&lt;/li>
&lt;/ul>
&lt;p>另外，需要指出的是，make和cmake主要命令只有一条，make用于处理Makefile，cmake用来转译CMakeLists.txt，而qmake是一个体系，用于支撑一个编程环境，它还包含除qmake之外的其它多条命令(比如uic，rcc,moc)。&lt;/p>
&lt;p>上个简图，其中cl表示visual studio的编译器，gcc表示linux下的编译器&lt;/p></description></item><item><title>Xxxxx</title><link>https://huweim.github.io/posts/xxxxx/</link><pubDate>Fri, 13 Jan 2023 14:49:52 +0800</pubDate><guid>https://huweim.github.io/posts/xxxxx/</guid><description/></item><item><title>Xx</title><link>https://huweim.github.io/posts/xx/</link><pubDate>Fri, 13 Jan 2023 14:25:14 +0800</pubDate><guid>https://huweim.github.io/posts/xx/</guid><description/></item><item><title>自己动手部署transformer模型 by huggingface</title><link>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E9%83%A8%E7%BD%B2transformer%E6%A8%A1%E5%9E%8B_huggingface/</link><pubDate>Sun, 23 Oct 2022 11:00:17 +0800</pubDate><guid>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E9%83%A8%E7%BD%B2transformer%E6%A8%A1%E5%9E%8B_huggingface/</guid><description>&lt;h1 id="0-前言">0. 前言&lt;/h1>
&lt;p>这部分内容还是很重要的，预计会设计常见的 pytorch 模型部署方法，理解框架中，每个模块在做什么。另外，这也是工程上必备的技能。&lt;/p>
&lt;h2 id="01-模型及下载地址">0.1 模型及下载地址&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>Repo&lt;/th>
&lt;th>Paper&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ResNet (18: 12M; 50: 26M; 152: 60M)&lt;/td>
&lt;td>&lt;a href="https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py">https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py&lt;/a>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BERT (110 / 330M)&lt;/td>
&lt;td>&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT">https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT&lt;/a>&lt;/td>
&lt;td>&lt;a href="https://arxiv.org/abs/1810.04805">https://arxiv.org/abs/1810.04805&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GPT-2 (1.5B)&lt;/td>
&lt;td>&lt;a href="https://github.com/openai/gpt-2">https://github.com/openai/gpt-2&lt;/a>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OPT (125 / 350M; 1.3 / 2.7 / 6.7 / 13 / 30 / 66 / 175B)&lt;/td>
&lt;td>&lt;a href="https://github.com/facebookresearch/metaseq">https://github.com/facebookresearch/metaseq&lt;/a>&lt;/td>
&lt;td>&lt;a href="https://arxiv.org/pdf/2205.01068.pdf">https://arxiv.org/pdf/2205.01068.pdf&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BLOOM (560M; 1.1 / 1.7 / 3 / 7.1 / 176B)&lt;/td>
&lt;td>&lt;a href="https://huggingface.co/docs/transformers/model_doc/bloom">https://huggingface.co/docs/transformers/model_doc/bloom&lt;/a>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>T5 (60 / 220 / 770M; 3 / 11B)&lt;/td>
&lt;td>&lt;a href="https://github.com/google-research/text-to-text-transfer-transformer#released-model-checkpoints">https://github.com/google-research/text-to-text-transfer-transformer#released-model-checkpoints&lt;/a>&lt;/td>
&lt;td>&lt;a href="https://jmlr.org/papers/volume21/20-074/20-074.pdf">https://jmlr.org/papers/volume21/20-074/20-074.pdf&lt;/a>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="02-模型下载方法">0.2 模型下载方法&lt;/h2>
&lt;p>2023-07-08 20:10:12，重新回顾 22 年关于大模型研究的工作。从 chatgpt 爆火之后，大模型应用的框架变得火热，语言模型的社区也变得火热起来。准备在 ant_ext 工作中加入一些新的模型的评估，但是期智连接 huggingface 的网络老是抽风，导致试图从 huggingface 下载模型时出现错误。现在总结一些其他的下载方法。&lt;/p>
&lt;p>Ref: &lt;a href="https://zhuanlan.zhihu.com/p/475260268">https://zhuanlan.zhihu.com/p/475260268&lt;/a>&lt;/p>
&lt;h3 id="021-git-lfs">0.2.1 git lfs&lt;/h3>
&lt;p>这个方法会下载所有框架的模型文件，flax_model.msgpack、tf_model.h5和pytorch_model.bin，可以看到有 3 种框架的模型文件，比较冗余。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>git lfs install
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git clone https://huggingface.co/bert-base-chinese
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="022-hungging-face-hub">0.2.2 hungging face hub&lt;/h3>
&lt;p>这种方法其实仍然是通过访问 huggingface 网站来下载&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>python
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;gt;&amp;gt;&amp;gt; from huggingface_hub import snapshot_download
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;gt;&amp;gt;&amp;gt; snapshot_download&lt;span style="color:#f92672">(&lt;/span>repo_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;facebook/opt-13b&amp;#34;&lt;/span>&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 通过参数可以指定下载的文件，屏蔽不需要的文件即可&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;gt;&amp;gt;&amp;gt; snapshot_download&lt;span style="color:#f92672">(&lt;/span>repo_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;facebook/opt-13b&amp;#34;&lt;/span>, ignore_patterns&lt;span style="color:#f92672">=[&lt;/span>&lt;span style="color:#e6db74">&amp;#34;*.h5&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;*.ot&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;*.msgpack&amp;#34;&lt;/span>&lt;span style="color:#f92672">]&lt;/span>, local_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;/localdata_ssd/model&amp;#34;&lt;/span>, local_dir_use_symlinks&lt;span style="color:#f92672">=&lt;/span>False&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="1-hugging-face">1. Hugging Face&lt;/h1>
&lt;p>简介：Hugging face 是一家总部位于纽约的聊天机器人初创服务商，开发的应用在青少年中颇受欢迎，相比于其他公司，Hugging Face更加注重产品带来的情感以及环境因素。但更令它广为人知的是Hugging Face专注于NLP技术，拥有大型的开源社区。尤其是在github上开源的自然语言处理，预训练模型库 Transformers，已被下载超过一百万次，github上超过24000个star。Transformers 提供了NLP领域大量state-of-art的 预训练语言模型结构的模型和调用框架。&lt;/p>
&lt;p>BERT 模型中，一个 token-wise 就是 768 维的向量。&lt;/p>
&lt;blockquote>
&lt;p>总的来说，提供了各种易用 transformer 模型，并且有很好的社区和文档。&lt;/p>
&lt;/blockquote>
&lt;h2 id="11-简介">1.1 简介&lt;/h2>
&lt;h3 id="111-用途">1.1.1 用途&lt;/h3>
&lt;p>理解了一下，感觉是提供预训练好的模型，自己可以用来解决一些任务。&lt;/p>
&lt;h3 id="112-重要概念">1.1.2 重要概念&lt;/h3>
&lt;h4 id="1121-pipeline">1.1.2.1 Pipeline&lt;/h4>
&lt;p>pipeline 函数：包含 pro-processing, model, post-processing&lt;/p>
&lt;p>如果只是想使用训练好的模型的功能，这是最简单的方法。pipeline 函数中应该完成了一套 workflow。下列代码下载了大概 300MB 的预训练模型，给出了对我输入的句子的情感分析。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> pipeline
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>classifier &lt;span style="color:#f92672">=&lt;/span> pipeline(&lt;span style="color:#e6db74">&amp;#34;sentiment-analysis&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(classifier(&lt;span style="color:#e6db74">&amp;#34;You like a pig&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>output: [{&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;NEGATIVE&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;score&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">0.9961085915565491&lt;/span>}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1122-autoclass">1.1.2.2 AutoClass&lt;/h4>
&lt;p>&lt;code>AutoModelForSequenceClassification&lt;/code> 以及 &lt;code>AutoTokenizer&lt;/code> 用于支持 &lt;code>pipeline()&lt;/code>。AutoClass 是一种快捷方式，可以自动从预训练模型的名称或路径中检索模型架构。 您只需要为您的任务选择适当的 AutoClass 及其关联的预处理类。&lt;/p>
&lt;blockquote>
&lt;p>在自己使用时，选择 GPT2 模型，需要 &lt;code>from transformers import GPT2Model&lt;/code>，如果要引入其他模型也是类似的做法。&lt;code>from transformers import AutoModel&lt;/code>，应该可以根据模型名称自己去检索下载。&lt;/p>
&lt;/blockquote>
&lt;p>2022-10-25 21:13:01，当我有可能通过参数载入多种模型时，我意识到了 AutoClass 的作用。&lt;/p>
&lt;h4 id="1123-custom-model">1.1.2.3 Custom Model&lt;/h4>
&lt;p>主要途径是获取模型的 config，然后手动修改即可。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> AutoConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>my_config &lt;span style="color:#f92672">=&lt;/span> AutoConfig&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;distilbert-base-uncased&amp;#34;&lt;/span>, n_heads&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">12&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>my_model &lt;span style="color:#f92672">=&lt;/span> AutoModel&lt;span style="color:#f92672">.&lt;/span>from_config(my_config)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1124-trainer---a-pytorch-optimized-training-loop">1.1.2.4 Trainer - a PyTorch optimized training loop&lt;/h4>
&lt;p>目前的很多框架中都有一套训练的 loop，hugging face 也提供了这套流程。设置好几个必备的参数和输入即可。&lt;/p>
&lt;ol>
&lt;li>A PreTrainedModel or a &lt;code>torch.nn.Module&lt;/code>；自己定制一个模型应该也是可以的。&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> AutoModelForSequenceClassification
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> AutoModelForSequenceClassification&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;distilbert-base-uncased&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>&lt;code>TrainingArguments&lt;/code>：超参数，比如 learning rate, batch size, epoch&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> TrainingArguments
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>training_args &lt;span style="color:#f92672">=&lt;/span> TrainingArguments(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> output_dir&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;path/to/save/folder/&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> learning_rate&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2e-5&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> per_device_train_batch_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> per_device_eval_batch_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_train_epochs&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>设置预处理过程：比如 tokenizer, feature extractor, processor&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> AutoTokenizer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenizer &lt;span style="color:#f92672">=&lt;/span> AutoTokenizer&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;distilbert-base-uncased&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="4">
&lt;li>定义预处理的训练数据集和测试数据集；不过这段代码之前得先把 dataset load 进来吧。&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_dataset &lt;span style="color:#f92672">=&lt;/span> dataset[&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># doctest: +SKIP&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>eval_dataset &lt;span style="color:#f92672">=&lt;/span> dataset[&lt;span style="color:#e6db74">&amp;#34;eval&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># doctest: +SKIP&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="5">
&lt;li>&lt;code>DataCollator()&lt;/code> to create a batch of examples from your dataset&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> DefaultDataCollator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data_collator &lt;span style="color:#f92672">=&lt;/span> DefaultDataCollator()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>2022-10-24 09:43:20，这个 example 比较陌生&lt;/p>
&lt;/blockquote>
&lt;ol start="6">
&lt;li>Put it all together&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> Trainer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>trainer &lt;span style="color:#f92672">=&lt;/span> Trainer(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">=&lt;/span>model,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">=&lt;/span>training_args,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_dataset&lt;span style="color:#f92672">=&lt;/span>dataset[&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> eval_dataset&lt;span style="color:#f92672">=&lt;/span>dataset[&lt;span style="color:#e6db74">&amp;#34;test&amp;#34;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tokenizer&lt;span style="color:#f92672">=&lt;/span>tokenizer,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data_collator&lt;span style="color:#f92672">=&lt;/span>data_collator,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) &lt;span style="color:#75715e"># doctest: +SKIP&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># start training&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>trainer&lt;span style="color:#f92672">.&lt;/span>train()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1125-预处理">1.1.2.5 预处理&lt;/h4>
&lt;p>对于 NLP 模型，一般就是用 tokenizer 来做。经过 tokenizer 的字典有三个重要的 items&lt;/p>
&lt;ul>
&lt;li>input_ids, the indices corresponding to each token in the sentence.&lt;/li>
&lt;li>attention_mask, indicates whether a token should be attended to or not.&lt;/li>
&lt;li>token_type_ids, identifies which sequence a token belongs to when there is more than one sequence.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>padding&lt;/strong>&lt;/p>
&lt;p>每个 sentence 长度不一致，用 padding 来 tensor 对齐。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>batch_sentences &lt;span style="color:#f92672">=&lt;/span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;But what about second breakfast?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;Don&amp;#39;t think he knows about second breakfast, Pip.&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;What about elevensies?&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>encoded_input &lt;span style="color:#f92672">=&lt;/span> tokenizer(batch_sentences, padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(encoded_input)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{&lt;span style="color:#e6db74">&amp;#39;input_ids&amp;#39;&lt;/span>: [[&lt;span style="color:#ae81ff">101&lt;/span>, &lt;span style="color:#ae81ff">1252&lt;/span>, &lt;span style="color:#ae81ff">1184&lt;/span>, &lt;span style="color:#ae81ff">1164&lt;/span>, &lt;span style="color:#ae81ff">1248&lt;/span>, &lt;span style="color:#ae81ff">6462&lt;/span>, &lt;span style="color:#ae81ff">136&lt;/span>, &lt;span style="color:#ae81ff">102&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">101&lt;/span>, &lt;span style="color:#ae81ff">1790&lt;/span>, &lt;span style="color:#ae81ff">112&lt;/span>, &lt;span style="color:#ae81ff">189&lt;/span>, &lt;span style="color:#ae81ff">1341&lt;/span>, &lt;span style="color:#ae81ff">1119&lt;/span>, &lt;span style="color:#ae81ff">3520&lt;/span>, &lt;span style="color:#ae81ff">1164&lt;/span>, &lt;span style="color:#ae81ff">1248&lt;/span>, &lt;span style="color:#ae81ff">6462&lt;/span>, &lt;span style="color:#ae81ff">117&lt;/span>, &lt;span style="color:#ae81ff">21902&lt;/span>, &lt;span style="color:#ae81ff">1643&lt;/span>, &lt;span style="color:#ae81ff">119&lt;/span>, &lt;span style="color:#ae81ff">102&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">101&lt;/span>, &lt;span style="color:#ae81ff">1327&lt;/span>, &lt;span style="color:#ae81ff">1164&lt;/span>, &lt;span style="color:#ae81ff">5450&lt;/span>, &lt;span style="color:#ae81ff">23434&lt;/span>, &lt;span style="color:#ae81ff">136&lt;/span>, &lt;span style="color:#ae81ff">102&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;token_type_ids&amp;#39;&lt;/span>: [[&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;attention_mask&amp;#39;&lt;/span>: [[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]]}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Truncation&lt;/strong>&lt;/p>
&lt;p>也是一种对齐的方式&lt;/p>
&lt;h3 id="113-模型-model">1.1.3 模型 Model&lt;/h3>
&lt;p>支持的模型很多，比较热门的预训练模型基本都有。学术界的很多模型也有，比如 I-BERT，RoBERTa&lt;/p>
&lt;h2 id="12-api">1.2 API&lt;/h2>
&lt;h3 id="121-from_pretrained">1.2.1 from_pretrained&lt;/h3>
&lt;p>功能：&lt;code>from_pretrained&lt;/code> 提供了模型类别判断，模型文件列表映射，模型文件下载及缓存，网络下载稳定性容错等功能。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Download from huggingface.co and cache&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> BertModel&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;bert-base-uncased&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model&lt;span style="color:#f92672">.&lt;/span>save_pretrained(&lt;span style="color:#e6db74">&amp;#39;./local_model_directory/&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Load from local&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> BertModel&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#39;./local_model_directory/&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>实例：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span>(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>exists(&lt;span style="color:#e6db74">&amp;#39;./model/&amp;#39;&lt;/span>&lt;span style="color:#f92672">+&lt;/span>args&lt;span style="color:#f92672">.&lt;/span>gpt2_model&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#e6db74">&amp;#39;pytorch_model.bin&amp;#39;&lt;/span>)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">.&lt;/span>GPT2ForSequenceClassification&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#39;./model/&amp;#39;&lt;/span>&lt;span style="color:#f92672">+&lt;/span>args&lt;span style="color:#f92672">.&lt;/span>gpt2_model)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model &lt;span style="color:#f92672">=&lt;/span> GPT2ForSequenceClassification&lt;span style="color:#f92672">.&lt;/span>from_pretrained(args&lt;span style="color:#f92672">.&lt;/span>gpt2_model)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_labels &lt;span style="color:#f92672">=&lt;/span> len(model&lt;span style="color:#f92672">.&lt;/span>config&lt;span style="color:#f92672">.&lt;/span>id2label)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model &lt;span style="color:#f92672">=&lt;/span> GPT2ForSequenceClassification&lt;span style="color:#f92672">.&lt;/span>from_pretrained(args&lt;span style="color:#f92672">.&lt;/span>gpt2_model, num_labels&lt;span style="color:#f92672">=&lt;/span>num_labels)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">.&lt;/span>save_pretrained(&lt;span style="color:#e6db74">&amp;#39;./model/&amp;#39;&lt;/span>&lt;span style="color:#f92672">+&lt;/span>args&lt;span style="color:#f92672">.&lt;/span>gpt2_model)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="13-fine-tune-a-pretrained-model">1.3 Fine-tune a pretrained model&lt;/h2>
&lt;p>可以用 1.1.2.4 中的 &lt;code>Trainer()&lt;/code> 来实现微调和训练，也可以在 pytorch 框架中实现。下面是步骤。&lt;/p>
&lt;h3 id="131-prepare-a-dataset">1.3.1 Prepare a dataset&lt;/h3>
&lt;p>比如，从 &lt;code>Yelp Reviews&lt;/code> 中 load 数据，然后进行预处理。下面的代码用到了 &lt;code>map()&lt;/code> 函数，写法比较陌生，不过这个过程是通用的。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># load&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datasets &lt;span style="color:#f92672">import&lt;/span> load_dataset
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(&lt;span style="color:#e6db74">&amp;#34;yelp_review_full&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset[&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>][&lt;span style="color:#ae81ff">100&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;text&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;My expectations for McDonalds are t rarely high....&amp;#39;&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># tokenizer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> AutoTokenizer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenizer &lt;span style="color:#f92672">=&lt;/span> AutoTokenizer&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;bert-base-cased&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">tokenize_function&lt;/span>(examples):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> tokenizer(examples[&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>], padding&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;max_length&amp;#34;&lt;/span>, truncation&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenized_datasets &lt;span style="color:#f92672">=&lt;/span> dataset&lt;span style="color:#f92672">.&lt;/span>map(tokenize_function, batched&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="132-train">1.3.2 Train&lt;/h3>
&lt;p>用 &lt;code>Trainer()&lt;/code> 训练在 1.1.2.4 中讲过了，讲一下用 native pytorch 训练，&lt;strong>Train in native PyTorch&lt;/strong>&lt;/p>
&lt;h4 id="1321-dataloader">1.3.2.1 DataLoader&lt;/h4>
&lt;p>为训练数据集和测试数据集创建一个 &lt;code>DataLoader&lt;/code>，以便可以遍历数据的 batch。给出 BERT 框架中的示例代码。变量 &lt;code>batch&lt;/code> 中就是一个 batch，经过 tokenizer 之后的数据。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> torch.utils.data &lt;span style="color:#f92672">import&lt;/span> (DataLoader, RandomSampler, SequentialSampler, TensorDataset)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_features &lt;span style="color:#f92672">=&lt;/span> get_train_features(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>data_dir,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>gpt2_model,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>max_seq_length,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>do_lower_case,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>local_rank,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>train_batch_size,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>gradient_accumulation_steps,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>num_train_epochs,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tokenizer,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> processor,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_data &lt;span style="color:#f92672">=&lt;/span> gen_tensor_dataset(train_features)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_dataloader &lt;span style="color:#f92672">=&lt;/span> DataLoader(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_data,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sampler&lt;span style="color:#f92672">=&lt;/span>train_sampler,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> batch_size&lt;span style="color:#f92672">=&lt;/span>args&lt;span style="color:#f92672">.&lt;/span>train_batch_size,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> e &lt;span style="color:#f92672">in&lt;/span> range(args&lt;span style="color:#f92672">.&lt;/span>num_train_epochs):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> step, batch &lt;span style="color:#f92672">in&lt;/span> enumerate(train_dataloader):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1322-optimizer-and-learning-rate-scheduler">1.3.2.2 Optimizer and learning rate scheduler&lt;/h4>
&lt;p>优化器根据模型来定义，要传入 learning rate 吗，代码示例：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>model, optimizer, scheduler &lt;span style="color:#f92672">=&lt;/span> init_optimizer_and_amp(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>learning_rate,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>loss_scale,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>warmup_proportion,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_train_optimization_steps,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args&lt;span style="color:#f92672">.&lt;/span>fp16,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">init_optimizer_and_amp&lt;/span>(model, learning_rate, loss_scale, warmup_proportion,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_train_optimization_steps, use_fp16):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> optimizer, scheduler &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>, &lt;span style="color:#66d9ef">None&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logger&lt;span style="color:#f92672">.&lt;/span>info(&lt;span style="color:#e6db74">&amp;#34;using fp32&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> num_train_optimization_steps &lt;span style="color:#f92672">is&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> optimizer &lt;span style="color:#f92672">=&lt;/span> BertAdam(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> optimizer_grouped_parameters,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lr&lt;span style="color:#f92672">=&lt;/span>learning_rate,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> warmup&lt;span style="color:#f92672">=&lt;/span>warmup_proportion,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t_total&lt;span style="color:#f92672">=&lt;/span>num_train_optimization_steps,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> model, optimizer, scheduler
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1323-training-loop">1.3.2.3 Training Loop&lt;/h4>
&lt;p>这个无需多说。设置好 epoch，每个 epoch 会过完训练数据集中的所有数据。（当然，也有随机抽样的形式）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>model&lt;span style="color:#f92672">.&lt;/span>train()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> e &lt;span style="color:#f92672">in&lt;/span> range(args&lt;span style="color:#f92672">.&lt;/span>num_train_epochs):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> step, batch &lt;span style="color:#f92672">in&lt;/span> enumerate(train_dataloader):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> batch &lt;span style="color:#f92672">=&lt;/span> tuple(t&lt;span style="color:#f92672">.&lt;/span>to(device) &lt;span style="color:#66d9ef">for&lt;/span> t &lt;span style="color:#f92672">in&lt;/span> batch)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_ids, input_mask, segment_ids, label_ids &lt;span style="color:#f92672">=&lt;/span> batch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># outputs = model(**batch)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputs &lt;span style="color:#f92672">=&lt;/span> model(input_ids&lt;span style="color:#f92672">=&lt;/span>input_ids, token_type_ids&lt;span style="color:#f92672">=&lt;/span>segment_ids, attention_mask&lt;span style="color:#f92672">=&lt;/span>input_mask, labels&lt;span style="color:#f92672">=&lt;/span>label_ids)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loss &lt;span style="color:#f92672">=&lt;/span> outputs&lt;span style="color:#f92672">.&lt;/span>loss
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loss&lt;span style="color:#f92672">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> optimizer&lt;span style="color:#f92672">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lr_scheduler&lt;span style="color:#f92672">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> optimizer&lt;span style="color:#f92672">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> progress_bar&lt;span style="color:#f92672">.&lt;/span>update(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1324-evaluate">1.3.2.4 Evaluate&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>model&lt;span style="color:#f92672">.&lt;/span>eval()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i, (input_ids, input_mask, segment_ids, label_ids) &lt;span style="color:#f92672">in&lt;/span> enumerate(eval_dataloader):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_ids &lt;span style="color:#f92672">=&lt;/span> input_ids&lt;span style="color:#f92672">.&lt;/span>to(device)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input_mask &lt;span style="color:#f92672">=&lt;/span> input_mask&lt;span style="color:#f92672">.&lt;/span>to(device)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> segment_ids &lt;span style="color:#f92672">=&lt;/span> segment_ids&lt;span style="color:#f92672">.&lt;/span>to(device)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> label_ids &lt;span style="color:#f92672">=&lt;/span> label_ids&lt;span style="color:#f92672">.&lt;/span>to(device)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># label_ids = label_ids.to(torch.float)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputs &lt;span style="color:#f92672">=&lt;/span> model(input_ids&lt;span style="color:#f92672">=&lt;/span>input_ids, token_type_ids&lt;span style="color:#f92672">=&lt;/span>segment_ids, attention_mask&lt;span style="color:#f92672">=&lt;/span>input_mask, labels&lt;span style="color:#f92672">=&lt;/span>label_ids)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logits &lt;span style="color:#f92672">=&lt;/span> outputs&lt;span style="color:#f92672">.&lt;/span>logits
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="14-accelerate">1.4 Accelerate&lt;/h2>
&lt;p>Easily rain and use PyTorch models with multi-GPU, TPU, mixed-precision&lt;/p>
&lt;h3 id="140-术语">1.4.0 术语&lt;/h3>
&lt;p>关于分布式的一些概念和术语。&lt;/p>
&lt;p>参考：&lt;/p>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/544273093">https://zhuanlan.zhihu.com/p/544273093&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.zhihu.com/question/453920336/answer/1828326535">https://www.zhihu.com/question/453920336/answer/1828326535&lt;/a>&lt;/p>
&lt;ul>
&lt;li>Scatter: 把数据分发到其他线程 or 进程&lt;/li>
&lt;li>Gather: 把数据从其他进程 or 线程中收集到一个主进程中&lt;/li>
&lt;li>Reduce: 计算在各个进程 or 线程中进行，然后归约到一个主进程中&lt;/li>
&lt;li>All-Reduce: 同 Reduce 一样，计算再各个进程 or 线程中进行，但是每个节点都一起归约，保持每个节点的结果一致&lt;/li>
&lt;li>Broadcast: 把数据复制到各个进程 or 线程&lt;/li>
&lt;li>All-Gather: 与 Gather 不同，每个进程 or 线程中完成数据的手机，保证每个节点的结果一致&lt;/li>
&lt;li>CLI (Command Line Interface)：一种通过命令行来交互的工具或者应用，比如 mkdir, cd, scp, npm 等&lt;/li>
&lt;li>Rank: 表示进程的编号/序号。（自己观察到一个 GPU 似乎对应一个 rank，不过 rank 和 GPU 没有严格的对应关系。如果是多进程共享 GPU，那么一个 GPU 可以为多个 rank 服务）&lt;/li>
&lt;li>Node: 物理节点，可以是一台机器或者一个容器，节点内可以有多个 GPU&lt;/li>
&lt;li>Rank 和 Local Rank: rank是指在整个分布式任务中进程的序号；local_rank是指在一个node上进程的相对序号，local_rank在node之间相互独立。&lt;/li>
&lt;li>nnodes、node_rank 与 nproc_per_node： nnodes是指物理节点数量，node_rank是物理节点的序号；nproc_per_node是指每个物理节点上面进程的数量。&lt;/li>
&lt;li>word size ： 全局（一个分布式任务）中，rank的数量。&lt;/li>
&lt;li>csrc: 应该是 C source code&lt;/li>
&lt;li>NVIDIA Megatron-LM: 针对Transformer类的模型提供半自动的分布式部署。&lt;/li>
&lt;li>DeepSpeed: 微软提供的一个开源深度学习训练优化库。基于英伟达 Megatron-LM 进行了张量切分式的模型并行。&lt;/li>
&lt;/ul>
&lt;p>同步 SGD：每个 Worker 都是同步计算一个批量。&lt;/p>
&lt;h3 id="141-分布式概念-distributed">1.4.1 分布式概念 Distributed&lt;/h3>
&lt;p>2022-10-24 10:43:08，日后填坑。&lt;/p>
&lt;p>2022-11-01 09:04:30，开始学习。&lt;/p>
&lt;p>&lt;code>nn.parallel.scatter(data, devices)&lt;/code>，可以将一组数据 split 到多个 devices 上&lt;/p>
&lt;h4 id="1411-dataparallel">1.4.1.1 DataParallel&lt;/h4>
&lt;p>&lt;code>nn.DataParallel(net, devices_ids=devices)&lt;/code>，DP 模型。单进程，多线程，适于一台机器的情况。&lt;/p>
&lt;p>做法是将 model 复制到不同的 GPU 上，各个 GPU 计算不同 batch 的数据。&lt;/p>
&lt;h4 id="1412-distributeddataparallel">1.4.1.2 DistributedDataParallel&lt;/h4>
&lt;p>&lt;code>torch.nn.parallel.DistributedDataParallel&lt;/code>，DDP 模型（PyTorch 官网更推荐）。&lt;/p>
&lt;p>需要启动 &lt;code>init_process_group&lt;/code>&lt;/p>
&lt;p>如果想在一个有 N 个 GPU 的设备上面使用 DistributedDataParallel，则需要 spawn up N 个进程，每个进程对应0-N-1 的一个 GPU。这可以通过下面的语句实现&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>torch&lt;span style="color:#f92672">.&lt;/span>cuda&lt;span style="color:#f92672">.&lt;/span>set_device(i)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># i from 0-N-1，每个进程中都需要：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>torch&lt;span style="color:#f92672">.&lt;/span>distributed&lt;span style="color:#f92672">.&lt;/span>init_process_group(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backend&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;nccl&amp;#39;&lt;/span>, world_size&lt;span style="color:#f92672">=&lt;/span>N, init_method&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;...&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> DistributedDataParallel(model, device_ids&lt;span style="color:#f92672">=&lt;/span>[i], output_device&lt;span style="color:#f92672">=&lt;/span>i)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 实践&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> args&lt;span style="color:#f92672">.&lt;/span>local_rank &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">or&lt;/span> args&lt;span style="color:#f92672">.&lt;/span>no_cuda:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> device &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>device(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;cuda&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>cuda&lt;span style="color:#f92672">.&lt;/span>is_available() &lt;span style="color:#f92672">and&lt;/span> &lt;span style="color:#f92672">not&lt;/span> args&lt;span style="color:#f92672">.&lt;/span>no_cuda &lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#e6db74">&amp;#34;cpu&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n_gpu &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>cuda&lt;span style="color:#f92672">.&lt;/span>device_count()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> torch&lt;span style="color:#f92672">.&lt;/span>cuda&lt;span style="color:#f92672">.&lt;/span>set_device(args&lt;span style="color:#f92672">.&lt;/span>local_rank)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> device &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>device(&lt;span style="color:#e6db74">&amp;#34;cuda&amp;#34;&lt;/span>, args&lt;span style="color:#f92672">.&lt;/span>local_rank)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n_gpu &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Initializes the distributed backend which will take care of&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># sychronizing nodes/GPUs.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>distributed&lt;span style="color:#f92672">.&lt;/span>is_initialized():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> torch&lt;span style="color:#f92672">.&lt;/span>distributed&lt;span style="color:#f92672">.&lt;/span>init_process_group(backend&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;nccl&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>多进程，适于多台机器的情况，可以结合模型并行的方法。&lt;/p>
&lt;p>使用时建议&lt;/p>
&lt;ul>
&lt;li>使用一个 big dataset&lt;/li>
&lt;li>好的 CPU-GPU 和机器-机器带宽&lt;/li>
&lt;li>高效的 data load 以及 preprocess&lt;/li>
&lt;li>模型需要有好的计算（FLOP）通讯（model size）比
&lt;ul>
&lt;li>Inception &amp;gt; ResNet &amp;gt; AlexNet&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>使用足够大的 batch size 来获取好的系统性能&lt;/li>
&lt;li>使用高效的优化算法对应大批量大小&lt;/li>
&lt;/ul>
&lt;h3 id="142-hugging-face-文档">1.4.2 Hugging face 文档&lt;/h3>
&lt;h4 id="1421-步骤">1.4.2.1 步骤&lt;/h4>
&lt;ul>
&lt;li>import Accelerator 并且实例化&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> accelerator &lt;span style="color:#f92672">import&lt;/span> Accelerator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>accelerator &lt;span style="color:#f92672">=&lt;/span> Accelerator()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>消去 model 以及 input data 的 &lt;code>.to(device)&lt;/code> 或者 &lt;code>.cuda()&lt;/code> 操作。&lt;code>accelerator&lt;/code> 会帮你完成这件事&lt;/li>
&lt;li>把相关的对象（optimizer, model, train_dataloader, lr_scheduler）传递给 &lt;code>prepare()&lt;/code> 方法&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>model, optimizer, train_dataloader, lr_scheduler &lt;span style="color:#f92672">=&lt;/span> accelerator&lt;span style="color:#f92672">.&lt;/span>prepare(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model, optimizer, train_dataloader, lr_scheduler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>每个 GPU 会加载 training dataset 中的不同部分（batch），这看起来像是数据并行。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>Replace the line &lt;code>loss.backward()&lt;/code> by &lt;code>accelerator.backward(loss)&lt;/code>.&lt;/li>
&lt;/ul>
&lt;h4 id="1422-distributed-evaluation">1.4.2.2 Distributed evaluation&lt;/h4>
&lt;p>如果需要分布式评估，同理，把 validation dataloader 发送给 &lt;code>prepare()&lt;/code> 方法。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>validation_dataloader &lt;span style="color:#f92672">=&lt;/span> accelerator&lt;span style="color:#f92672">.&lt;/span>prepare(validation_dataloader)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样的话每个 devices 只能看见 evaluation data 中的一部分，所以最后需要把结果 group 到一起，通过 &lt;code>gather_for_metrics()&lt;/code> 方法。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> inputs, targets &lt;span style="color:#f92672">in&lt;/span> validation_dataloader:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> predictions &lt;span style="color:#f92672">=&lt;/span> model(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Gather all predictions and targets&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> all_predictions, all_targets &lt;span style="color:#f92672">=&lt;/span> accelerator&lt;span style="color:#f92672">.&lt;/span>gather_for_metrics((predictions, targets))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Example of use with a *Datasets.Metric*&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metric&lt;span style="color:#f92672">.&lt;/span>add_batch(all_predictions, all_targets)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1423-launch">1.4.2.3 Launch&lt;/h4>
&lt;p>&lt;code>accelerate&lt;/code> 命令整合了在不同平台上发射脚本的命令，你无需自己记住所有命令。如果你自己熟悉 PyTorch 提供的发射脚本，也可以不使用 &lt;code>accelerate&lt;/code>。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 单 GPU 执行&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CUDA_VISIBLE_DEVICES&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span> accelerate launch &lt;span style="color:#f92672">{&lt;/span>script_name.py&lt;span style="color:#f92672">}&lt;/span> --arg1 --arg2 ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 默认参数，使用所有的 GPU，不启动混合精度&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>accelerate launch --multi_gpu &lt;span style="color:#f92672">{&lt;/span>script_name.py&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">{&lt;/span>--arg1&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">{&lt;/span>--arg2&lt;span style="color:#f92672">}&lt;/span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 当然，也可以指定参数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>accelerate launch --multi_gpu --mixed_precision&lt;span style="color:#f92672">=&lt;/span>fp16 --num_processes&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#f92672">{&lt;/span>script_name.py&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">{&lt;/span>--arg1&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">{&lt;/span>--arg2&lt;span style="color:#f92672">}&lt;/span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 查看所有参数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>accelerate launch -h
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>accelerate config&lt;/strong>&lt;/p>
&lt;p>当然，更好的方式是配置一个 config 文件。使用了 &lt;code>accelerate config&lt;/code> 之后，会在 &lt;code>~/.cache/huggingface/accelerate&lt;/code> 目录下生成 &lt;code>default_config.yaml&lt;/code> 文件。也可以自己定制 config 文件然后读取。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>accelerate launch --config_file ~/.cache/huggingface/accelerate &lt;span style="color:#f92672">{&lt;/span>script_name.py&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">{&lt;/span>--arg1&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">{&lt;/span>--arg2&lt;span style="color:#f92672">}&lt;/span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="15-dataset">1.5 Dataset&lt;/h2>
&lt;h3 id="151-load-from-hugging-face">1.5.1 load from hugging face&lt;/h3>
&lt;p>hugging face 下载文件存储的位置：&lt;code>~/.cache/huggingface&lt;/code>&lt;/p>
&lt;p>找到 dataset 之后如何下载：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 搜索到数据集 oscar，里面有很多 subset，比如：unshuffled_deduplicated_en, unshuffled_deduplicated_br&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 第一个参数是数据集的名称，第二个参数用于索引子集，一般还有 split 参数：train, test, validation &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datasets &lt;span style="color:#f92672">import&lt;/span> load_dataset
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(path&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;oscar&amp;#34;&lt;/span>, name&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;unshuffled_deduplicated_en&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 420G，赶紧中断&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset&lt;span style="color:#f92672">.&lt;/span>save_to_disk(&lt;span style="color:#e6db74">&amp;#34;./glue/&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 尝试下载 wikitext&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(path&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;wikitext&amp;#34;&lt;/span>, name&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;wikitext-103-v1&amp;#34;&lt;/span>, split&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 2022-10-24 14:07:31，是可以的&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(dataset[:&lt;span style="color:#ae81ff">3&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{&lt;span style="color:#e6db74">&amp;#39;text&amp;#39;&lt;/span>: [&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39; = Valkyria Chronicles III = &lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>]}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 保存&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset&lt;span style="color:#f92672">.&lt;/span>save_to_disk(&lt;span style="color:#e6db74">&amp;#34;./&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="152-数据集格式">1.5.2 数据集格式&lt;/h3>
&lt;p>1.5.1 的例子中，默认保存为 &lt;code>dataset.arrow&lt;/code> 加上 &lt;code>.json&lt;/code> 文件。&lt;/p>
&lt;p>现在我们想将其保存为 &lt;code>.csv&lt;/code>&lt;/p>
&lt;h3 id="153-split-作用">1.5.3 split 作用&lt;/h3>
&lt;p>下面是带有 feature 的 dataset 一个示例&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datasets &lt;span style="color:#f92672">import&lt;/span> load_dataset
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 如果用了 split &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(&lt;span style="color:#e6db74">&amp;#34;rotten_tomatoes&amp;#34;&lt;/span>, split&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(dataset)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Dataset({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> features: [&lt;span style="color:#e6db74">&amp;#39;text&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_rows: &lt;span style="color:#ae81ff">8530&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 如果不用 split，&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(&lt;span style="color:#e6db74">&amp;#34;rotten_tomatoes&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>DatasetDict({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train: Dataset({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> features: [&lt;span style="color:#e6db74">&amp;#39;text&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_rows: &lt;span style="color:#ae81ff">8530&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> })
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> validation: Dataset({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> features: [&lt;span style="color:#e6db74">&amp;#39;text&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_rows: &lt;span style="color:#ae81ff">1066&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> })
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> test: Dataset({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> features: [&lt;span style="color:#e6db74">&amp;#39;text&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_rows: &lt;span style="color:#ae81ff">1066&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> })
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="16-github-文档">1.6 Github 文档&lt;/h2>
&lt;p>所有任务的 example 存放在 &lt;a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch">https://github.com/huggingface/transformers/tree/main/examples/pytorch&lt;/a> 里面。&lt;/p>
&lt;h1 id="2-知识补充">2. 知识补充&lt;/h1>
&lt;p>补充一些相关的，之前不熟悉的概念。&lt;/p>
&lt;h2 id="22-data-set">2.2 Data Set&lt;/h2>
&lt;h3 id="221-glue">2.2.1 GLUE&lt;/h3>
&lt;p>数据集是之前屏蔽的一个部分，但是如果想了解模型是在做什么，并且要动手做实验，必须了解数据集。&lt;/p>
&lt;p>GLUE 是学术界非常常用的数据集。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>数据集&lt;/th>
&lt;th>类型&lt;/th>
&lt;th>描述&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>MNLI&lt;/td>
&lt;td>句子对分类任务&lt;/td>
&lt;td>给定一个前提 (Premise) ，根据这个前提去推断假设 (Hypothesis) 与前提的关系。该任务的关系分为三种，蕴含关系 (Entailment)、矛盾关系 (Contradiction) 以及中立关系 (Neutral)。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>QQP&lt;/td>
&lt;td>句子对分类任务&lt;/td>
&lt;td>判断 Quora 上的两个问题句是否表示的是一样的意思&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SST-2&lt;/td>
&lt;td>分类任务&lt;/td>
&lt;td>情感分析&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CoLA&lt;/td>
&lt;td>单句分类任务&lt;/td>
&lt;td>句子语义判断，是否是可接受的（Acceptable）&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>QNLI&lt;/td>
&lt;td>&lt;/td>
&lt;td>用于判断文本是否包含问题的答案&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>STS-B&lt;/td>
&lt;td>&lt;/td>
&lt;td>预测两个句子的相似性，包括5个级别。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MRPC&lt;/td>
&lt;td>句子对分类任务&lt;/td>
&lt;td>也是判断两个句子是否是等价的。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>RTE&lt;/td>
&lt;td>分类&lt;/td>
&lt;td>类似于MNLI，但是只是对蕴含关系的二分类判断，而且数据集更小。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SWAG&lt;/td>
&lt;td>&lt;/td>
&lt;td>从四个句子中选择为可能为前句下文的那个&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="3-编程实例">3. 编程实例&lt;/h1>
&lt;h2 id="31-通用知识">3.1 通用知识&lt;/h2>
&lt;h3 id="311-主要的组件">3.1.1 主要的组件&lt;/h3>
&lt;ul>
&lt;li>Configuration: 编程模型中的参数或是变量。用于配置词表大小，隐藏层维数，Dropout rate 等等。给出一个 BERT_base 配置的示例。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;attention_probs_dropout_prob&amp;#34;&lt;/span>: 0.1,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;hidden_act&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;gelu&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;hidden_dropout_prob&amp;#34;&lt;/span>: 0.1,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;hidden_size&amp;#34;&lt;/span>: 768,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;initializer_range&amp;#34;&lt;/span>: 0.02,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;intermediate_size&amp;#34;&lt;/span>: 3072,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;max_position_embeddings&amp;#34;&lt;/span>: 512,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;num_attention_heads&amp;#34;&lt;/span>: 12,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;num_hidden_layers&amp;#34;&lt;/span>: 12,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;type_vocab_size&amp;#34;&lt;/span>: 2,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;vocab_size&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">30522&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>Tokenizer: 每个模型都有对应的分词器。存储 token 到 index 的映射。&lt;/li>
&lt;li>Model: 实现模型的计算图和编码过程，实现前向传播。对于 output 层，不同的模型有不一样的封装。比如今天（2022-10-23）debug 观察的 &lt;code>BaseModelOutputWithPoolingAndCrossAttentions&lt;/code>，&lt;code>类型：SequenceClassifierOutput&lt;/code> 等等。&lt;/li>
&lt;/ul>
&lt;h3 id="312-任务分类">3.1.2 任务分类&lt;/h3>
&lt;p>语言生成任务，对应模型：GPT，GPT-2，XLNet&lt;/p>
&lt;p>语言理解任务，对应模型：BERT，RoBERTa，XLM&lt;/p>
&lt;h2 id="32-在-gpt-2-上运行-wikitext">3.2 在 GPT-2 上运行 wikitext&lt;/h2>
&lt;p>README：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>pip install transformers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ln -s ../BERT/glue/ ./glue
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="301-坑1">3.0.1 坑1&lt;/h3>
&lt;p>&lt;strong>坑，和 BERT 区分&lt;/strong>&lt;/p>
&lt;p>BERT forward 和 GPT-2 forward 不一样。之前实现的 &lt;code>model(inputs_id, token_type_ids, attention_mask)&lt;/code> 按位置传参，但是 GPT-2 forward 第二个参数是 &lt;code>past_key_values&lt;/code>，所以报错，按关键字传参即可解决这个问题。&lt;/p>
&lt;p>他们经过前向之后，output 也不一样。&lt;/p>
&lt;h3 id="302-大坑2">3.0.2 大坑2&lt;/h3>
&lt;p>2022-10-26 22:31:46，复现 GPT 的结果出了大问题，好在今晚解决了。问题来源于框架中会自动启动分布式 train/eval，但是没有很好地支持分布式（单 GPU 运行 30s，4 GPU 运行 6min），而且 loss 的处理也有问题，导致最终的 metric - PPL 出了问题。用单 GPU 可以解决这个问题。&lt;/p>
&lt;h3 id="303-坑3">3.0.3 坑3&lt;/h3>
&lt;p>2022-10-28 16:03:02，框架K 是不支持分布式的，这导致了 local_rank 索引不到，因此执行 evaluate()，进入 quant 模块时报错。&lt;/p>
&lt;h3 id="321-prepare-dataset">3.2.1 Prepare Dataset&lt;/h3>
&lt;p>读取 datasets 并保存到本地&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datasets &lt;span style="color:#f92672">import&lt;/span> load_dataset
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_dataset &lt;span style="color:#f92672">=&lt;/span> load_dataset(&lt;span style="color:#e6db74">&amp;#34;json&amp;#34;&lt;/span>, data_files&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;test.json&amp;#34;&lt;/span>, split&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_dataset&lt;span style="color:#f92672">.&lt;/span>save_to_disk(&lt;span style="color:#e6db74">&amp;#34;test.hf&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="322-lm-预处理">3.2.2 LM 预处理&lt;/h3>
&lt;p>针对生成类模型的预处理。如何从原始的数据集生成 tokenizer 之后的数据。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>row_datasets &lt;span style="color:#f92672">=&lt;/span> load_dataset(data_args&lt;span style="color:#f92672">.&lt;/span>dataset_name, data_args&lt;span style="color:#f92672">.&lt;/span>dataset_config_name, cache_dir&lt;span style="color:#f92672">=&lt;/span>model_args&lt;span style="color:#f92672">.&lt;/span>cache_dir)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># tokenizer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenized_datasets &lt;span style="color:#f92672">=&lt;/span> raw_datasets&lt;span style="color:#f92672">.&lt;/span>map(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tokenize_function,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> batched&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_proc&lt;span style="color:#f92672">=&lt;/span>data_args&lt;span style="color:#f92672">.&lt;/span>preprocessing_num_workers,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> remove_columns&lt;span style="color:#f92672">=&lt;/span>column_names,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> load_from_cache_file&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#f92672">not&lt;/span> data_args&lt;span style="color:#f92672">.&lt;/span>overwrite_cache,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> desc&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Running tokenizer on dataset&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> training_args&lt;span style="color:#f92672">.&lt;/span>main_process_first(desc&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;grouping texts together&amp;#34;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lm_datasets &lt;span style="color:#f92672">=&lt;/span> tokenized_datasets&lt;span style="color:#f92672">.&lt;/span>map(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> group_texts,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> batched&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_proc&lt;span style="color:#f92672">=&lt;/span>data_args&lt;span style="color:#f92672">.&lt;/span>preprocessing_num_workers,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> load_from_cache_file&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#f92672">not&lt;/span> data_args&lt;span style="color:#f92672">.&lt;/span>overwrite_cache,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> desc&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Grouping texts in chunks of &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>block_size&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 计算 token 长度&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> split, data &lt;span style="color:#f92672">in&lt;/span> lm_datasets&lt;span style="color:#f92672">.&lt;/span>items():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total_eval_tokens &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> chunk &lt;span style="color:#f92672">in&lt;/span> data[&lt;span style="color:#e6db74">&amp;#39;labels&amp;#39;&lt;/span>]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> total_eval_tokens &lt;span style="color:#f92672">+=&lt;/span> len([x &lt;span style="color:#66d9ef">for&lt;/span> x &lt;span style="color:#f92672">in&lt;/span> chunk[&lt;span style="color:#ae81ff">1&lt;/span>:] &lt;span style="color:#66d9ef">if&lt;/span> x &lt;span style="color:#f92672">!=&lt;/span> padding_index])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>logger&lt;span style="color:#f92672">.&lt;/span>info(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;[&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>split&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">] Total eval tokens: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>total_eval_tokens&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 得到 eval dataset 以及 train dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> training_args&lt;span style="color:#f92672">.&lt;/span>do_train:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#f92672">in&lt;/span> tokenized_datasets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span> &lt;span style="color:#a6e22e">ValueError&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;--do_train requires a train dataset&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_dataset &lt;span style="color:#f92672">=&lt;/span> lm_datasets[&lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> data_args&lt;span style="color:#f92672">.&lt;/span>max_train_samples &lt;span style="color:#f92672">is&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_dataset &lt;span style="color:#f92672">=&lt;/span> train_dataset&lt;span style="color:#f92672">.&lt;/span>select(range(data_args&lt;span style="color:#f92672">.&lt;/span>max_train_samples))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> training_args&lt;span style="color:#f92672">.&lt;/span>do_eval:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#e6db74">&amp;#34;validation&amp;#34;&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#f92672">in&lt;/span> tokenized_datasets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span> &lt;span style="color:#a6e22e">ValueError&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;--do_eval requires a validation dataset&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> eval_dataset &lt;span style="color:#f92672">=&lt;/span> lm_datasets[data_args&lt;span style="color:#f92672">.&lt;/span>eval_subset]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> data_args&lt;span style="color:#f92672">.&lt;/span>max_eval_samples &lt;span style="color:#f92672">is&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> eval_dataset &lt;span style="color:#f92672">=&lt;/span> eval_dataset&lt;span style="color:#f92672">.&lt;/span>select(range(data_args&lt;span style="color:#f92672">.&lt;/span>max_eval_samples))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 这个时候 eval_dataset size (480, 3)，3 个维度分别是 input_ids, attention_mask, labels&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="33-在-t5-上运行-wmt">3.3 在 T5 上运行 WMT&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>MODEL&lt;span style="color:#f92672">=&lt;/span>t5-small
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CUDA_VISIBLE_DEVICES&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span> python -u run_translation.py &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --model_name_or_path &lt;span style="color:#e6db74">${&lt;/span>MODEL&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --dataset_name wmt16 --dataset_config_name ro-en &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --per_device_eval_batch_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --output_dir checkpoints-translation/&lt;span style="color:#e6db74">${&lt;/span>MODEL&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --source_lang en --target_lang ro &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --do_eval &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --predict_with_generate &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --source_prefix &lt;span style="color:#e6db74">&amp;#34;translate English to Romanian: &amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="4-编程-flow">4. 编程 flow&lt;/h1>
&lt;p>利用 debug 以及 hugging face 文档，了解整个流程。在 Section 1 介绍 hugging face 指导文档，这部分结合实际编程来看。&lt;/p>
&lt;h2 id="41-数据读取及预处理">4.1 数据读取及预处理&lt;/h2>
&lt;h3 id="421-数据读取">4.2.1 数据读取&lt;/h3>
&lt;p>通过参数 &lt;code>--data_dir&lt;/code>，把本地的数据加载进来，应该包含 &lt;code>.tsv&lt;/code> 文件。hugging face 的预训练模型可以下载到本地并保存，那么 Dataset 应该也可以。&lt;/p>
&lt;h3 id="422-dataloader">4.2.2 DataLoader&lt;/h3>
&lt;p>经过处理后的 &lt;code>train_features&lt;/code>，长度是 8551 examples，装的是经过 tokenizer 后的数据。&lt;/p>
&lt;p>原始的 &lt;code>train_example&lt;/code>，从 &lt;code>./glue/CoLA/train.tsv&lt;/code> 读入，长度是 8551 examples，每个 example 装的是：&lt;/p>
&lt;ul>
&lt;li>&lt;code>guid&lt;/code>:&lt;code>train-1&lt;/code> or &lt;code>train=2&lt;/code>&amp;hellip;&lt;/li>
&lt;li>&lt;code>label&lt;/code>:&lt;code>1&lt;/code> or &lt;code>0&lt;/code>&lt;/li>
&lt;li>&lt;code>text_a&lt;/code>:&lt;code>Our friends won't buy this analysis...&lt;/code>&lt;/li>
&lt;li>&lt;code>text_b&lt;/code>:None&lt;/li>
&lt;/ul>
&lt;p>&lt;code>train_data&lt;/code> 就是通过 &lt;code>gen_tensor_dataset()&lt;/code> 把 &lt;code>train_features&lt;/code> 转换为 tensor；经过 &lt;code>DataLoader(train_data, sampler, batch_size)&lt;/code> 方法之后，得到 &lt;code>train_dataloader&lt;/code>，&lt;code>sampler&lt;/code> 就是 8551。&lt;/p>
&lt;p>在一个 epoch 中，需要遍历一遍整个 train_dataloader，一个 iteration 处理其中一个 batch，train_loader 遍历完就是一个 epoch。&lt;/p>
&lt;blockquote>
&lt;p>记得数据需要转移到 device&lt;/p>
&lt;/blockquote>
&lt;h3 id="42x-tokenizer">4.2.X Tokenizer&lt;/h3>
&lt;p>&lt;code>input_ids&lt;/code> 存放的就是 tokenizer 后的数据本身，是一个 (64, 128) 的 tensor。&lt;code>mask&lt;/code>, &lt;code>segment_id&lt;/code> 也是 (64, 128)，label 是 (64)，这应该就是最后的分类，因为 batch size 是 64，所以有 64 个输出。&lt;/p>
&lt;p>对于 hugging face BERT，经过 tokenizer 打印出来就是一整个 mapping，也就是对应 &lt;code>run_glue.py&lt;/code> 中遍历 &lt;code>train_dataloader&lt;/code> 的变量 &lt;code>batch&lt;/code>。不过 &lt;code>batch&lt;/code> 的类型是 list，而下面的 &lt;code>inputs&lt;/code> 是 dict。而 hugging face BERT 的 &lt;code>output&lt;/code> 也是一个 &lt;code>BaseModelOutputWithPoolingAndCrossAttentions&lt;/code> 类型。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> BertTokenizer, BertModel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenizer &lt;span style="color:#f92672">=&lt;/span> BertTokenizer&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;bert-base-uncased&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> BertModel&lt;span style="color:#f92672">.&lt;/span>from_pretrained(&lt;span style="color:#e6db74">&amp;#34;bert-base-uncased&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>inputs &lt;span style="color:#f92672">=&lt;/span> tokenizer(&lt;span style="color:#e6db74">&amp;#34;Hello, my dog is cute&amp;#34;&lt;/span>, return_tensors&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;pt&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{&lt;span style="color:#e6db74">&amp;#39;input_ids&amp;#39;&lt;/span>: tensor([[ &lt;span style="color:#ae81ff">101&lt;/span>, &lt;span style="color:#ae81ff">7592&lt;/span>, &lt;span style="color:#ae81ff">1010&lt;/span>, &lt;span style="color:#ae81ff">2026&lt;/span>, &lt;span style="color:#ae81ff">3899&lt;/span>, &lt;span style="color:#ae81ff">2003&lt;/span>, &lt;span style="color:#ae81ff">10140&lt;/span>, &lt;span style="color:#ae81ff">102&lt;/span>]]), &lt;span style="color:#e6db74">&amp;#39;token_type_ids&amp;#39;&lt;/span>: tensor([[&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]]), &lt;span style="color:#e6db74">&amp;#39;attention_mask&amp;#39;&lt;/span>: tensor([[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>]])}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>outputs &lt;span style="color:#f92672">=&lt;/span> model(&lt;span style="color:#f92672">**&lt;/span>inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># output 输出包含 last_hidden_state, pooler_output，其他属性 hidden_states, past_key_values, attentions, cross_attentions 为 None&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于 hugging face BertForSequenceClassification，&lt;/p>
&lt;ul>
&lt;li>&lt;code>output&lt;/code> 类型：SequenceClassifierOutput(loss=None, logits=tensor([[-2.2095, 2.5760]]), hidden_states=None, attentions=None)&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="43-计算-loss">4.3 计算 loss&lt;/h2>
&lt;p>hugging face 有一个普通 trainer 的实例，关于如何计算 loss。看一下能不能套用到原先 BERT 的框架中。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> torch &lt;span style="color:#f92672">import&lt;/span> nn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> transformers &lt;span style="color:#f92672">import&lt;/span> Trainer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">CustomTrainer&lt;/span>(Trainer):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">compute_loss&lt;/span>(self, model, inputs, return_outputs&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels &lt;span style="color:#f92672">=&lt;/span> inputs&lt;span style="color:#f92672">.&lt;/span>get(&lt;span style="color:#e6db74">&amp;#34;labels&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># forward pass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputs &lt;span style="color:#f92672">=&lt;/span> model(&lt;span style="color:#f92672">**&lt;/span>inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logits &lt;span style="color:#f92672">=&lt;/span> outputs&lt;span style="color:#f92672">.&lt;/span>get(&lt;span style="color:#e6db74">&amp;#34;logits&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># compute custom loss (suppose one has 3 labels with different weights)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loss_fct &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>CrossEntropyLoss(weight&lt;span style="color:#f92672">=&lt;/span>torch&lt;span style="color:#f92672">.&lt;/span>tensor([&lt;span style="color:#ae81ff">1.0&lt;/span>, &lt;span style="color:#ae81ff">2.0&lt;/span>, &lt;span style="color:#ae81ff">3.0&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loss &lt;span style="color:#f92672">=&lt;/span> loss_fct(logits&lt;span style="color:#f92672">.&lt;/span>view(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, self&lt;span style="color:#f92672">.&lt;/span>model&lt;span style="color:#f92672">.&lt;/span>config&lt;span style="color:#f92672">.&lt;/span>num_labels), labels&lt;span style="color:#f92672">.&lt;/span>view(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (loss, outputs) &lt;span style="color:#66d9ef">if&lt;/span> return_outputs &lt;span style="color:#66d9ef">else&lt;/span> loss
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>2022-10-23 18:32:34，直接用 forward 函数中计算的 loss&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>label_ids &lt;span style="color:#f92672">=&lt;/span> label_ids&lt;span style="color:#f92672">.&lt;/span>to(torch&lt;span style="color:#f92672">.&lt;/span>float)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>outputs &lt;span style="color:#f92672">=&lt;/span> model(input_ids&lt;span style="color:#f92672">=&lt;/span>input_ids, token_type_ids&lt;span style="color:#f92672">=&lt;/span>segment_ids, attention_mask&lt;span style="color:#f92672">=&lt;/span>input_mask, labels&lt;span style="color:#f92672">=&lt;/span>label_ids)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>logits &lt;span style="color:#f92672">=&lt;/span> outputs&lt;span style="color:#f92672">.&lt;/span>logits
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#f92672">=&lt;/span> outputs&lt;span style="color:#f92672">.&lt;/span>loss
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意，对于 &lt;code>single_label_classification&lt;/code> 分类任务，不要将 &lt;code>label_ids&lt;/code> 转化成 int。&lt;/p>
&lt;h1 id="5-理解">5. 理解&lt;/h1>
&lt;h2 id="51-深度学习研究者在做什么">5.1 深度学习研究者在做什么&lt;/h2>
&lt;p>转载自 &lt;a href="https://www.zhihu.com/question/433274875/answer/2240764095">https://www.zhihu.com/question/433274875/answer/2240764095&lt;/a>&lt;/p>
&lt;p>以下阶段层层递进&lt;/p>
&lt;ul>
&lt;li>把已有的开源模型下载下来，换成自己的数据集。这个时候应该是偏向于应用型研究，把动物图像数据集换成自己领域的，医学图像数据集，并且跑出 SOTA 的准确率。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>这个过程要求看懂开源的代码架构，loss, optimizer, 基本的前向反向传播应该无需修改，但是需要了解数据的预处理，输入的数据是什么样的，如何进行数据转换，数据集从哪里下载，用哪个函数 load data。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>从理论上理解模型的一些算法和思想，知道一些重要的超参数背后的思想。有信心调整它，并符合自己预期的效果&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>最显然的，learning rate, batch size，又比如量化时的 scale factor 搜索范围&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>深入了解模型的代码实现和细节，能够为模型添加一些主流的，提升性能的 module 或者 trick；能够分析修改前后，模型的差异；对模型的推理和训练过程了如指掌&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>比如分析推理时某个 epoch 的激活分布情况，分布出现了什么问题，如何解决，loss 变化有什么问题等等&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>能够根据自己的业务需求，拓展模型的功能，让模型能做更多的事情&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>这个可能更多体现在业务需求层面，如何去部署公司需要的模型。不过我认为做了量化框架的拓展，也达到这个水平了。&lt;/p>
&lt;/blockquote>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/120315111">https://zhuanlan.zhihu.com/p/120315111&lt;/a>&lt;/p></description></item><item><title>（转载）Having Effective Meetings Between Advisors and Students</title><link>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_having-effective-meetings-between-advisors-and-students/</link><pubDate>Mon, 26 Sep 2022 02:42:41 +0800</pubDate><guid>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_having-effective-meetings-between-advisors-and-students/</guid><description>&lt;blockquote>
&lt;p>Title: Having Effective Meetings Between Advisors and Students
by Mingyu Gao on Nov 2, 2020 | Tags: Academia, Advice, Students&lt;/p>
&lt;/blockquote>
&lt;p>原文链接：https://www.sigarch.org/having-effective-meetings-between-advisors-and-students/#undefined&lt;/p>
&lt;p>来自高鸣宇老师在 sigarch 上发表的博客，以下是翻译：&lt;/p>
&lt;p>导师和学生之间的有效合作和交流是学术成功的关键。不幸的是，在大多数情况下，导师只能提供一周一次或者两周一次，而非日常的一对一 meeting。这意味着学生一个月也无法和导师交流几次。因此如何优化会议，实现学生和导师之间的有效交流就很值得思考。&lt;/p>
&lt;p>实际上，对我来说现在有很多重要的课题。过去一年半内，我们组扩张到了 8 位研究生（包括下一年即将入学的学生）和一些本科生，以及 gap-year 实习生。几乎每个人都有自己的独立课题，需要时间开会和讨论。每周都会有这样的一次会议，每次会议的时间限制在 30-45 分钟。在这种情况下，交流的有效性十分重要。&lt;/p>
&lt;p>我站在导师和学生这两个角色的视角思考了这件事，我会基于最近的经验分享一些建议，希望这个一手的建议对于新的研究生和导师有用。&lt;/p>
&lt;h1 id="1-在开始的时候建立合适的风格">1. 在开始的时候建立合适的风格&lt;/h1>
&lt;p>在给出具体的建议之前，我想强调每个人有不同的偏好和工作风格。下面的建议不适用于所有人。因此了解彼此是很重要的，在师生关系开始的时候设置好清晰的期望。比如，学生可能会想知道导师的风格是怎样的，项目的里程碑和论文 deadline 可以预见一年内的节奏。导师也需要认知到学生有多独立，学生一周会在哪些时候工作，会工作多久。直接对话并不是一个坏主意，而不是一直观察并且慢慢适应。&lt;/p>
&lt;blockquote>
&lt;p>这个可以理解为前期的沟通，这也十分重要。适应彼此的节奏。&lt;/p>
&lt;/blockquote>
&lt;h1 id="2-专注于长期路线图和脚下的路">2. 专注于长期路线图和脚下的路&lt;/h1>
&lt;p>很多低年级学生喜欢准备很长很细节的进展报告，描述他们上周做过的所有事情。因为他们担心到时会觉得他们做的太少了。我认为这是不够的。为了从宝贵的时间中获得更多的信息，学生应该 &lt;strong>花更多的时间来寻求他们下一步应该做什么的建议&lt;/strong>。&lt;/p>
&lt;blockquote>
&lt;p>我完全同意这一点，实际上我在 meeting 的早期也是这么做的。描述了一些工作，询问下一步应该做 A 好一点还是做 B 好一点。但是有的时候投入的时间不足，自己都没怎么思考，也没什么进度，那肯定也就没有 &lt;strong>带着问题&lt;/strong> 去开会。这样的话可能只会觉得水过去就好了，浪费了宝贵的开会时间。&lt;/p>
&lt;/blockquote>
&lt;p>这是从导师那里学习如何思考研究问题，以及在 high level 审视项目的时间。更好的方法是学生简单地总结 &lt;strong>where they are now in the overall plan&lt;/strong>，以及 &lt;strong>接下来的计划是什么&lt;/strong>。之后导师可以开始提供评论和建议。&lt;/p>
&lt;blockquote>
&lt;p>我认为之前有过简单的总结，但是缺少一个 overall 的整理，确实，我们需要先总结之前工作的结论，然后总结目前推进到了哪一步，对于整体进度到了哪一步，然后再阐述接下来的计划。&lt;/p>
&lt;/blockquote>
&lt;p>有两种形式的讨论比较通用。在项目早期，快速地根据精炼的总结，和 high level 的预期来建立 &lt;strong>overall research roadmap&lt;/strong> 是非常重要的。低年级学生可能会提出一个有前途的想法，但是通常不会预见所有的设计问题和全部潜力。导师有助于彻底地分析挑战和机会，更好地找到期望的关键贡献。在投入阶段，应该把更多的时间花在 &lt;strong>immediate next steps&lt;/strong>，也就是下周应该关注什么。比如诸多事情里面优先级最高的，如何调整以处理实验中不好的结果，为了让这个工作更完整还需要补充什么探索。&lt;/p>
&lt;p>在这样的会议之后，学生对于接下来做什么应该有清晰的蓝图，不管是对于最终的文章，还是对于下次会议前的工作。在会议之后总结一个 to do list 总是有所帮助的，它可以作为便于查询的一次记录，下次会议之前也可以检查进度。&lt;/p>
&lt;h1 id="3-在线下写作中保存细节">3. 在线下写作中保存细节&lt;/h1>
&lt;p>如果会议都是关于 high level 的想法，我们什么时候应该讨论同样重要的底层细节，例如定理证明、模型细节、工作进展描述和具体案例研究？我的建议是把他们全部保存下来。换句话说，学生应该 &lt;strong>write detailed and comprehensive documents&lt;/strong>，包括这次会议中所有重要的，支撑 high level 观点的细节。导师可以在会议前后查阅这份文档。&lt;/p>
&lt;p>我想强调的是这份文章需要 &lt;strong>尽可能地详细&lt;/strong>，这个和仅仅总结要点的，简明的会议 slide 不同。一眼看上去，这似乎非常低效，因为写作是非常耗时的。但是相比其优点，这都是值得的。&lt;/p>
&lt;blockquote>
&lt;p>目前参与了接近 3 个月 intern，在其中几次会议时会记下很多东西和细节，但是在过去一两个月之后，很多东西已经忘记了。一个研究项目的周期是很长的，因此这件事情确实也是有必要做的。&lt;/p>
&lt;/blockquote>
&lt;p>首先，当你开始写下这件事情的时候，作为学生，有机会组织整个 idea，回顾整个设计。有些时候总是会忘记一些事情，除非把他们都写下来，并且详尽地检查。其次，对老师来说，可以用充足的，线下的时间来仔细地浏览所有细节，而不是在背靠背的会议上，顶着紧凑的时间压力来做这些事情。第三点，对学生来说也是练习写作的好机会。如果你发现难以用文字清晰地解释完整的设计细节，总是将通过直接交谈来表达，那你应该记住，你是没有机会和文章审稿人交谈的。最后，这些内部文档的段落和图片很可能被重复使用，或者直接拷贝到最终的文章中。总之，你的时间没有被浪费。&lt;/p>
&lt;blockquote>
&lt;p>不知道有哪种工具适于这种 &lt;strong>内部文档&lt;/strong>，这个听起来是一个大家都能看到的，前期的 paper manuscript，应该有详细的图片和阐述。格式可能都接近于 paper 了，这个倒是可以请教一下老师们。
2023-03-21 11:15:15，谷歌文档和腾讯文档应该都能做&lt;/p>
&lt;/blockquote>
&lt;h1 id="4-学会做深度的分析">4. 学会做深度的分析&lt;/h1>
&lt;p>学生应该掌握的另一个技能是自己处理简单的问题，节约会议的时间，用这个时间来解决更重要和更困难的问题。这意味着学生应该学习如何独立地进行深度分析，以解决遇到的问题，或者至少收集足够的数据细节和证据，用于下一次会议的讨论。&lt;/p>
&lt;p>一个例子是，当实验结果和初试期望不符时。与其等到下一次会议才报告给导师，不如通过分析数据主动找出合理的原因。一个技巧是 &lt;strong>zoom in to the next level of details&lt;/strong>，或者 &lt;strong>always measure one level deeper&lt;/strong>。例如，当网络数据包的时延呈现长尾（long tail）时，可以在 tail 中选择几个有代表性的数据包，检查它们的路由是否规律（从所有数据包进入到单个数据包），或者检查它们是否存在沿这些路径的常见热点（hotspot）（从整个路径（routes）进入到单个链接（link））。&lt;/p>
&lt;blockquote>
&lt;p>首先，道理就是很简单的要自己主动。但是行动起来并不容易。并且，这并不是一个简单的按钮，“行动”或者“不行动”，通常，人会在几种状态中切换。有的时候是不想去推进这个课题，由于遇到了一些阻力，可能是没有找到充足的论文支撑，可能是受到了导师的批评，可能是 peer pressure，可能是审稿人的质疑，可能是程序的 bug。这是一个螺旋推进的过程，要不断地调整自己的状态，周期性地审视。&lt;/p>
&lt;p>根据高老师举的例子，理解为做更加底层/细粒度的分析。&lt;/p>
&lt;/blockquote>
&lt;h1 id="5-寻求帮助">5. 寻求帮助&lt;/h1>
&lt;p>reach out for help&lt;/p>
&lt;p>最后的建议，同样也是最重要的，就是 &lt;strong>actively seek help when needed&lt;/strong>。从来没有人能够独自做所有事情。在你尝试了你能想到的一切方法后（比如那些前人的建议），是时候和你的同门交流，或者直接向导师寻求帮助。承认你遇到了问题，这个场景并不会羞耻或者尴尬。&lt;strong>你不必等到下一次会议&lt;/strong>。发送一封短邮件，或者直接去导师的办公室，简单交谈 5 分钟。或许导师的一两个词就是一盏明灯，让你有更多进展，而不是被卡在原地。生活和研究总是有起有落。请记住，你并不孤单，导师在这里提供帮助和支持。&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>不必等到下一次会议&lt;/strong>，一定要主动，积极。&lt;/p>
&lt;p>&lt;strong>请记住，你并不孤单，导师在这里提供帮助和支持&lt;/strong>，当你找到了一起同行的人，一起讨论的人，一定要珍惜。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>作为总结&lt;/strong>，有效的会议是 &lt;strong>make a good plan for time and content&lt;/strong>。我的经验是按以下内容来组织。快速查看当前进度。主要花时间在改进建议和下一步的计划上。以待办事项摘要来结束会议。将简单和次要的问题，以及详细的审视作为离线任务。学习如何独立和全面地分析问题。在需要时积极寻求帮助。&lt;/p></description></item><item><title>论文阅读的笔记模板</title><link>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%9A%84%E7%AC%94%E8%AE%B0%E6%A8%A1%E6%9D%BF/</link><pubDate>Fri, 23 Sep 2022 11:15:41 +0800</pubDate><guid>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%9A%84%E7%AC%94%E8%AE%B0%E6%A8%A1%E6%9D%BF/</guid><description>&lt;h1 id="论文标题-title">论文标题 Title&lt;/h1>
&lt;p>会议/期刊的信息，例：&lt;strong>MICRO'21&lt;/strong>&lt;/p>
&lt;p>&lt;strong>作者信息：&lt;/strong> 大概总结一下一作和其导师目前的情况，之前的一些工作，目前的机构等等。&lt;/p>
&lt;h2 id="abs">Abs&lt;/h2>
&lt;p>总结一下摘要。&lt;/p>
&lt;p>浏览文章的图片，可以稍微总结一下图片传递的信息。&lt;/p>
&lt;h2 id="1-intro-总体介绍">1. Intro 总体介绍&lt;/h2>
&lt;p>看懂原文内容后，翻译或者用自己的话阐述，这部分要把几个问题说清楚，并且要有逻辑。&lt;/p>
&lt;ul>
&lt;li>文章大概的背景，之后会引申出，目前的问题是什么？&lt;/li>
&lt;li>目前有哪些解决方案，有哪些工作，之后会阐述目前的工作的问题&lt;/li>
&lt;li>介绍他们的解决方案（他们的 paper 做了什么，contribution 是什么）&lt;/li>
&lt;/ul>
&lt;h2 id="2-背景知识的相关工作">2. 背景知识的相关工作&lt;/h2>
&lt;p>这部分会根据文章背景，把一些需要了解的概念稍微展开讲一下。&lt;/p>
&lt;p>可能会把相关工作归类之后再讲一遍，如果是第一次读这个子领域的顶会，那么这部分内容涉及到的工作可以都浏览一下，了解大概的研究情况。&lt;/p>
&lt;h2 id="3-method">3. Method&lt;/h2>
&lt;p>这部分占据了主要的篇幅，一篇 12 页的文章可能有一半篇幅。我认为核心的地方是看懂每一张图片，暂时先不要过分沉浸于细节（比如各种参数是怎么设置的，除非图片有清晰的说明，否则这个需求应该是为复现服务的）。&lt;/p>
&lt;p>总结一下，可能会有以下几个部分。&lt;/p>
&lt;ul>
&lt;li>展示一些实验结果，主要是为了说明： XX 参数我们为什么要设置为 YY；根据这个观察（例：前几层 layer 不需要高精度）所以我们有了 XX insight；主要是阐述为什么这个系统/架构中的一些参数/模块为什么要这么设计。&lt;/li>
&lt;li>架构/系统的设计细节，能够完整地介绍工作的 flow&lt;/li>
&lt;/ul>
&lt;h2 id="4-实验评估结果">4. 实验/评估/结果&lt;/h2>
&lt;p>介绍实验是怎么做的，用的什么模型/benchmark，在什么框架/系统/模拟器上实现的。&lt;/p>
&lt;p>结果怎么样。一般很多人浏览时会在看完 intro 之后直接看结果如何。所以结果一定是直观的，一目了然的。&lt;/p>
&lt;h2 id="5-结论">5. 结论&lt;/h2>
&lt;p>总结一下作者结论部分的内容。&lt;/p>
&lt;h2 id="6-总结">6. 总结&lt;/h2>
&lt;p>&amp;#x2b50; 这部分是用自己的话总结，也是对自己的锻炼。阐述这篇文章解决的问题，他们的效果如何，他们和之前看的一些 &lt;strong>文章/方法/解决方案&lt;/strong> 相比如何。如果对小领域有了一些了解，还可以写下自己的 “主观” 评价，他们对于实际的 模型/硬件/框架 是否有作用，文章图片画的如何，文章结构如何，写作怎么样，有哪些可以学习的地方，工作量怎么样，有哪些地方比较 confuse，有哪些可以借鉴的地方，如果是你在设计实验，你会怎么做。&lt;/p></description></item><item><title>Python 语法学习</title><link>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_python%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/</link><pubDate>Wed, 14 Sep 2022 11:15:41 +0800</pubDate><guid>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_python%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/</guid><description>&lt;h1 id="1-attribute">1. Attribute&lt;/h1>
&lt;h2 id="11-string">1.1 string&lt;/h2>
&lt;p>用 for 循环实现了 list 中的元素转为 string，目的是用来索引。for 感觉比较麻烦，不易读也不优雅，有没有更好的方法？&lt;/p>
&lt;h3 id="111-operation">1.1.1 Operation&lt;/h3>
&lt;h4 id="1111-slice">1.1.1.1 slice&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>b &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Hello, World!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(b[&lt;span style="color:#ae81ff">2&lt;/span>:&lt;span style="color:#ae81ff">5&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># llo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(b[&lt;span style="color:#ae81ff">2&lt;/span>:])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># llo, World! &lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1112-replace">1.1.1.2 replace&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>string&lt;span style="color:#f92672">.&lt;/span>replace(oldvalue, newvalue, count)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># replaces a specified phrase with another specified phrase.&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1113-split">1.1.1.3 Split&lt;/h4>
&lt;p>The split() method splits a string into a list&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>string&lt;span style="color:#f92672">.&lt;/span>split(separator, maxsplit)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> file &lt;span style="color:#f92672">in&lt;/span> files:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># file -&amp;gt; &amp;#39;64_768_192.log&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> str_tmp &lt;span style="color:#f92672">=&lt;/span> file&lt;span style="color:#f92672">.&lt;/span>split(&lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>)[&lt;span style="color:#ae81ff">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># file.split(&amp;#39;.&amp;#39;) -&amp;gt; [&amp;#39;64_768_192&amp;#39;, &amp;#39;log&amp;#39;]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># file.split(&amp;#39;.&amp;#39;)[0] -&amp;gt; &amp;#39;64_768_192&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gemm_data[str_tmp] &lt;span style="color:#f92672">=&lt;/span> process_result(&lt;span style="color:#e6db74">&amp;#34;ant&amp;#34;&lt;/span>, file)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1114-format">1.1.1.4 Format&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>txt1 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;My name is &lt;/span>&lt;span style="color:#e6db74">{fname}&lt;/span>&lt;span style="color:#e6db74">, I&amp;#39;m &lt;/span>&lt;span style="color:#e6db74">{age}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>format(fname &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;John&amp;#34;&lt;/span>, age &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">36&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>txt2 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;My name is &lt;/span>&lt;span style="color:#e6db74">{0}&lt;/span>&lt;span style="color:#e6db74">, I&amp;#39;m &lt;/span>&lt;span style="color:#e6db74">{1}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>format(&lt;span style="color:#e6db74">&amp;#34;John&amp;#34;&lt;/span>,&lt;span style="color:#ae81ff">36&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>txt3 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;My name is &lt;/span>&lt;span style="color:#e6db74">{}&lt;/span>&lt;span style="color:#e6db74">, I&amp;#39;m &lt;/span>&lt;span style="color:#e6db74">{}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>format(&lt;span style="color:#e6db74">&amp;#34;John&amp;#34;&lt;/span>,&lt;span style="color:#ae81ff">36&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(txt1)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># My name is John, I&amp;#39;m 36&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(txt2)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># My name is John, I&amp;#39;m 36&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(txt3)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># My name is John, I&amp;#39;m 36&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>2022-11-24 16:58:29，这个在输出处理 log 信息时会经常用过。之前一直用的是 +，学习一下 f string。上面的 format 组合可以等价于下面的写法：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>fname &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;John&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>age &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">36&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>txt1 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;My name is &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>fname&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">, I&amp;#39;m &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>age&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># or&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>txt1 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">F&lt;/span>&lt;span style="color:#e6db74">&amp;#34;My name is &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>fname&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">, I&amp;#39;m &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>age&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>甚至无需使用 &lt;code>str(index)&lt;/code> 这种写法了。&lt;/p>
&lt;h3 id="112-实际使用时的一些需求">1.1.2 实际使用时的一些需求&lt;/h3>
&lt;h4 id="1121-list-转-string">1.1.2.1 list 转 string&lt;/h4>
&lt;p>&lt;strong>list item 是 string 类型，join&lt;/strong>&lt;/p>
&lt;p>join, return values are strings&lt;/p>
&lt;p>注意，使用这个方法，list 中的元素也需要是字符串，所以对于 list item 不是字符串的情况，也许还是得用 for loop。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># list = [1, 2, 3, 4, 5]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>list &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;1&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;2&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;3&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;4&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;5&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>join(list) &lt;span style="color:#75715e"># get &amp;#34;12345&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;,&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>join(list) &lt;span style="color:#75715e"># get &amp;#34;1,2,3,4,5&amp;#34; &lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>list item 不是 string 类型&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> it &lt;span style="color:#f92672">in&lt;/span> list:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conv_list &lt;span style="color:#f92672">+=&lt;/span> str(it) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39; &amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1122-string-转-list">1.1.2.2 string 转 list&lt;/h4>
&lt;p>&lt;strong>使用 list 函数&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> string
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>str_ &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;abcde&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>list1 &lt;span style="color:#f92672">=&lt;/span> list(str_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(list1)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;, &amp;#39;e&amp;#39;]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>使用 split() 函数&lt;/strong>，根据 string 中的某个分隔符来划分 element&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> file &lt;span style="color:#f92672">in&lt;/span> files:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># file -&amp;gt; &amp;#39;64_768_192.log&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> str_tmp &lt;span style="color:#f92672">=&lt;/span> file&lt;span style="color:#f92672">.&lt;/span>split(&lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>)[&lt;span style="color:#ae81ff">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># file.split(&amp;#39;.&amp;#39;) -&amp;gt; [&amp;#39;64_768_192&amp;#39;, &amp;#39;log&amp;#39;]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># file.split(&amp;#39;.&amp;#39;)[0] -&amp;gt; &amp;#39;64_768_192&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gemm_data[str_tmp] &lt;span style="color:#f92672">=&lt;/span> process_result(&lt;span style="color:#e6db74">&amp;#34;ant&amp;#34;&lt;/span>, file)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="12-list">1.2 list&lt;/h1>
&lt;h3 id="121-一些性质">1.2.1 一些性质&lt;/h3>
&lt;ul>
&lt;li>&lt;code>m_list[-1]&lt;/code> 直接索引到最后一个元素；&lt;code>m_list[-2]&lt;/code> 索引倒数第二个&lt;/li>
&lt;/ul>
&lt;h3 id="122-实际使用时的需要">1.2.2 实际使用时的需要&lt;/h3>
&lt;h4 id="1221-multi-dimension-to-one-dimension">1.2.2.1 multi-dimension to one-dimension&lt;/h4>
&lt;p>也就是多维列表转一维列表，有些时候只是想拿到所有数据并绘图或者做其他处理，不需要其 shape&lt;/p>
&lt;p>对于二维列表，方法比较多，对于多维，目前找到一种方法，并且必须知道具体维度，写对应数量的 for 循环处理&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># from_iterable 方法&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> itertools &lt;span style="color:#f92672">import&lt;/span> chain
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tmp_list &lt;span style="color:#f92672">=&lt;/span> list(chain&lt;span style="color:#f92672">.&lt;/span>from_iterable(grad_output[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>tolist()))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># grad_output[0].tolist() 是一个二维 list&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 使用 for 循环遍历，对于 四维 list&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tmp_list &lt;span style="color:#f92672">=&lt;/span> [element &lt;span style="color:#66d9ef">for&lt;/span> batch &lt;span style="color:#f92672">in&lt;/span> grad_output[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>tolist() &lt;span style="color:#66d9ef">for&lt;/span> channel &lt;span style="color:#f92672">in&lt;/span> batch &lt;span style="color:#66d9ef">for&lt;/span> height &lt;span style="color:#f92672">in&lt;/span> channel &lt;span style="color:#66d9ef">for&lt;/span> element &lt;span style="color:#f92672">in&lt;/span> height]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1222-切片">1.2.2.2 切片&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>tmp_list &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;CS&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;EE&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;EECS&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 取前两个元素&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tmp_list[:&lt;span style="color:#ae81ff">2&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 从 index = 1 开始，取两个元素&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tmp_list[&lt;span style="color:#ae81ff">1&lt;/span>:&lt;span style="color:#ae81ff">3&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 前 10 个数，每 2 个数取一个&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tmp_list[:&lt;span style="color:#ae81ff">10&lt;/span>:&lt;span style="color:#ae81ff">2&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 所有数，每 5 个取一个&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tmp_list[::&lt;span style="color:#ae81ff">5&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1223-迭代">1.2.2.3 迭代&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 判断是否可以迭代&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#f92672">from&lt;/span> collections.abc &lt;span style="color:#f92672">import&lt;/span> Iterable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> isinstance(&lt;span style="color:#e6db74">&amp;#39;abc&amp;#39;&lt;/span>, Iterable) &lt;span style="color:#75715e"># str是否可迭代&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">True&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> isinstance(&lt;span style="color:#ae81ff">123&lt;/span>, Iterable) &lt;span style="color:#75715e"># 整数是否可迭代&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 下标循环，用 enumerate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">for&lt;/span> i, value &lt;span style="color:#f92672">in&lt;/span> enumerate([&lt;span style="color:#e6db74">&amp;#39;A&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;B&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;C&amp;#39;&lt;/span>]):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span> print(i, value)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">0&lt;/span> A
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">1&lt;/span> B
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">2&lt;/span> C
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 二维 list 遍历&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">for&lt;/span> x, y &lt;span style="color:#f92672">in&lt;/span> [(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>), (&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>), (&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">9&lt;/span>)]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span> print(x, y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">3&lt;/span> &lt;span style="color:#ae81ff">9&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="1224-列表生成">1.2.2.4 列表生成&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 最基本的用 range&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> list(range(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">11&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">7&lt;/span>, &lt;span style="color:#ae81ff">8&lt;/span>, &lt;span style="color:#ae81ff">9&lt;/span>, &lt;span style="color:#ae81ff">10&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 用 for 循环&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> [x &lt;span style="color:#f92672">*&lt;/span> x &lt;span style="color:#66d9ef">for&lt;/span> x &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">11&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">9&lt;/span>, &lt;span style="color:#ae81ff">16&lt;/span>, &lt;span style="color:#ae81ff">25&lt;/span>, &lt;span style="color:#ae81ff">36&lt;/span>, &lt;span style="color:#ae81ff">49&lt;/span>, &lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">81&lt;/span>, &lt;span style="color:#ae81ff">100&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 比如列出当前目录下的所有文件和目录名&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> [d &lt;span style="color:#66d9ef">for&lt;/span> d &lt;span style="color:#f92672">in&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>listdir(&lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>)] &lt;span style="color:#75715e"># os.listdir可以列出文件和目录&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#e6db74">&amp;#39;.emacs.d&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;.ssh&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;.Trash&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Adlm&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Applications&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Desktop&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Documents&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Downloads&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Library&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Movies&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Music&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Pictures&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Public&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;VirtualBox VMs&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Workspace&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;XCode&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="13-tuple">1.3 tuple&lt;/h2>
&lt;h3 id="131-基本性质">1.3.1 基本性质&lt;/h3>
&lt;p>&lt;code>m_tuple = ('CS', 'EE', 'EECS')&lt;/code>&lt;/p>
&lt;p>和 list 比较类似，不过 tuple 不能修改，只读；不过看了一些拓展，这个不可变似乎只是指针的指向不变，而指针对象本身是否改变就不知道了。&lt;/p>
&lt;p>&lt;strong>只有一个元素的 tuple 为了消除歧义&lt;/strong>，会表示为 &lt;code>t = (1, )&lt;/code>；这一点和我打印出来的结果是一致的，一开始还困惑为什么有个 &lt;code>,&lt;/code>&lt;/p>
&lt;h3 id="132-操作">1.3.2 操作&lt;/h3>
&lt;p>&lt;strong>切片&lt;/strong>，和 list 类似&lt;/p>
&lt;h3 id="14-转-list">1.4 转 list&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 对于 dict，直接放入 list function 就是将其 key 转为 list&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> list({&lt;span style="color:#e6db74">&amp;#39;apple&amp;#39;&lt;/span>:&lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;banana&amp;#39;&lt;/span>:&lt;span style="color:#e6db74">&amp;#39;1233&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;cherry&amp;#39;&lt;/span>:&lt;span style="color:#e6db74">&amp;#39;1231243&amp;#39;&lt;/span>})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y &lt;span style="color:#f92672">=&lt;/span> list({&lt;span style="color:#e6db74">&amp;#39;apple&amp;#39;&lt;/span>:&lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;banana&amp;#39;&lt;/span>:&lt;span style="color:#e6db74">&amp;#39;1233&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;cherry&amp;#39;&lt;/span>:&lt;span style="color:#e6db74">&amp;#39;1231243&amp;#39;&lt;/span>}&lt;span style="color:#f92672">.&lt;/span>keys())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># output&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#e6db74">&amp;#39;apple&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;banana&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;cherry&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#e6db74">&amp;#39;apple&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;banana&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;cherry&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="14-dict">1.4 dict&lt;/h2>
&lt;h3 id="141-判断-keyvalue-是否存在">1.4.1 判断 key/value 是否存在&lt;/h3>
&lt;p>&lt;strong>key&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>dict_tmp&lt;span style="color:#f92672">.&lt;/span>has_key()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>value&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 判断 key 是否存在&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;CS&amp;#39;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> Major
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 不存在则返回 None&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Major&lt;span style="color:#f92672">.&lt;/span>get(&lt;span style="color:#e6db74">&amp;#39;CS&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 不存在则返回 -1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Major&lt;span style="color:#f92672">.&lt;/span>get(&lt;span style="color:#e6db74">&amp;#39;CS&amp;#39;&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="142-存放">1.4.2 存放&lt;/h3>
&lt;p>dict 内部存放的顺序和 key 放入的顺序是没有关系的。&lt;/p>
&lt;p>key 必须是不可变对象，比如 string, 整数可以作为 key，但是 list 不能作为 key，因为 list 可变&lt;/p>
&lt;h3 id="143-迭代">1.4.3 迭代&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 默认迭代 key&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>d &lt;span style="color:#f92672">=&lt;/span> {&lt;span style="color:#e6db74">&amp;#39;a&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;b&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;c&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">3&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> key &lt;span style="color:#f92672">in&lt;/span> d:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 迭代 value&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> value &lt;span style="color:#f92672">in&lt;/span> d&lt;span style="color:#f92672">.&lt;/span>values():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 同时迭代&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> k, v &lt;span style="color:#f92672">in&lt;/span> d&lt;span style="color:#f92672">.&lt;/span>items():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="15-set">1.5 set&lt;/h2>
&lt;p>看起来就是去重的数组&lt;/p>
&lt;h2 id="16-array">1.6 array&lt;/h2>
&lt;h3 id="161-什么是-array-like">1.6.1 什么是 array like&lt;/h3>
&lt;p>&lt;a href="https://stackoverflow.com/questions/40378427/numpy-formal-definition-of-array-like-objects">https://stackoverflow.com/questions/40378427/numpy-formal-definition-of-array-like-objects&lt;/a> 回答 in stackoverflow&lt;/p>
&lt;blockquote>
&lt;p>It turns out almost anything is technically an array-like. &amp;ldquo;Array-like&amp;rdquo; is more of a statement of how the input will be interpreted than a restriction on what the input can be; if a parameter is documented as array-like, NumPy will try to interpret it as an array.&lt;/p>
&lt;/blockquote>
&lt;p>一个陈述，如何去理解 input，而非一个限制。&lt;/p>
&lt;blockquote>
&lt;p>The term &amp;ldquo;array-like&amp;rdquo; is used in NumPy, referring to anything that can be passed as first parameter to &lt;code>numpy.array()&lt;/code> to create an array ().&lt;/p>
&lt;/blockquote>
&lt;p>直接的定义，可以作为 &lt;code>numpy.array()&lt;/code> 的第一个参数&lt;/p>
&lt;p>&lt;a href="https://thecleverprogrammer.com/2021/03/19/difference-between-tensors-and-arrays/">https://thecleverprogrammer.com/2021/03/19/difference-between-tensors-and-arrays/&lt;/a>&lt;/p>
&lt;p>The difference between a NumPy array and a tensor is that the tensors are backed by the accelerator memory like GPU and they are immutable, unlike NumPy arrays.&lt;/p>
&lt;p>总的来说，&lt;strong>Tensors are like arrays&lt;/strong>, both are data structures that are used to store data that can be indexed individually.&lt;/p>
&lt;p>&lt;strong>综上，tensor 是否是 array-like?&lt;/strong>&lt;/p>
&lt;p>&lt;strong>是的&lt;/strong>&lt;/p>
&lt;h3 id="162-operation--操作">1.6.2 operation / 操作&lt;/h3>
&lt;h4 id="1621-插入-append--insert">1.6.2.1 插入 append / insert&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>bins &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">2.0&lt;/span> &lt;span style="color:#f92672">**&lt;/span> (np&lt;span style="color:#f92672">.&lt;/span>arange(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 插入到数组末端&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 插入到数组开头，或者任意 index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>index &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>element &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bins &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>insert(bins, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="1x-其他特性">1.X 其他特性&lt;/h2>
&lt;h3 id="1x1-generator">1.X.1 generator&lt;/h3>
&lt;p>暂时没有用过，先挖个坑&lt;/p>
&lt;h1 id="2-数据类型变量语法">2. 数据类型，变量，语法&lt;/h1>
&lt;h2 id="21-data-type">2.1 data type&lt;/h2>
&lt;p>python 支持的 data type 应该足够满足日常使用了。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>complex 在 cutlass 里面也有支持，不过平时没有使用过。tuple 使用也比较少&lt;/p>
&lt;h3 id="211-float">2.1.1 float&lt;/h3>
&lt;p>可以写成 &lt;code>1.23e9&lt;/code>&lt;/p>
&lt;h3 id="212-string">2.1.2 string&lt;/h3>
&lt;p>python 中，用 &lt;code>''&lt;/code> 和 &lt;code>&amp;quot;&amp;quot;&lt;/code> 有什么区别？&lt;/p>
&lt;p>从 stackoverflow 回答来看是完全一样的&lt;/p>
&lt;h2 id="22-类型转换">2.2 类型转换&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">25&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>str_ &lt;span style="color:#f92672">=&lt;/span> str(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>int_ &lt;span style="color:#f92672">=&lt;/span> int(str_)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="23-编码">2.3 编码&lt;/h2>
&lt;blockquote>
&lt;p>UTF-8 编码，把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。&lt;/p>
&lt;/blockquote>
&lt;p>看来这里也有哈夫曼的思想&lt;/p>
&lt;h2 id="24-global-variables">2.4 Global Variables&lt;/h2>
&lt;p>在函数内部创建变量时，默认是局部的&lt;/p>
&lt;p>在函数外部定义变量时，默认是全局的，此时无需使用 global 关键字；在函数外使用 global 没有作用。&lt;/p>
&lt;p>在函数内读写全局变量时，需要使用 global 关键字&lt;/p>
&lt;h2 id="25-下划线-_-的使用">2.5 下划线 _ 的使用&lt;/h2>
&lt;p>3.9 16:21&lt;/p>
&lt;ul>
&lt;li>&lt;code>_var&lt;/code> prefix single 下划线. 表示变量 &lt;code>_var&lt;/code> 仅供内部使用。python 并没有强制的 private 属性，而是用这样一种社区规定，表示这个变量并不是公共接口，但是外部仍然可以访问到这个变量
&lt;ul>
&lt;li>同样，如果是函数，那么表明这是一个私有函数&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>var_&lt;/code> suffix single 下划线. 变量名字被关键字占用，用一个下划线来解决命名冲突，比如&lt;code>class_&lt;/code>&lt;/li>
&lt;li>&lt;code>__var&lt;/code> prefix double. 这个有点抽象，没太理解&lt;/li>
&lt;li>&lt;code>__var__&lt;/code> prefix and suffix double. 表示类中的私有变量，并且不会被解释器所修改&lt;/li>
&lt;/ul>
&lt;h1 id="3-file-操作">3. File 操作&lt;/h1>
&lt;h2 id="31-文件读写">3.1 文件读写&lt;/h2>
&lt;p>read, open, write&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>f &lt;span style="color:#f92672">=&lt;/span> open(&lt;span style="color:#e6db74">&amp;#34;demofile.txt&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;r&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(f&lt;span style="color:#f92672">.&lt;/span>read())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f &lt;span style="color:#f92672">=&lt;/span> open(&lt;span style="color:#e6db74">&amp;#34;demofile2.txt&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># a, append; w, overwrite&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f&lt;span style="color:#f92672">.&lt;/span>write(&lt;span style="color:#e6db74">&amp;#34;Now the file has more content!&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f&lt;span style="color:#f92672">.&lt;/span>close()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>实际使用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i, line &lt;span style="color:#f92672">in&lt;/span> enumerate(open(get_file_path() &lt;span style="color:#f92672">+&lt;/span> file)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> &lt;span style="color:#66d9ef">match&lt;/span> &lt;span style="color:#f92672">in&lt;/span> re&lt;span style="color:#f92672">.&lt;/span>finditer(pattern_cycle, line):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tmp &lt;span style="color:#f92672">=&lt;/span> list(&lt;span style="color:#66d9ef">match&lt;/span>&lt;span style="color:#f92672">.&lt;/span>group(&lt;span style="color:#ae81ff">1&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tmp &lt;span style="color:#f92672">=&lt;/span> float(&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>join(tmp))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> res_data[&lt;span style="color:#e6db74">&amp;#34;cycle&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> tmp
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="32-文件目录操作">3.2 文件目录操作&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">(&lt;/span>torch&lt;span style="color:#f92672">)&lt;/span> zdli@GPU74:/nvme/wmhu$ &lt;span style="color:#75715e"># 工作目录&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/nvme/wmhu/shader_docker/cutlass-gpgpu-sim &lt;span style="color:#75715e"># python 文件所在的目录&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>一些常用的路径&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>path_ &lt;span style="color:#f92672">=&lt;/span> os.getcwd&lt;span style="color:#f92672">()&lt;/span> &lt;span style="color:#75715e"># 获取当前工作目录的绝对路径, /nvme/wmhu&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>path_ &lt;span style="color:#f92672">=&lt;/span> os.path.abspath&lt;span style="color:#f92672">(&lt;/span>__ file __&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#75715e"># 获取当前文件的绝对路径, /nvme/wmhu/shader_docker/cutlass-gpgpu-sim/data_analyze.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>path_ &lt;span style="color:#f92672">=&lt;/span> os.path.dirname&lt;span style="color:#f92672">(&lt;/span>__file__&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#75715e"># 获得当前文件所在目录的绝对路径, /nvme/wmhu/shader_docker/cutlass-gpgpu-sim&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="4-函数">4. 函数&lt;/h1>
&lt;h2 id="41-特性">4.1 特性&lt;/h2>
&lt;p>&lt;code>def forward(self, x: torch.Tensor) -&amp;gt; torch.Tensor:&lt;/code>，箭头 &lt;code>-&amp;gt;&lt;/code> 后面表示返回值&lt;/p>
&lt;p>尝试在 class 内部调用成员函数，报了错。调用 class 内部成员函数要加上前缀 &lt;code>self.&lt;/code>，否则会被当成外部函数&lt;/p>
&lt;p>&lt;strong>Python 不支持函数重载&lt;/strong>&lt;/p>
&lt;h3 id="411-别名和引用">4.1.1 别名和引用&lt;/h3>
&lt;p>Python 中可以把函数名赋值给一个对象&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> a &lt;span style="color:#f92672">=&lt;/span> abs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> a(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="412-pass-占位符">4.1.2 pass 占位符&lt;/h3>
&lt;p>还没想好函数或者条件语句的内容，可以用一个 pass，让代码可以先运行&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">nop&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> agr &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">18&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="413-参数检查">4.1.3 参数检查&lt;/h3>
&lt;p>参数数量不对时，Python 解释器可以检查；如果是参数 type 错误，Python 解释器可能看不出来。可以用函数 &lt;code>isinstance()&lt;/code> 来检查，这个看起来有点像 assert()，一个典型的错误和异常处理&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">my_abs&lt;/span>(x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> isinstance(x, (int, float)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span> &lt;span style="color:#a6e22e">TypeError&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;bad operand type&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> x &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#f92672">-&lt;/span>x
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="42-__init__-and-forward">4.2 &lt;strong>init&lt;/strong> and forward()&lt;/h2>
&lt;p>了解函数的定义，以及调用，比如 &lt;strong>init&lt;/strong>&lt;/p>
&lt;h3 id="421-__init__">4.2.1 &lt;strong>init&lt;/strong>&lt;/h3>
&lt;blockquote>
&lt;p>个人将其理解为 C 中的构造函数&lt;/p>
&lt;/blockquote>
&lt;p>创建对象时，python 解释器会自动调用它。&lt;/p>
&lt;h3 id="422-forward">4.2.2 forward()&lt;/h3>
&lt;p>使用 pytorch 的训练模型的时候，不需要调用 forward 函数，只需要在实例化一个对象中（&lt;code>model = ViT(model_name, pretrained=True)&lt;/code>）传入对应的参数，就可以自动调用 forward 函数，下面展示一个例子。来自 &lt;a href="https://zhuanlan.zhihu.com/p/357021687">https://zhuanlan.zhihu.com/p/357021687&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Module&lt;/span>(nn&lt;span style="color:#f92672">.&lt;/span>Module):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> super()&lt;span style="color:#f92672">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># ......&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># ......&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">......&lt;/span> &lt;span style="color:#75715e"># 输入数据&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 实例化一个对象&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> Module()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 前向传播&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model(data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 而不是使用下面的&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># model.forward(data) &lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="422-why">4.2.2 Why?&lt;/h3>
&lt;p>为什么有这种等价关系？&lt;code>model(data)&lt;/code> 等价于 &lt;code>model.forward(data)&lt;/code>，因为在 class 中使用了 &lt;strong>call&lt;/strong> 函数。更深的就不继续展开了。&lt;/p>
&lt;h2 id="43-unittest">4.3 unittest&lt;/h2>
&lt;p>2022-08-01 14:38:19，今天接触到这玩意儿。因为组里面这边在做和 ngp 相关的东西。有同学用 jax 写了一版代码，test.py 文件看起来没有入口，所有函数都在 class 里面。调试的方式就是 &lt;code>python -m unittest test.py&lt;/code>。所以算是接触到了一个新的东西。&lt;/p>
&lt;p>编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 如下，继承自 unittest.TestCase&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">TestFoward&lt;/span>(unittest&lt;span style="color:#f92672">.&lt;/span>TestCase):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="44-pytest">4.4 pytest&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>pip install pytest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="441-命名规则">4.4.1 命名规则&lt;/h3>
&lt;ul>
&lt;li>测试文件名必须以“test_”开头&lt;/li>
&lt;li>测试类以Test开头，并且不能带有 init 方法&lt;/li>
&lt;li>测试函数必须以“test_”开头&lt;/li>
&lt;li>除了有setup/teardown，还能更自由的定义fixture装载测试用例&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h3 id="442-case">4.4.2 case&lt;/h3>
&lt;p>来自 &lt;a href="https://www.jianshu.com/p/75c27fe23b4e">https://www.jianshu.com/p/75c27fe23b4e&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># test_class.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">TestClass&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">test_one&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;this&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">assert&lt;/span> &lt;span style="color:#e6db74">&amp;#39;h&amp;#39;&lt;/span> &lt;span style="color:#f92672">in&lt;/span> x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">test_two&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;hello&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">assert&lt;/span> hasattr(x, &lt;span style="color:#e6db74">&amp;#39;check&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>运行&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ pytest -v test_
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="45-参数">4.5 参数&lt;/h2>
&lt;p>函数作为另一个函数的参数传入：&lt;/p>
&lt;h3 id="451-返回多个参数">4.5.1 返回多个参数&lt;/h3>
&lt;p>其实就是返回一个 tuple，但是在语法上，接收时不需要用括号&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> math
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">move&lt;/span>(x, y, step, angle&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> nx &lt;span style="color:#f92672">=&lt;/span> x &lt;span style="color:#f92672">+&lt;/span> step &lt;span style="color:#f92672">*&lt;/span> math&lt;span style="color:#f92672">.&lt;/span>cos(angle)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ny &lt;span style="color:#f92672">=&lt;/span> y &lt;span style="color:#f92672">-&lt;/span> step &lt;span style="color:#f92672">*&lt;/span> math&lt;span style="color:#f92672">.&lt;/span>sin(angle)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> nx, ny
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x, y &lt;span style="color:#f92672">=&lt;/span> move(&lt;span style="color:#ae81ff">100&lt;/span>, &lt;span style="color:#ae81ff">100&lt;/span>, &lt;span style="color:#ae81ff">60&lt;/span>, math&lt;span style="color:#f92672">.&lt;/span>pi &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="452-默认参数">4.5.2 默认参数&lt;/h3>
&lt;p>Python 应该不像 C 语言那样有函数的重构，可以用默认参数；必选参数必须全部放在前面，而全部可选参数/默认参数放在后面&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">power&lt;/span>(x, n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> s &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">while&lt;/span> n &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n &lt;span style="color:#f92672">=&lt;/span> n &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> s &lt;span style="color:#f92672">=&lt;/span> s &lt;span style="color:#f92672">*&lt;/span> x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> power(&lt;span style="color:#ae81ff">5&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">25&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> power(&lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">25&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="453-可变参数">4.5.3 可变参数&lt;/h3>
&lt;p>和返回的情况类似，传入的参数是一个 tuple，下面给出语法&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 加上 * 代表传入可变参数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">calc&lt;/span>(&lt;span style="color:#f92672">*&lt;/span>numbers):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sum &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> n &lt;span style="color:#f92672">in&lt;/span> numbers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sum &lt;span style="color:#f92672">=&lt;/span> sum &lt;span style="color:#f92672">+&lt;/span> n &lt;span style="color:#f92672">*&lt;/span> n
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> sum
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nums &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 传可变参数，过于繁琐&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>calc(nums[&lt;span style="color:#ae81ff">0&lt;/span>], nums[&lt;span style="color:#ae81ff">1&lt;/span>], nums[&lt;span style="color:#ae81ff">2&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 类似于返回多参数的写法&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>calc(&lt;span style="color:#f92672">*&lt;/span>nums)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="454-关键字参数">4.5.4 关键字参数&lt;/h3>
&lt;p>2022-08-11 15:28:10，这一块就是在理论上比较薄弱的地方，也是为什么之前阅读 Python 代码存在一些阻碍。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 除了必选参数 name, age，还可以传入任意个关键字参数 kw&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>def person&lt;span style="color:#f92672">(&lt;/span>name, age, **kw&lt;span style="color:#f92672">)&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print&lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#e6db74">&amp;#39;name:&amp;#39;&lt;/span>, name, &lt;span style="color:#e6db74">&amp;#39;age:&amp;#39;&lt;/span>, age, &lt;span style="color:#e6db74">&amp;#39;other:&amp;#39;&lt;/span>, kw&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="455-命名关键字参数">4.5.5 命名关键字参数&lt;/h3>
&lt;p>这个感觉在很多 Python 内置库中常用，限制关键字参数的名字。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># * 作为分隔符，* 之后的参数被视为命名关键字参数&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">person&lt;/span>(name, age, &lt;span style="color:#f92672">*&lt;/span>, city, job):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(name, age, city, job)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 也可以由一个可变参数来分隔&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">person&lt;/span>(name, age, &lt;span style="color:#f92672">*&lt;/span>args, city, job):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(name, age, args, city, job)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> person(&lt;span style="color:#e6db74">&amp;#39;Jack&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">24&lt;/span>, city&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Beijing&amp;#39;&lt;/span>, job&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Engineer&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Jack &lt;span style="color:#ae81ff">24&lt;/span> Beijing Engineer
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。&lt;/p>
&lt;h2 id="45-高阶函数">4.5 高阶函数&lt;/h2>
&lt;p>2022-08-11 16:02:01，之前疑惑的一个地方，函数作为另一个函数的参数传入。这个就是高阶函数。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 高阶函数的例子&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">add&lt;/span>(x, y, f):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> f(x) &lt;span style="color:#f92672">+&lt;/span> f(y)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="451-map-reduce">4.5.1 map, reduce&lt;/h3>
&lt;p>&lt;code>map()&lt;/code> 的参数，一个是函数，另一个是可迭代序列，&lt;code>map()&lt;/code> 会把传入的函数依次作用到序列的每个元素，然后把结果返回到序列中&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">f&lt;/span>(x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span> &lt;span style="color:#66d9ef">return&lt;/span> x &lt;span style="color:#f92672">*&lt;/span> x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> r &lt;span style="color:#f92672">=&lt;/span> map(f, [&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">7&lt;/span>, &lt;span style="color:#ae81ff">8&lt;/span>, &lt;span style="color:#ae81ff">9&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> list(r)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">9&lt;/span>, &lt;span style="color:#ae81ff">16&lt;/span>, &lt;span style="color:#ae81ff">25&lt;/span>, &lt;span style="color:#ae81ff">36&lt;/span>, &lt;span style="color:#ae81ff">49&lt;/span>, &lt;span style="color:#ae81ff">64&lt;/span>, &lt;span style="color:#ae81ff">81&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>reduce()&lt;/code> 也就接受函数作为参数，他会把函数作用在一个序列上，并把结果和序列中的下一个元素做累计计算&lt;/p>
&lt;p>&lt;code>reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)&lt;/code>&lt;/p>
&lt;h3 id="452-lambda">4.5.2 lambda&lt;/h3>
&lt;p>匿名函数，简化代码的一种方式&lt;/p>
&lt;h1 id="5-class">5. Class&lt;/h1>
&lt;h2 id="51-构造函数">5.1 构造函数&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Student&lt;/span>(object):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self, name, score):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>name &lt;span style="color:#f92672">=&lt;/span> name
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>score &lt;span style="color:#f92672">=&lt;/span> score
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 如果要定义为 私有成员，加两个下划线&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>__name &lt;span style="color:#f92672">=&lt;/span> name
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>__score &lt;span style="color:#f92672">=&lt;/span> score
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> bart &lt;span style="color:#f92672">=&lt;/span> Student(&lt;span style="color:#e6db74">&amp;#39;Bart Simpson&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">59&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> bart&lt;span style="color:#f92672">.&lt;/span>name
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;Bart Simpson&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> bart&lt;span style="color:#f92672">.&lt;/span>score
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">59&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="52-继承">5.2 继承&lt;/h2>
&lt;p>继承的语法&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Animal&lt;/span>(object):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">run&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;Animal is running...&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 把这个 object 换成需要继承的 class 即可&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Dog&lt;/span>(Animal):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Cat&lt;/span>(Animal):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="6-module--模块">6. module / 模块&lt;/h1>
&lt;h2 id="61-获取模块中的元素">6.1 获取模块中的元素&lt;/h2>
&lt;p>定义了一个模块 &lt;code>coda_int.py&lt;/code> 用来装需要绘图的所有 list，一个接一个输入名字过于繁琐，尝试获取模块的中对象来自动遍历。&lt;/p>
&lt;h3 id="611-遍历模块">6.1.1 遍历模块&lt;/h3>
&lt;p>2022-09-14 11:13:48 搞定。用 &lt;code>if not key.startswith('__')&lt;/code> 来过滤掉一些自带的方法，剩下的就是 &lt;code>cola_int&lt;/code> 这个 module 中的 list。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> key, value &lt;span style="color:#f92672">in&lt;/span> cola_int&lt;span style="color:#f92672">.&lt;/span>__dict__&lt;span style="color:#f92672">.&lt;/span>items():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> key&lt;span style="color:#f92672">.&lt;/span>startswith(&lt;span style="color:#e6db74">&amp;#39;__&amp;#39;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(value[&lt;span style="color:#e6db74">&amp;#39;max&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="7-os">7. os&lt;/h1>
&lt;h4 id="指定-gpu-运行">指定 GPU 运行&lt;/h4>
&lt;p>命令行&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>CUDA_VISIBLE_DEVICES&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span> python &lt;span style="color:#f92672">-&lt;/span>u &lt;span style="color:#f92672">-&lt;/span>m torch&lt;span style="color:#f92672">.&lt;/span>distributed&lt;span style="color:#f92672">.&lt;/span>launch &lt;span style="color:#f92672">--&lt;/span>nproc_per_node&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">--&lt;/span>master_port &lt;span style="color:#ae81ff">46666&lt;/span> main&lt;span style="color:#f92672">.&lt;/span>py &lt;span style="color:#f92672">--&lt;/span>dataset&lt;span style="color:#f92672">=&lt;/span>imagenet &lt;span style="color:#f92672">--&lt;/span>model&lt;span style="color:#f92672">=&lt;/span>inception_v3 &lt;span style="color:#f92672">--&lt;/span>epoch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#f92672">--&lt;/span>mode&lt;span style="color:#f92672">=&lt;/span>int &lt;span style="color:#f92672">--&lt;/span>wbit&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#f92672">--&lt;/span>abit&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#f92672">--&lt;/span>batch_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">160&lt;/span> &lt;span style="color:#f92672">--&lt;/span>lr&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">5e-05&lt;/span> &lt;span style="color:#f92672">--&lt;/span>train &lt;span style="color:#f92672">--&lt;/span>dataset_path&lt;span style="color:#f92672">=/&lt;/span>home&lt;span style="color:#f92672">/&lt;/span>cguo&lt;span style="color:#f92672">/&lt;/span>imagenet&lt;span style="color:#f92672">-&lt;/span>raw&lt;span style="color:#f92672">-&lt;/span>data&lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#f92672">./&lt;/span>log&lt;span style="color:#f92672">/&lt;/span>inception_v3_Int&lt;span style="color:#f92672">.&lt;/span>log &lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">&amp;gt;&amp;amp;&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>python 文件&lt;/p>
&lt;pre tabindex="0">&lt;code>import os
os.environ[&amp;#34;CUDA_VISIBLE_DEVICES&amp;#34;] = &amp;#34;2&amp;#34;
&lt;/code>&lt;/pre>&lt;h1 id="debug">Debug&lt;/h1>
&lt;blockquote>
&lt;p>用Python开发程序，完全可以一边在文本编辑器里写代码，一边开一个交互式命令窗口，在写代码的过程中，把部分代码粘到命令行去验证，事半功倍！前提是得有个27&amp;rsquo;的超大显示器！&lt;/p>
&lt;/blockquote>
&lt;p>这倒是这类语言的一个debug 方法&lt;/p>
&lt;h1 id="bug">BUG&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;dict_values&amp;#39;&lt;/span> object &lt;span style="color:#f92672">is&lt;/span> &lt;span style="color:#f92672">not&lt;/span> subscriptable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tot_stat[model_name &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;_&amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> mode] &lt;span style="color:#f92672">=&lt;/span> sum_stat&lt;span style="color:#f92672">.&lt;/span>values()[len_ &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>:]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意 sum_stat.values() 返回的是 dict_keys 对象而不是 list，不支持 index 索引，可以使用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>tot_stat[model_name &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;_&amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> mode] &lt;span style="color:#f92672">=&lt;/span> list(sum_stat&lt;span style="color:#f92672">.&lt;/span>values())[len_ &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>:]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017024645952992">https://www.liaoxuefeng.com/wiki/1016959663602400/1017024645952992&lt;/a>&lt;/p></description></item><item><title>Tips to Become a Better (Computer Science) Ph.D. Student (By Ziyang Xu)</title><link>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_tips-to-become-a-better-computer-science-ph.d.-student/</link><pubDate>Sun, 28 Aug 2022 00:04:17 +0800</pubDate><guid>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_tips-to-become-a-better-computer-science-ph.d.-student/</guid><description>&lt;blockquote>
&lt;p>&lt;a href="https://www.cs.princeton.edu/~ziyangx/graduate-advice/">https://www.cs.princeton.edu/~ziyangx/graduate-advice/&lt;/a>
&lt;strong>作者信息&lt;/strong>： 转载自北大本科生 Ziyang Xu，本科在梁云那里实习，现在是 princeton 4th year phd，导师是 Greg Chan&lt;/p>
&lt;/blockquote>
&lt;h1 id="1-5-topics">1. 5 Topics&lt;/h1>
&lt;h1 id="11-research--course">1.1 Research &amp;gt; Course&lt;/h1>
&lt;p>Young Ph.D. students tend to spend too much time on courses. However, research outweighs courses.&lt;/p>
&lt;p>&lt;strong>Take courses with a grain of salt&lt;/strong>&lt;/p>
&lt;p>Courses are not as important as they seem to be. The priority of a Ph.D. student is to do research – the earlier you start your research, the better off you’ll be in the long run.&lt;/p>
&lt;p>However, &lt;strong>don’t go to extremes&lt;/strong>! A poor grade can also be a huge problem. You should always be familiar with the requirement of qualification exams or generals and meet all the standards about the courses.&lt;/p>
&lt;p>&lt;strong>Remember the main ideas of courses&lt;/strong>&lt;/p>
&lt;p>Trapping ourselves in trivial details of a course is easy. However, most of the specifics are not important to our research even if the topic is related to our area.&lt;/p>
&lt;p>A good approach is to use what you’ve learned from one course and apply it to a different field (e.g., taking an analysis tool from a compiler course and applying it in computer networks).&lt;/p>
&lt;blockquote>
&lt;p>低年级的 phd 容易迷失在课程中，但是这也完全可以理解。我自己研一的时候由于不适应节奏，感觉几乎所有时间都是花在课程上的。科研比课程重要，我相信大多数人都知道，只是去调整，去适应还需要花费一点时间。&lt;/p>
&lt;/blockquote>
&lt;h2 id="12-be-professional">1.2 Be professional&lt;/h2>
&lt;p>Treat your Ph.D. as a job. You get paid (albeit not much) for being a Ph.D. candidate, so make your work worth the money. This professional mindset should also be apparent to your advisor. Some advisors take on a more hands-off approach, for instance letting you work from home, but this is no reason for slacking; you should be responsible for your research schedule, such as reminding your advisor of plans from previous group meetings. Your status is not that of a student but rather that of a peer in the research community.&lt;/p>
&lt;blockquote>
&lt;p>个人理解举几个具体一点的例子吧，比如 meeting 之类的做好 PPT，有什么事情快速回复和确认，不要看到了之后想着做完了再回复；做不出来的东西也要及时反馈；有时间观念&lt;/p>
&lt;/blockquote>
&lt;h2 id="13-read-a-lot-and-read-broadly">1.3 Read a lot and read broadly&lt;/h2>
&lt;p>Though it can be very daunting starting out, reading papers is an essential part of the Ph.D. life. Previously, you may have read papers when it was necessary for a class or a project. However, you should put reading papers in your daily routine. Doing so allows you to draw inspiration from a sea of knowledge and prevents yourself from reinventing the wheel. Besides, it’s a great way to be productive on a slow day.&lt;/p>
&lt;p>&lt;strong>Make a plan to read&lt;/strong>&lt;/p>
&lt;p>When scheduling your day, assign one period just for reading papers. You can read one paper in depth or compare several papers; regardless of your choice, allotting time to this task is the key.&lt;/p>
&lt;p>&lt;strong>Read broadly&lt;/strong>&lt;/p>
&lt;p>Reading papers from different subfields of computer science is a great way to learn the jargon, the method, and the mindset of researchers in each field. This can be the first step towards discovering opportunities for collaboration.&lt;/p>
&lt;blockquote>
&lt;p>很惭愧还没有养成每天固定阅读的习惯，我觉得这个必须在入学前做好。&lt;/p>
&lt;/blockquote>
&lt;h2 id="14-fail-fast">1.4 Fail fast&lt;/h2>
&lt;p>It is not uncommon for a Ph.D. student to spend several years building a system that turns out to be fundamentally flawed or not as applicable as expected. Don’t worry! There is nothing wrong with failing, and perhaps we should even expect failure to be part of the journey. But we should aim to fail early in order to have time to work on another project (and graduate!).&lt;/p>
&lt;p>&lt;strong>Perform a limit study&lt;/strong>&lt;/p>
&lt;p>Perform a quick limit study before sticking with a project. A limit study includes in-depth analyses of implicit assumptions we make when coming up with an idea, a related works search, and the potential of the work if everything goes well. A great limit study can itself be a publishable paper. An example can be found &lt;a href="https://homes.cs.washington.edu/~luisceze/publications/fortuna-iiswc2010.pdf">&lt;strong>here&lt;/strong>&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Hacky implementation can be useful&lt;/strong>&lt;/p>
&lt;p>Being a researcher, your work is to develop proof-of-concepts. Nevertheless, you need to demonstrate that your concept is sound for the simplest of cases before continuing to the full-blown system. Hack in the minimum set to show that your idea is possible while resisting the temptation to build a robust infrastructure – if your idea fails, you will know to stop earlier.&lt;/p>
&lt;h2 id="15-impact-humankind">1.5 Impact humankind&lt;/h2>
&lt;p>Impacting humankind may sound too ambitious, but it should be the ultimate reason why we embark on this journey.&lt;/p>
&lt;p>&lt;strong>Choose an impactful research topic&lt;/strong>&lt;/p>
&lt;p>In terms of how our Ph.D. research could impact human knowledge, I would like to refer to &lt;a href="http://matt.might.net/articles/phd-school-in-pictures/">&lt;strong>The Illustrated Guide to a Ph.D.&lt;/strong>&lt;/a> by Matt Might. All we will do in five years is pushing the boundary of human knowledge by a minute margin. Choose a topic that you are able to contribute to, feel passionate about, and can explain the importance of to a layman in a 3-min talk.&lt;/p>
&lt;p>Check out why &lt;a href="http://matt.might.net/">&lt;strong>Matt Might&lt;/strong>&lt;/a> changed his research focus from programming languages to precise medicine.&lt;/p>
&lt;p>&lt;strong>How can our research actually impact people from other fields?&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://liberty.princeton.edu/Publications/sc11_survey.pdf">&lt;strong>A survey paper&lt;/strong>&lt;/a> by the Liberty Research Group sheds light on how the improvement of programming tools impacts (&lt;del>computational scientists&lt;/del>) all scientists. Thinking about how your research affects people from other fields can help you define the scope of your contribution.&lt;/p>
&lt;blockquote>
&lt;p>做有影响力的课题&lt;/p>
&lt;/blockquote>
&lt;h1 id="2-5-tips">2. 5 Tips&lt;/h1>
&lt;h2 id="21-dont-give-up-on-your-research-topic-easily">2.1 Don’t give up on your research topic easily&lt;/h2>
&lt;p>At some point, we will get bored with our research topic and find something else interesting. Think twice before switching topics. You must differentiate between your project heading nowhere and you getting tired of being stuck.&lt;/p>
&lt;blockquote>
&lt;p>这是显然的，不过如何选课题也要慎重。目前自己还暂时没有去自主选择一个课题，但是毫无疑问，当你真正开始做这个事的时候，可能是需要投入时间最多的时候。这极大可能决定了之后6-9个月的努力是否有效。&lt;/p>
&lt;/blockquote>
&lt;h2 id="22-aim-for-top-tier-conferences">2.2 Aim for top-tier conferences&lt;/h2>
&lt;p>You should focus on publishing at only top-tier conferences. Don’t consider second-tier venues unless the work has been rejected several times by top-tier conferences. This can prevent you from doing incremental work to make your publication list look better.&lt;/p>
&lt;blockquote>
&lt;p>当你做好准备，并且有合适的老师指导的时候，确实可以把这个当做研究的动机，只瞄准顶级会议，加油。&lt;/p>
&lt;/blockquote>
&lt;h2 id="23-use-existing-resources-in-your-group">2.3 Use existing resources in your group&lt;/h2>
&lt;p>For many fields in computer science, a mature infrastructure requires several years of development by multiple graduate students. Think about how to make use of the infrastructure and resources in the group to boost your research progress.&lt;/p>
&lt;blockquote>
&lt;p>这个其实就很好理解，组里面做硬件很强的学长，以及发过顶会的学长，各个方向的，都是非常宝贵资源。&lt;/p>
&lt;/blockquote>
&lt;h2 id="24-you-are-powerful">2.4 You are powerful&lt;/h2>
&lt;p>Even though we are just junior graduate students, we can have a massive impact on ourselves, our group, and even our department. For example, if there is no reading group for your field in your department, start one!&lt;/p>
&lt;blockquote>
&lt;p>心态调整好&lt;/p>
&lt;/blockquote>
&lt;h2 id="25-focus-on-publishing">2.5 Focus on publishing&lt;/h2>
&lt;p>Needless to say, publications are essential since those are what people look at once we graduate.&lt;/p>
&lt;blockquote>
&lt;p>pub 是一名 phd 唯一要做的事情&lt;/p>
&lt;/blockquote>
&lt;h1 id="3-other-amazing-blogs-out-there">3. Other amazing blogs out there:&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="http://www.pgbovine.net/PhD-memoir.htm">The Ph.D. Grind&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.ifs.tuwien.ac.at/~silvia/research-tips/">Tips: How to Do Research&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.cs.unc.edu/~azuma/hitch4.html">So long, and thanks for the Ph.D.!&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.math.waikato.ac.nz/~seano/grad-school-advice.html">Graduate School Survival Guide&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.sigarch.org/tips-for-a-new-computer-architecture-phd-student/">Tips for a New Computer Architecture PhD Student&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Tips for a New Computer Architecture PhD Student (By Swapnil Haria)</title><link>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_tips-for-a-new-computer-architecture-phd-student/</link><pubDate>Sat, 27 Aug 2022 23:57:17 +0800</pubDate><guid>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_tips-for-a-new-computer-architecture-phd-student/</guid><description>&lt;p>原文网址：https://www.sigarch.org/tips-for-a-new-computer-architecture-phd-student/&lt;/p>
&lt;p>作者在 2019 年是 UWM 5 年级 phd，导师是 Mark Hill，毕业后去了 Google 做一名软件开发工程师。&lt;/p>
&lt;p>原文&lt;/p>
&lt;p>I have been fortunate enough to have many helpful senior students and two wonderful advisors to learn from throughout my PhD. Now as a senior PhD student myself, I have identified some lessons that proved most valuable as well as common mistakes made by younger graduate students. While these may be common knowledge, I am documenting these tips here to pass on some of our collectively learned lessons to future graduate students.&lt;/p>
&lt;p>&lt;strong>1. Learn to read a paper efficiently.&lt;/strong>
Fifty years of architecture research has produced a venerable but sizeable collection of research literature, growing by almost 200+ papers a year just from the top four conferences. To make good progress as we wade through the ocean of related work, it is important to read papers efficiently. &lt;a href="http://ccr.sigcomm.org/online/files/p83-keshavA.pdf">Here&lt;/a> is a useful three-pass technique for reading papers efficiently. For me, reading a paper involves finding an answer to these questions (inspired by &lt;a href="http://pages.cs.wisc.edu/~markhill/grant-tips.html">grant writing tips&lt;/a>):&lt;/p>
&lt;ul>
&lt;li>What is the problem that the paper is trying to solve?&lt;/li>
&lt;li>Why is the problem relevant?&lt;/li>
&lt;li>What is the insight that drives the solution proposed by the paper?&lt;/li>
&lt;li>What are the trade-offs of the proposed solution?&lt;/li>
&lt;li>How have the authors evaluated the solution?&lt;/li>
&lt;li>What is one good trait in the paper (problem, solution, evaluation, presentation)?&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>甚至可以把这些问题贴在墙边，读论文的时候才能反复地去思考问题的答案，提升效率。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>2. Know when to stop reading papers.&lt;/strong>
Whenever one begins a new project, it is easy to fall into the trap of endlessly reading paper after paper of related work. While surveying related literature is essential, it tends to yield diminishing returns after a certain point. it is equally important to get one’s feet wet and actually start working on a project. There will be gaps in one’s knowledge but any critical gaps can be filled when that information is actually needed. After all, a graduate student is expected to be an information producer and not just a consumer.&lt;/p>
&lt;blockquote>
&lt;p>这个其实很难。对我自己来说，读了一段时间我就会想去做一些实验，一方面也是一些调剂，一种做同一件事情总会觉得疲劳。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>3. Join or start a reading group.&lt;/strong>
One way of being social is to participate in a reading group, which is a group of students that meet regularly to discuss an interesting paper (old or new) related to a particular area (e.g., architecture). In each meeting, one of the members is responsible for leading the discussion while the others are expected to have read the paper so as to contribute to the discussion. Through reading groups, one is forced to read papers outside of one’s particular niche. Ph.D. graduates often end up working in an area outside of the focus of their thesis. Thus, being exposed to a wide variety of topics is extremely useful. Group discussions also help bring out multiple perspectives into the same paper.&lt;/p>
&lt;blockquote>
&lt;p>这个是一个很有意思的建议，不过推动这件事情通常需要一些有影响力的 host，或者是导师组织的，不知道美国是否会有比较多的自发组织的 reading group&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>4. Use appropriate evaluation methodologies.&lt;/strong>
There is no one size fits all when it comes to &lt;a href="https://www.morganclaypool.com/doi/abs/10.2200/S00273ED1V01Y201006CAC010">evaluation methodologies&lt;/a>. Always select an appropriate methodology by taking into account development time, simulation speed and accuracy of results. There are three broad types of evaluation methodologies. Analytical modelling involves building mathematical models of the area of interest. At early stages of a project, it may be more useful to build simple mathematical models to get a broad sense of the efficacy of a research idea. Popular analytical models include the Roofline Model, Little’s law, Bottleneck analysis and others. Trace-based simulation involves using simulators that read in instruction or memory accesses sequences (traces) to provide reasonable estimates of runtime. Finally, execution-based simulators model hardware behavior at a cycle granularity. While such simulators offer the most accurate results, they also require the most development time as well as simulation time. As such, they may be overkill for simpler experiments. Hence, it is good to be familiar with different evaluation methodologies and use the right one at the right time.&lt;/p>
&lt;blockquote>
&lt;p>paper 看多了之后，基本能知道一些常用的分析方法&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>5. Work on real systems.&lt;/strong>
Although simulators are becoming more sophisticated, there is no substitute for working on real systems. This involves prototyping ideas in the linux kernel, modifying device drivers, building &lt;a href="https://rise.cs.berkeley.edu/projects/firesim/">FPGA-based systems&lt;/a> or &lt;a href="https://mshahrad.github.io/openpiton-asplos16.html">taping out chips&lt;/a>. Looking at real systems gives us an idea of the complexity and robustness of industrial-strength solutions. This also forces us to confront the practical limitations of our ideas. The rise of open-source hardware along with existing open-source software has made it easy to work on real-world &lt;a href="https://www.linux.org/">operating systems&lt;/a>, &lt;a href="https://llvm.org/">compilers&lt;/a>, &lt;a href="https://riscv.org/">CPUs&lt;/a> and &lt;a href="http://miaowgpu.org/">GPUs&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>这一点是我非常赞同的，simulation work 是一件非常危险的事情，有条件的话一定要转向真实的系统&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>6. Spend time improving your programming skills.&lt;/strong>
New computer architecture graduates may not already be good software engineers as computer architecture attracts students with backgrounds in hardware as well. However, PhD-level architecture research typically involves writing a lot of code as part of simulators, operating systems or benchmarks. Hence, it is worth spending some time early in the graduate lifecycle to improve one’s programming skills. Here are some handy resources:
&lt;a href="http://cs-www.cs.yale.edu/homes/aspnes/classes/223/notes.pdf">Data Structures&lt;/a>, &lt;a href="http://bigocheatsheet.com/">Complexity Theory&lt;/a>, &lt;a href="http://pages.cs.wisc.edu/~swapnilh/resources/design-pattern-scard.pdf">Design Patterns&lt;/a>, &lt;a href="http://google.github.io/styleguide/">Code Style&lt;/a>, &lt;a href="http://rogerdudler.github.io/git-guide/">Git/Mercurial&lt;/a>, &lt;a href="http://cslibrary.stanford.edu/102/PointersAndMemory.pdf">Pointers&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>体系结构的学生需要同时具备硬件和软件背景，至少他们必须会使用模拟器，熟悉操作系统，各种 benchmark&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>7. Use microbenchmarks wisely.&lt;/strong>
Microbenchmarks are simple and self-contained programs written to achieve a specific outcome. Microbenchmarks are immensely useful for preliminary exploration as well as sanity checking. An example is a program that can deterministically generate ~100K TLB misses on every execution. Our example microbenchmark can validate a TLB simulator by comparing simulator-reported misses with microbenchmark-generated misses. Being simpler and more easily understood than full-fledged benchmarks, they can be used for initial evaluation to get results that demonstrate general trends. However, microbenchmarks should not be relied upon for any meaningful evaluation, particularly they should not be used as a proxy for real applications.&lt;/p>
&lt;blockquote>
&lt;p>目前自己用的比较少，但这个绝对是体系结构领域非常重要的东西&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>8. Create talks/posters/paper drafts to get early feedback.&lt;/strong>
Once we start plugging away at implementation work, we sometimes lose track of the big research picture and instead simply generate a lot of experimental results. It is important to analyze these results in the context of the overall project. Then, crafting a talk or poster even with little to no results forces us to present our ideas in actual words and images. Different presentation media make us think about our research differently and thus refine our story. By presenting our posters and talks to other researchers, we get timely feedback that can help set the direction of our project.&lt;/p>
&lt;blockquote>
&lt;p>2022-08-27 09:53:50，今天就是 poster talk 的 DDL，只能说自己确实比较拖延，正常来说可能应该找别人讨论一下，模拟一下。确实，沉浸在实验中时，容易丢失 high level 的视野，只能不断提醒自己不要忘记最初的 motivation 和故事的框架&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>9. Care for your mental and physical well-being and maintain a support system.&lt;/strong>
The typical &lt;a href="http://phdcomics.com/comics/archive.php?comicid=125">PhD lifetime&lt;/a> is long years of hard work with a few triumphant occasions such as paper acceptances mixed in. Remember that graduate school is a marathon and not a sprint. Hence, it is important to care for one’s overall health by getting enough sleep, having a healthy diet and spending time on exercise and hobbies. More importantly, graduate school is the first time many of us struggle academically or feel unproductive which may lead to &lt;a href="https://www.theatlantic.com/education/archive/2018/11/anxiety-depression-mental-health-graduate-school/576769/">mental health issues&lt;/a>. Just remember that you are not alone in facing these issues and it is okay to ask for help. Most schools offer free or subsidized &lt;a href="https://www.uhs.wisc.edu/mental-health/">mental health resources&lt;/a>. Furthermore, try to build and subsequently maintain a strong support structure for yourself by nurturing personal relationships with family and friends. Be social with your peers and almost never say no to going out for lunch, attending practice talks and other such activities.&lt;/p>
&lt;blockquote>
&lt;p>毫无疑问，保持身体健康和心理健康非常重要&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Acknowledgements&lt;/strong>
I thank Prof. Mark Hill, Lena Olson and Prof. Jason Lowe-Power for help improving this document. For teaching me these lessons in the first place, I am grateful to Prof. Mark Hill, Prof. Michael Swift, Prof. David Wood, Lena Olson, Jason Lowe-Power, Nilay Vaish, Jayneel Gandhi, Hongil Yoon, Rathijit Sen, Gokul Ravi, Marc Orr, Muhammad Shoaib, Joel Hestness, Prof. Tony Nowatzki, Newsha Ardalani, Vijay Thiruvengadam, Vinay Gangadhar and many others whom I encountered in graduate school.&lt;/p>
&lt;p>&lt;strong>About the author:&lt;/strong> &lt;a href="http://pages.cs.wisc.edu/~swapnilh/">Swapnil Haria&lt;/a> is a 5th-year PhD Candidate at the University of Wisconsin-Madison, advised by Mark Hill and Michael Swift. His research is focused on hardware and software support for persistent memory.&lt;/p>
&lt;p>&lt;strong>Disclaimer:&lt;/strong> &lt;em>These posts are written by individual contributors to share their thoughts on the Computer Architecture Today blog for the benefit of the community. Any views or opinions represented in this blog are per&lt;/em>&lt;/p></description></item><item><title>What My Mentors Taught Me (By Shan Lu)</title><link>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_what-my-mentors-taught-me-by-shan-lu/</link><pubDate>Sat, 27 Aug 2022 23:57:17 +0800</pubDate><guid>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_what-my-mentors-taught-me-by-shan-lu/</guid><description>&lt;h1 id="0-前言">0. 前言&lt;/h1>
&lt;p>视频地址：https://www.youtube.com/watch?v=lOOBJix9-Dw&amp;amp;t=5s&lt;/p>
&lt;p>这是来自卢山老师的 talk&lt;/p>
&lt;p>shan lu 老师目前是芝加哥大学的教授，计算机系统领域的大牛。&lt;/p>
&lt;p>&lt;strong>一定要 open to help，千万不要害羞，千万不要害怕向别人寻求帮助&lt;/strong>&lt;/p>
&lt;p>大牛第一篇 paper 被拒了 5 次，第三年还没有一作 paper。&lt;/p>
&lt;p>&lt;strong>Why did you want to be a phd student&lt;/strong>&lt;/p>
&lt;p>第三年换了一个 topic，投到了 ISCA，也被拒绝了。当时老师觉得是他的 phd 最低谷的时候了。&lt;/p>
&lt;p>他的 phd 导师一直鼓励着他，在低估的时候给予指引，在低估的时候给予 support，真的是一个非常 nice 的事情。&lt;/p>
&lt;p>ISCA 被拒之后中了 ASPLOS，有时候真的很难说。之后几年的 research 都非常顺利。YY 告诉她一定要注意英语。同学写信建议她多 read English book，她花了一年多看完了两本难啃的书。那之后他看英文书变得很快很快。有的时候是 advice 来自不同的地方。&lt;/p>
&lt;p>第四年开始 conference presentation. 一定要去找别的老师，要敢于去找 senior 的老师。一定要告诉别人你在 job market 上面。他说了之后，CMU 老师说他们没有 position，但是可以给她一个 mock interview。&lt;/p>
&lt;p>&lt;strong>只要自己鼓起勇气，很多 senior 的老师会给出很多好的建议&lt;/strong>&lt;/p>
&lt;p>&lt;strong>第一次去要 external letter&lt;/strong>&lt;/p>
&lt;p>别人的回复是 &amp;ldquo;No. I don&amp;rsquo;t know your work well enough.&amp;rdquo; 作者说他已经出汗了，但是我觉得这本身已经是很大的勇气了。&lt;/p>
&lt;p>他咨询的教授非常 straight forward&lt;/p>
&lt;p>&lt;strong>My interview trip&lt;/strong>&lt;/p>
&lt;p>&amp;ldquo;I am surprised how much you have improved&amp;rdquo;&lt;/p>
&lt;p>去 UWM，mark 给了他很多 advice。所以还是一定要 open。&lt;/p>
&lt;p>&lt;strong>Say bye to YY&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Do what you believe in. Be yourself&lt;/li>
&lt;li>Family and Health are two glass balls; career is plastic ball&lt;/li>
&lt;li>Integrity is the most important&lt;/li>
&lt;li>Faculty life is a marathon; Ph.D. life is a sprint&lt;/li>
&lt;li>It is a learning experience&lt;/li>
&lt;/ul>
&lt;p>在不同的环境中也要像不同的人学习&lt;/p>
&lt;p>&lt;strong>My first ASPLOS paper as a faculty&lt;/strong>&lt;/p>
&lt;p>Mark 作为同事仍然在帮助他修改 paper。Mark 从 introduction 中没有读到他的 passion，希望他重新想一下，重新构思这个 story。&lt;/p>
&lt;p>Mark 说他确实有不错的 idea，但是写的不行。&lt;/p>
&lt;p>&amp;#x2b50; Mark 提了一个建议。画一个 2-dimension 图片，以前的 paper 是专注于 Effects 这个维度，我们的工作和他们不一样在哪？This paper 专注于 Causes 这个维度。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Mark 说我来告诉你你的 introduction 每个 paragraph 应该写什么，应该怎么写。而且不能是大概，每一个词都必须要想清楚。&lt;/p>
&lt;blockquote>
&lt;p>这一点也得说一下，有些时候自己也会觉得大概知道了要讲什么，但实际到了真正的细节那里还是一片模糊，这样是不行的。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>My first undergrad. teaching&lt;/strong>&lt;/p>
&lt;p>don&amp;rsquo;t give back, give forward；回馈给下一代&lt;/p>
&lt;p>&lt;strong>My first NSF proposal&lt;/strong>&lt;/p>
&lt;p>&amp;ldquo;You are not a Turing Award Winner, why worrying about rejection&amp;rdquo;&lt;/p>
&lt;p>Mark 仍然在帮助他修改 proposal。&lt;/p>
&lt;p>如果从头再来，他会主动地去找 Mark 帮忙。&lt;/p>
&lt;p>&lt;strong>My student first conference presentation&lt;/strong>&lt;/p>
&lt;p>一定要 seek advice&lt;/p>
&lt;p>写一篇 paper 一定是有 6 months delay，当你 feel good，是因为半年前做得好，而不是现在做得好。当你 feel bad，也不要太 bad，因为收益也是延后的&lt;/p>
&lt;p>他的 co-author 给他反馈了 comment&lt;/p>
&lt;p>&lt;strong>My depression&lt;/strong>&lt;/p>
&lt;p>2011 年有段时间，看起来很累，晚上没法入睡。Andrea 主动邀请他一起上画画课，走出沮丧的情绪。&lt;/p>
&lt;p>&lt;strong>Is my research too incremental&lt;/strong>&lt;/p>
&lt;p>他担心自己的工作过于 incremental。同行告诉不用太担心，还是要不断地去做探索，才能够发掘出新的工作。&lt;/p>
&lt;p>&lt;strong>My first leaving student&lt;/strong>&lt;/p>
&lt;p>他的有一个学生想转学去 CMU。Mark 的建议是要给学生写好的推荐信&lt;/p>
&lt;p>&lt;strong>Service, Service&lt;/strong>&lt;/p>
&lt;p>指的是一些会议的 service，这些东西其实需要去平衡。因为很容易就花费太多时间在上面。&lt;/p>
&lt;p>&lt;strong>提问环境&lt;/strong>&lt;/p>
&lt;p>卢山老师起点很高，怎么去看 2 流会议，或者非 top 会议？&lt;/p>
&lt;ul>
&lt;li>先从最好的 conference 上发表&lt;/li>
&lt;/ul>
&lt;p>如果一篇 paper 被领域内的会议拒稿太多次只有，会做什么&lt;/p>
&lt;ul>
&lt;li>他跟着 YY 做的时候，基本觉得想出一个 idea 都能投到 top 会议。去了 UW 之后，觉得不要有一个特别牛的 idea 才开始做。只要解决了问题，就可以去做一些，因为学生也需要 training，不能总投 top 会议。&lt;/li>
&lt;li>他一开始的时候想了 ASPLOS 的一个点，做着做着就开始拓展了。做完之后觉得好像也成了 top 会议了&lt;/li>
&lt;/ul></description></item><item><title>Hugo 文章页面添加固定目录栏</title><link>https://huweim.github.io/post/blog_hugo_%E6%96%87%E7%AB%A0%E9%A1%B5%E9%9D%A2%E6%B7%BB%E5%8A%A0%E5%9B%BA%E5%AE%9A%E7%9B%AE%E5%BD%95/</link><pubDate>Sun, 14 Aug 2022 19:33:17 +0800</pubDate><guid>https://huweim.github.io/post/blog_hugo_%E6%96%87%E7%AB%A0%E9%A1%B5%E9%9D%A2%E6%B7%BB%E5%8A%A0%E5%9B%BA%E5%AE%9A%E7%9B%AE%E5%BD%95/</guid><description>&lt;h1 id="0-前言">0. 前言&lt;/h1>
&lt;p>阅读博客文章时有一个固定的目录会舒服很多，现在就来探索一下怎么添加这个功能。&lt;/p>
&lt;h1 id="1-固定目录">1. 固定目录&lt;/h1>
&lt;p>以主题 &lt;code>jane&lt;/code> 为例，在文件 &lt;code>theme/jane/layouts/post/single.html&lt;/code> 中存放着如何显示 post。根据文件中的代码，关于 table of content 的设定存放在 &lt;code>theme/jane/layouts/partials/post/toc.html&lt;/code>&lt;/p>
&lt;p>之后把原来的 tableofcontent 那部分代码放到 nav 中即可，如下，注释掉原来的代码（15-17 行）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-html" data-lang="html">&lt;span style="display:flex;">&lt;span>{{ if or .Params.toc (and .Site.Params.toc (ne .Params.toc false)) }}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;post-toc&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;post-toc&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">h2&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;post-toc-title&amp;#34;&lt;/span>&amp;gt;{{ i18n &amp;#34;toc&amp;#34; }}&amp;lt;/&lt;span style="color:#f92672">h2&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">&amp;lt;!-- &amp;lt;div class=&amp;#34;post-toc-content&amp;#34;&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"> {{.TableOfContents}}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"> &amp;lt;/div&amp;gt; --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">nav&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;hide-on-mobile section-nav&amp;#34;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;&lt;span style="color:#f92672">h3&lt;/span> &lt;span style="color:#a6e22e">class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;ml-1&amp;#34;&lt;/span>&amp;gt;Table of contents&amp;lt;/&lt;span style="color:#f92672">h3&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {{ .TableOfContents }}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;/&lt;span style="color:#f92672">nav&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{{- end }}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>PyTorch 学习</title><link>https://huweim.github.io/post/%E6%96%87%E6%A1%A3_pytorch%E5%AD%A6%E4%B9%A0/</link><pubDate>Thu, 28 Jul 2022 16:05:35 +0800</pubDate><guid>https://huweim.github.io/post/%E6%96%87%E6%A1%A3_pytorch%E5%AD%A6%E4%B9%A0/</guid><description>&lt;h1 id="1-python-模块">1. Python 模块&lt;/h1>
&lt;h2 id="11-parser-模块">1.1 parser 模块&lt;/h2>
&lt;h3 id="111-parseradd_argument">1.1.1 parser.add_argument()&lt;/h3>
&lt;p>在命令行给代码赋值，不需要反复在 python 中修改代码。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parser&lt;span style="color:#f92672">.&lt;/span>add_argument(&lt;span style="color:#e6db74">&amp;#39;--file-dir&amp;#39;&lt;/span>,type&lt;span style="color:#f92672">=&lt;/span>str, required&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>,help&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Input file directory&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## 实例&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parser&lt;span style="color:#f92672">.&lt;/span>add_argument(&lt;span style="color:#e6db74">&amp;#39;--dataset&amp;#39;&lt;/span>, default&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;cifar10&amp;#39;&lt;/span>, type&lt;span style="color:#f92672">=&lt;/span>str,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> help&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;dataset name&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parser&lt;span style="color:#f92672">.&lt;/span>add_argument(&lt;span style="color:#e6db74">&amp;#39;--dataset_path&amp;#39;&lt;/span>, default&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;/state/partition/imagenet-raw-data&amp;#39;&lt;/span>, type&lt;span style="color:#f92672">=&lt;/span>str,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> help&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;dataset path&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parser&lt;span style="color:#f92672">.&lt;/span>add_argument(&lt;span style="color:#e6db74">&amp;#39;--model&amp;#39;&lt;/span>, default&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;resnet18&amp;#39;&lt;/span>, type&lt;span style="color:#f92672">=&lt;/span>str,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> help&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;model name&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>parser&lt;span style="color:#f92672">.&lt;/span>add_argument(&lt;span style="color:#e6db74">&amp;#39;--train&amp;#39;&lt;/span>, default&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>, action&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;store_true&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> help&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;train&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>action&lt;/code>: &lt;code>-train&lt;/code> 设置成一个开关，&lt;/p>
&lt;ul>
&lt;li>如果使用了 &lt;code>python -u -m --train ...&lt;/code>，就会把参数 &lt;code>--train&lt;/code> 设置为 True&lt;/li>
&lt;li>&lt;code>python -u -m ...&lt;/code>，没有这个开关，则参数存储为 False&lt;/li>
&lt;/ul>
&lt;h3 id="112-parserparse_args">1.1.2 parser.parse_args()&lt;/h3>
&lt;h2 id="12-tensor">1.2 Tensor&lt;/h2>
&lt;p>张量，多维数组。&lt;/p>
&lt;p>数据类型需要注意一下&lt;/p>
&lt;blockquote>
&lt;p>关于 dtype，PyTorch 提供了 9 种数据类型，共分为 3 大类：float (16-bit, 32-bit, 64-bit)、integer (unsigned-8-bit ,8-bit, 16-bit, 32-bit, 64-bit)、Boolean。模型参数和数据用的最多的类型是 float-32-bit。label 常用的类型是 integer-64-bit。&lt;/p>
&lt;/blockquote>
&lt;h1 id="2-torch">2. torch&lt;/h1>
&lt;p>有很多方便的数学操作，同理，先了解有这个东西，需要用到时看具体的用法。包括 torch.rand(), torch.range(), torch.chunk(), torch.normal(), torch.add()&lt;/p>
&lt;p>pytorch 主要分为五大模块&lt;/p>
&lt;ul>
&lt;li>dataset&lt;/li>
&lt;li>model&lt;/li>
&lt;li>loss funtion&lt;/li>
&lt;li>optimizer&lt;/li>
&lt;li>迭代训练&lt;/li>
&lt;/ul>
&lt;h2 id="21-nn">2.1 nn&lt;/h2>
&lt;p>&lt;code>torch.nn&lt;/code> 主要包含 4 个模块&lt;/p>
&lt;ul>
&lt;li>nn.Parameter, Tensor 子类，表示可学习的参数，如 weights, bias&lt;/li>
&lt;li>nn.Modules, 所有模型的基类，用于管理网络的属性&lt;/li>
&lt;li>nn.functional, 函数具体实现，如 conv, pool, 激活函数&lt;/li>
&lt;li>nn,init, 网络参数初始化方法&lt;/li>
&lt;/ul>
&lt;h3 id="211-nnmodule">2.1.1 nn.Module&lt;/h3>
&lt;p>class torch.nn.Module 是所有网络的基类（Base class for all neural network modules），每个模型都应该继承这个类，参考lab1的网络模型&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Net&lt;/span>(nn&lt;span style="color:#f92672">.&lt;/span>Module):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> super(Net, self)&lt;span style="color:#f92672">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv1 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Conv2d(&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, bias&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>pool &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>MaxPool2d(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>) &lt;span style="color:#75715e"># run after each conv (hence the 5x5 FC layer)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>conv2 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Conv2d(&lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">16&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, bias&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc1 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Linear(&lt;span style="color:#ae81ff">16&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">120&lt;/span>, bias&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc2 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Linear(&lt;span style="color:#ae81ff">120&lt;/span>, &lt;span style="color:#ae81ff">84&lt;/span>, bias&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc3 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Linear(&lt;span style="color:#ae81ff">84&lt;/span>, &lt;span style="color:#ae81ff">10&lt;/span>, bias&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, x: torch&lt;span style="color:#f92672">.&lt;/span>Tensor) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>pool(F&lt;span style="color:#f92672">.&lt;/span>relu(self&lt;span style="color:#f92672">.&lt;/span>conv1(x)))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>pool(F&lt;span style="color:#f92672">.&lt;/span>relu(self&lt;span style="color:#f92672">.&lt;/span>conv2(x)))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> x&lt;span style="color:#f92672">.&lt;/span>view(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">16&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> F&lt;span style="color:#f92672">.&lt;/span>relu(self&lt;span style="color:#f92672">.&lt;/span>fc1(x)) &lt;span style="color:#75715e">#输入是列向量&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> F&lt;span style="color:#f92672">.&lt;/span>relu(self&lt;span style="color:#f92672">.&lt;/span>fc2(x))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>fc3(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>net &lt;span style="color:#f92672">=&lt;/span> Net()&lt;span style="color:#f92672">.&lt;/span>to(device)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>一般在 model.py 文件中定义 NN model，再举一个 ViT 的例子&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">ViT&lt;/span>(nn&lt;span style="color:#f92672">.&lt;/span>Module):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> Args:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> name (str): Model name, e.g. &amp;#39;B_16&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> pretrained (bool): Load pretrained weights
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> in_channels (int): Number of channels in input data
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> num_classes (int): Number of classes, default 1000
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> References:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> [1] https://openreview.net/forum?id=YicbFdNTTy
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: Optional[str] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pretrained: bool &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> patches: int &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">16&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dim: int &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">768&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ff_dim: int &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3072&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_heads: int &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_layers: int &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> attention_dropout_rate: float &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0.0&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dropout_rate: float &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0.1&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> representation_size: Optional[int] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> load_repr_layer: bool &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> classifier: str &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;token&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> positional_embedding: str &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;1d&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> in_channels: int &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> image_size: Optional[int] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> num_classes: Optional[int] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> super()&lt;span style="color:#f92672">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="2111-一些子函数">2.1.1.1 一些子函数&lt;/h4>
&lt;p>2022-08-06 22:31:40&lt;/p>
&lt;p>named_ 系列&lt;/p>
&lt;p>&lt;strong>model.named_parameters()&lt;/strong>，返回两个变量，比如赋值给 name(e.g. &lt;code>name&lt;/code> -&amp;gt; &lt;code>stage_1.0.conv_b.weight&lt;/code>) 和 param (e.g. &lt;code>param.requires_grad&lt;/code> -&amp;gt; &lt;code>False&lt;/code>)&lt;/p>
&lt;h3 id="212-nnlayer">2.1.2 nn.Layer&lt;/h3>
&lt;p>&lt;strong>model.named_modules()&lt;/strong>，返回所有模块的迭代器。打印的话会输出模型的结构，如同 &lt;code>print(model)&lt;/code>&lt;/p>
&lt;p>&lt;strong>model.named_children&lt;/strong>，named_modules 的子集，返回子模块的迭代器&lt;/p>
&lt;p>&lt;strong>model.children()&lt;/strong>，返回下一级模块的迭代器&lt;/p>
&lt;blockquote>
&lt;p>所以这个只是访问到一级，如果下一级是一个 Sequential，那么就还得继续迭代，这个时候用 .modules() 可能会更好&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>model.modules()&lt;/strong>，Returns an iterator over all modules in the network&lt;/p>
&lt;p>model.named_modules() 会有冗余的返回，这种情况下需要结合一些函数来过滤。&lt;/p>
&lt;p>nn 还包含了很多 layer，比如 &lt;code>nn.Conv2d&lt;/code>, &lt;code>nn.MaxPool1d&lt;/code>, &lt;code>nn.ReLU&lt;/code>&lt;/p>
&lt;h3 id="213-model-的创建">2.1.3 model 的创建&lt;/h3>
&lt;p>主要是 2 个要素，构建子模块和拼接子模块，把子模块理解为 layer，构建子模块就是 &lt;code>__init__&lt;/code>，拼接子模块就是 &lt;code>forward()&lt;/code>&lt;/p>
&lt;ul>
&lt;li>调用 &lt;code>model = ViT(model_name, pretrained=True)&lt;/code> 创建模型时，会调用 &lt;code>__init__()&lt;/code> 方法创建模型的子模块&lt;/li>
&lt;li>训练时调用 &lt;code>outputs = net(inputs)&lt;/code> 时，会进入 &lt;code>module.py&lt;/code> 的 &lt;code>call()&lt;/code> 函数中&lt;/li>
&lt;li>在 &lt;code>__call__&lt;/code> 中调用 &lt;code>result = self.forward(*input, **kwargs)&lt;/code> 函数，进入到模型的 &lt;code>forward()&lt;/code> 函数中，进行前向传播&lt;/li>
&lt;/ul>
&lt;h4 id="2131-model-实例">2.1.3.1 model() 实例&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> quantize_model(model)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>outputs &lt;span style="color:#f92672">=&lt;/span> model(inputs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>loss &lt;span style="color:#f92672">=&lt;/span> criterion(outputs, targets)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 &lt;code>outputs = model(inputs)&lt;/code> 语句中会进入到 &lt;code>class Conv2dQuantizer(nn.Module)&lt;/code> 的 forward 函数，&lt;code>super(Conv2dQuantizer, self).__init__()&lt;/code> 是继承父类的构造函数 &lt;code>__init__()&lt;/code>，从而使得 Conv2dQuantizer 中包含了父类&lt;/p>
&lt;h4 id="2132-modeleval">2.1.3.2 model.eval()&lt;/h4>
&lt;p>作用：不启动 BatchNormalization 和 Dropout，保证 BN 和 Dropout 不发生变化，pytorch 框架会自动把 BN 和 Dropout 固定住，不会取平均值，而是用训练好的值，不然的话，一旦 test 的 batch_size 过小，很容易就会被 BN 层导致生成图片颜色失真极大。&lt;/p>
&lt;p>Reference: &lt;a href="https://zhuanlan.zhihu.com/p/357075502">https://zhuanlan.zhihu.com/p/357075502&lt;/a>&lt;/p>
&lt;h4 id="2133-torchno_grad">2.1.3.3 torch.no_grad()&lt;/h4>
&lt;p>tensor 有一个参数是 &lt;code>requires_grad&lt;/code>，如果设置为 True，则反向传播时该 tensor 会自动求导，默认为 False，反向传播时不求导，可以极大地节约显存或者内存。&lt;/p>
&lt;p>&lt;code>with torch.no_grad&lt;/code> 的作用：所有计算得出的 tensor 的 requires_grad 都自动设置为 False&lt;/p>
&lt;h3 id="214-crossentropyloss">2.1.4 CrossEntropyLoss&lt;/h3>
&lt;p>This criterion combines LogSoftmax and NLLLoss in one single class.&lt;/p>
&lt;h2 id="22-tensor">2.2 Tensor&lt;/h2>
&lt;p>Tensor 和 Numpy 中的 ndarrays 类似，但 Tensor 可以使用 GPU 进行加速计算。Tensor 可能是深度学习编程中，所有数据操作的基础单元。&lt;/p>
&lt;blockquote>
&lt;p>可以用 GPU 加速计算，这一点要记住&lt;/p>
&lt;/blockquote>
&lt;p>&lt;code>Tensor&lt;/code> is a multi-dimensional matrix containing elements of a single data type&lt;/p>
&lt;p>可以用 list 作为参数来构造 tensor&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>tensor([[&lt;span style="color:#ae81ff">1.&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1.&lt;/span>], [&lt;span style="color:#ae81ff">1.&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1.&lt;/span>]])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tensor([[ &lt;span style="color:#ae81ff">1.0000&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1.0000&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#ae81ff">1.0000&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1.0000&lt;/span>]])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>tensor(np&lt;span style="color:#f92672">.&lt;/span>array([[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>], [&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>]]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tensor([[ &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>]])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="221-view">2.2.1 view&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># to one-dimension&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>grad_output &lt;span style="color:#f92672">=&lt;/span> grad_output&lt;span style="color:#f92672">.&lt;/span>view(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># shape 是一个 list，存放了 tensor &amp;#39;data&amp;#39; 的整个维度信息&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>shape &lt;span style="color:#f92672">=&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>shape
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 按 data 的第一维展开，最终得到一个二维的 tensor。最终的数据，第一个维度是 data.shape[0]，和原来的第一个维度相同，第二个维度是后续所有元素的展开的总和&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#f92672">=&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>view(data&lt;span style="color:#f92672">.&lt;/span>shape[&lt;span style="color:#ae81ff">0&lt;/span>], &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 示例&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> x &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>randn(&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> x&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>torch&lt;span style="color:#f92672">.&lt;/span>Size([&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> y &lt;span style="color:#f92672">=&lt;/span> x&lt;span style="color:#f92672">.&lt;/span>view(&lt;span style="color:#ae81ff">16&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> y&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>torch&lt;span style="color:#f92672">.&lt;/span>Size([&lt;span style="color:#ae81ff">16&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> z &lt;span style="color:#f92672">=&lt;/span> x&lt;span style="color:#f92672">.&lt;/span>view(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">8&lt;/span>) &lt;span style="color:#75715e"># the size -1 is inferred from other dimensions&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> z&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>torch&lt;span style="color:#f92672">.&lt;/span>Size([&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">8&lt;/span>])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="222-常用操作">2.2.2 常用操作&lt;/h3>
&lt;h4 id="2222-索引">2.2.2.2 索引&lt;/h4>
&lt;p>&lt;strong>获取某一维度的长度&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># input 是一个 size = 1 的 tuple&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># input[0] 是一个 tensor, input[0] 的 size: &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 获取 tensor 第 1 个维度的 length&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>input[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>size(&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 获取 tensor 第 2 个维度的 length&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>input[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>size(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="2222-获取某-value-of-index-in-tensor">2.2.2.2 获取某 value of index in tensor&lt;/h4>
&lt;p>主要是用这个 nonzero&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>t &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor([&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print ((t &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>nonzero(as_tuple&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)[&lt;span style="color:#ae81ff">0&lt;/span>])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="2223-tensor-排序">2.2.2.3 tensor 排序&lt;/h4>
&lt;p>tensor.sort()&lt;/p>
&lt;p>2022-09-12 23:37:09，有一些坑，注意返回的是一个 tuple，所以要注意接收的形式。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>grad_output_sorted, grad_output_indices &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>sort(grad_output)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>grad_output_sorted &lt;span style="color:#f92672">=&lt;/span> grad_output_sorted&lt;span style="color:#f92672">.&lt;/span>double() &lt;span style="color:#75715e"># avoid RuntimeError: Found dtype Double but expected Float&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="2224-获取-tensor-中某-percentile">2.2.2.4 获取 tensor 中某 percentile&lt;/h4>
&lt;p>tensorflow 好像是支持 tfp.stats.percentile，直接获取 Finding p% of smallest tensor values&lt;/p>
&lt;p>直接用 &lt;code>np.percentile(tensor, )&lt;/code>&lt;/p>
&lt;h4 id="2225-torchwhere">2.2.2.5 torch.where()&lt;/h4>
&lt;p>快速地移除 tensor 中不满足某条件的 element&lt;/p>
&lt;p>比如，我们把值大于 0.5 的值置为0&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> x &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>randn(&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> y &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>ones(&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tensor([[&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">0.4620&lt;/span>, &lt;span style="color:#ae81ff">0.3139&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#ae81ff">0.3898&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">0.7197&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#ae81ff">0.0478&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">0.1657&lt;/span>]])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>where(x &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>, x, y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tensor([[ &lt;span style="color:#ae81ff">1.0000&lt;/span>, &lt;span style="color:#ae81ff">0.3139&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#ae81ff">0.3898&lt;/span>, &lt;span style="color:#ae81ff">1.0000&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#ae81ff">0.0478&lt;/span>, &lt;span style="color:#ae81ff">1.0000&lt;/span>]])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>实际&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>grad_output_sorted &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>where(grad_output_sorted &lt;span style="color:#f92672">&amp;gt;&lt;/span> max_75, &lt;span style="color:#ae81ff">0.&lt;/span>, grad_output_sorted)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>grad_output_sorted &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>where(grad_output_sorted &lt;span style="color:#f92672">&amp;lt;&lt;/span> min_75, &lt;span style="color:#ae81ff">0.&lt;/span>, grad_output_sorted)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="2226-torchcat-">2.2.2.6 torch.cat( )&lt;/h4>
&lt;p>删除掉 Tensor 中指定 value 的元素，比如&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># remove i-th element&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>i &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>T &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>tensor([&lt;span style="color:#ae81ff">1&lt;/span>,&lt;span style="color:#ae81ff">2&lt;/span>,&lt;span style="color:#ae81ff">3&lt;/span>,&lt;span style="color:#ae81ff">4&lt;/span>,&lt;span style="color:#ae81ff">5&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>T &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>cat([T[&lt;span style="color:#ae81ff">0&lt;/span>:i], T[i&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>:&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>]])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="222x-综合">2.2.2.X 综合&lt;/h4>
&lt;p>综上，有一个需求。对于一个一维 Tensor，消除掉其前25%的值，得到剩下75%的tensor&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="223-function">2.2.3 Function&lt;/h3>
&lt;h4 id="2231-tensordata-tensordetach">2.2.3.1 tensor.data, tensor.detach()&lt;/h4>
&lt;p>detach()和data生成的都是无梯度的纯tensor,并且通过同一个tensor数据操作，是共享一块数据内存。主要目的是让其独立于计算图之外&lt;/p>
&lt;h4 id="2232-tensormax-tensorabs-tensorunsqueeze-tensordim-tensorshape">2.2.3.2 tensor.max, tensor.abs, tensor.unsqueeze, tensor.dim, tensor.shape&lt;/h4>
&lt;p>tensor 原本是 (64, 128, 768)，经过 &lt;code>view&lt;/code> 将其二维化，第二维等于原本最后一个维度的 size，也就是 768。&lt;code>max(1)&lt;/code> 表示返回第二个维度的最大值，也就是 768 个元素中的最大值，最后得到的 tensor size 就是 (64*128)，然后通过 &lt;code>unsqueeze&lt;/code> 转换为 (64*128, 1) dimension&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>x_max, _ &lt;span style="color:#f92672">=&lt;/span> tensor&lt;span style="color:#f92672">.&lt;/span>view(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, tensor&lt;span style="color:#f92672">.&lt;/span>shape[tensor&lt;span style="color:#f92672">.&lt;/span>dim() &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>abs()&lt;span style="color:#f92672">.&lt;/span>max(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x_max &lt;span style="color:#f92672">=&lt;/span> x_max&lt;span style="color:#f92672">.&lt;/span>unsqueeze(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="2233-torcndot-torchmv-torchmm">2.2.3.3 torcn.dot. torch.mv, torch.mm&lt;/h4>
&lt;p>torch.dot: 向量点积&lt;/p>
&lt;p>torch.mv: 矩阵-向量积&lt;/p>
&lt;p>torch.mm: 矩阵-矩阵乘法&lt;/p>
&lt;h2 id="23-autograd">2.3 autograd&lt;/h2>
&lt;p>weight 更新依赖于梯度的计算，在 pytorch 中搭建好 forward 计算图，利用 &lt;code>torch.autograd&lt;/code> 自动求导得到所有 gradient of tensor&lt;/p>
&lt;h2 id="24-data-模块">2.4 data 模块&lt;/h2>
&lt;p>数据模块可以细分为 4 个部分&lt;/p>
&lt;ul>
&lt;li>数据收集：样本，label&lt;/li>
&lt;li>数据划分：train set, valid set, test set&lt;/li>
&lt;li>数据读取：pytorch dataloader 模块，dataloader 包括 sampler, dataset
&lt;ul>
&lt;li>sampler: 生成索引(index)&lt;/li>
&lt;li>dataset: 根据生成的索引(index)读取样本以及标签(label)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>数据预处理：对应于 pytorch transforms&lt;/li>
&lt;/ul>
&lt;h3 id="241-dataloader">2.4.1 DataLoader&lt;/h3>
&lt;p>&lt;code>torch.utils.data.DataLoader()&lt;/code>, 构建可迭代的数据装载器&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>torch&lt;span style="color:#f92672">.&lt;/span>utils&lt;span style="color:#f92672">.&lt;/span>data&lt;span style="color:#f92672">.&lt;/span>DataLoader(dataset, batch_size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, shuffle&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>, sampler&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>, batch_sampler&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>, num_workers&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>, collate_fn&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>, pin_memory&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>, drop_last&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>, timeout&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>, worker_init_fn&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>, multiprocessing_context&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>dataset: torchvision.datasets 类，决定数据从哪里读取，如何读取，以及是否下载，是否训练，给出一个例子&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>cifar100_test &lt;span style="color:#f92672">=&lt;/span> torchvision&lt;span style="color:#f92672">.&lt;/span>datasets&lt;span style="color:#f92672">.&lt;/span>CIFAR100(root&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;./data&amp;#39;&lt;/span>, train&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>, download&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>, transform&lt;span style="color:#f92672">=&lt;/span>transform_test)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>num_works: 是否多进程读取，指定读取的进程数量&lt;/li>
&lt;li>shuffle: 每个 epoch 是否乱序&lt;/li>
&lt;li>sampler: 指定一个 &lt;code>torch.utils.data.distributed.DistributedSampler&lt;/code> 类型&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>其他名词&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Epoch: 所有训练样本都已经输入到模型中，称为一个 epoch&lt;/li>
&lt;li>Iteration: a batch of 样本已经输入到模型中&lt;/li>
&lt;li>Batchsize: 批大小，决定一个 iteration 有多少样本，也决定了一个 Epoch 有多少个 Iteration&lt;/li>
&lt;/ul>
&lt;h4 id="2411-nvidiadali">2.4.1.1 NVIDIA.DALI&lt;/h4>
&lt;p>2022-07-28 21:24:17 了解到这玩意儿&lt;/p>
&lt;h3 id="242-dataset">2.4.2 DataSet&lt;/h3>
&lt;p>&lt;code>torch.utils.data.Dataset&lt;/code>, 抽象类，所有自定义大的 DataSet 都需要继承该类。&lt;/p>
&lt;p>在Dataset 的初始化函数中会调用 &lt;code>get_img_info()&lt;/code> 方法。&lt;/p>
&lt;h3 id="242-torchvision">2.4.2 torchvision&lt;/h3>
&lt;p>计算机视觉工具包，有 3 个主要的模块&lt;/p>
&lt;ul>
&lt;li>&lt;code>torchvision.transforms&lt;/code>, 包括常用的图像预处理方法&lt;/li>
&lt;li>&lt;code>torchvision.datasets&lt;/code>, 包括常用的 dataset, e.g. MNIST, CIFAR-10, ImageNet&lt;/li>
&lt;li>&lt;code>torchvision.models&lt;/code>, 常用的 pre-trained models, e.g. AlexNet, VGG, ResNet, GoogleNet&lt;/li>
&lt;/ul>
&lt;p>data 的数量和分布对模型训练的结果起决定性的作用，需要对 data 进行 pre-process 和数据增强。目的是增加数据的多样性，提高模型的泛化能力。&lt;/p>
&lt;h3 id="243-batch-size">2.4.3 Batch Size&lt;/h3>
&lt;p>2022-08-09 18:24:56，学习一下梯度，训练，和 batch size 的关系。&lt;/p>
&lt;p>通过举例来学习，比如目前使用的网络，batch_size = 128，训练数据行数为 $|x| = 1024$，代表每次网络模型的迭代使用了 128 个样本，128 个样本来自 $x$，可能是无序抽样，也可能是有序抽样。&lt;/p>
&lt;p>每个 epoch 包含 1024/128 iterations&lt;/p>
&lt;blockquote>
&lt;p>同一个 epoch，我用第一个 batch 完成了一次前向反向，接下来的第二次 iteration，换了一个 batch，但是 weight 已经更新过了
这个就是之前卡住我的点，要理解这一点。训练是为了让 weight 收敛。&lt;/p>
&lt;/blockquote>
&lt;h4 id="2431-epoch-bach-iteration">2.4.3.1 epoch, bach, iteration&lt;/h4>
&lt;p>epoch: 把所有训练数据丢进网络的周期&lt;/p>
&lt;p>batch_size: 一次迭代的数据量；这个从一些说法中，看起来是图片的张数&lt;/p>
&lt;p>iteration: 完成所有训练数据的迭代，所需要的次数。&lt;/p>
&lt;blockquote>
&lt;p>batch_size = 128，训练数据行数为 $|x| = 1024$，代表每次网络模型的迭代使用了 128 个样本，128 个样本来自 $x$，可能是无序抽样，也可能是有序抽样。
每个 epoch 包含 1024/128 iterations&lt;/p>
&lt;/blockquote>
&lt;p>&amp;#x2b50; 注意，第一个 epoch 结束之后，weight 是没有 reset 的，也就是说第二个 epoch 仍然接着更新 weight。&lt;/p>
&lt;blockquote>
&lt;p>epoch，背诵词典次数多了，就记牢了。当然，也有可能背傻了（过拟合）&lt;/p>
&lt;/blockquote>
&lt;h2 id="25-模型训练">2.5 模型训练&lt;/h2>
&lt;h3 id="251-损失函数">2.5.1 损失函数&lt;/h3>
&lt;p>Loss Function, 衡量模型输出与真实标签之间的差异，也就是 &lt;strong>一个&lt;/strong> 样本的 output 和真实标签（label）的差异&lt;/p>
&lt;p>Cost Function, 计算整个样本集的 output 和真实标签（label）的差异&lt;/p>
&lt;p>pytorch 中的损失函数也是继承于 &lt;code>nn.Module&lt;/code>&lt;/p>
&lt;h3 id="252-optimizer">2.5.2 optimizer&lt;/h3>
&lt;p>PyTorch 中的优化器是用于管理并更新模型中 &lt;strong>可学习参数的值&lt;/strong>，使得模型输出更加接近真实标签。&lt;/p>
&lt;h4 id="2521-属性">2.5.2.1 属性&lt;/h4>
&lt;ul>
&lt;li>defaults: 优化器的超参数，如 weight_decay, momentum&lt;/li>
&lt;li>state: 参数的缓存，如 momentum 中需要用到前几次的梯度，缓存在这个变量中&lt;/li>
&lt;li>param_groups: 管理的参数组，是一个 list，其中每个元素是 dict，包括 momentum, lr, weight_decay, params&lt;/li>
&lt;li>_step_count: 记录更新次数，在学习率调整中使用&lt;/li>
&lt;/ul>
&lt;h4 id="2522-optimizer-方法">2.5.2.2 optimizer 方法&lt;/h4>
&lt;ul>
&lt;li>zero_grad(): 清空所管理参数的梯度。因为 pytorch 张量的梯度不会自动清零，因此每次反向传播之后都需要清空梯度&lt;/li>
&lt;li>step(): 执行一步梯度更新&lt;/li>
&lt;li>add_param_group(): 添加参数组&lt;/li>
&lt;li>state_dict(): 获取优化器当前状态&lt;/li>
&lt;li>load_state_dict(): 加载状态信息的 dict&lt;/li>
&lt;/ul>
&lt;h4 id="2523-learning-rate">2.5.2.3 learning rate&lt;/h4>
&lt;p>learning rate, 影响 loss function 收敛的重要因素，控制了梯度下降更新的步伐&lt;/p>
&lt;h2 id="26-regularization-正则化">2.6 Regularization 正则化&lt;/h2>
&lt;p>正则化是一种减少方差的策略&lt;/p>
&lt;h3 id="261-weight-decay">2.6.1 weight decay&lt;/h3>
&lt;p>weight decay 是优化器中的一个参数，在执行 &lt;code>optim_wdecay_step()&lt;/code> 时，会计算 weight decay 后的梯度&lt;/p>
&lt;h3 id="262-dropout">2.6.2 Dropout&lt;/h3>
&lt;p>一种抑制过拟合的方法。理解为放缩数据&lt;/p>
&lt;h3 id="263-normalization">2.6.3 Normalization&lt;/h3>
&lt;p>Batch Normalization, 经过 normalization 后的数据服从 $N(0, 1)$ 分布，有如下优点&lt;/p>
&lt;ul>
&lt;li>可以使用更大的 lr，加速模型收敛&lt;/li>
&lt;li>可以不用精心设计 weight 初始化&lt;/li>
&lt;li>可以不用 dropout 或者较小的 dropout&lt;/li>
&lt;li>可以不用 L2 或者较小的 weight decay&lt;/li>
&lt;li>可以不用 LRN (Local Response Normalization)&lt;/li>
&lt;/ul>
&lt;h2 id="27-model-相关的操作">2.7 Model 相关的操作&lt;/h2>
&lt;h3 id="271-torchsave">2.7.1 torch.save&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>torch&lt;span style="color:#f92672">.&lt;/span>save(obj, f, pickle_module, pickle_protocol&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, _use_new_zipfile_serialization&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>obj 是保存的对象，f 是输出路径。还有 2 种方式&lt;/p>
&lt;ul>
&lt;li>保存整个 Module, &lt;code>torch.savev(net, path)&lt;/code> 这种方法比较耗时，保存的文件比较大&lt;/li>
&lt;li>只保存模型的参数，&lt;code>torch.savev(state_sict, path)&lt;/code>，推荐，保存的文件比较小&lt;/li>
&lt;/ul>
&lt;h3 id="272-torchload">2.7.2 torch.load&lt;/h3>
&lt;p>对应于 save&lt;/p>
&lt;h3 id="273-fine-tuning">2.7.3 Fine-tuning&lt;/h3>
&lt;p>一种迁移学习的方法，比如在人脸识别应用中，ImageNet 作为 source domain，人脸数据作为 target domain。通常 source domain 比 target domain 大很多，可以利用 ImageNet 训练好的网络应用到人脸识别中。&lt;/p>
&lt;p>&lt;strong>理解&lt;/strong>
对于一个模型，可以分为流程在前面的 feature extractor （conv 层） 和后面的 classifier。fine-tune 通常不改变 feature extractor 的 weight，也就是冻结 conv 层；改变最后一个 fc layer 的输出来适应目标任务，训练后面 classifier 的 weight。&lt;/p>
&lt;p>通常 target domain 的数据比较小，不足以训练全部参数，容易导致过拟合，因此不改变 feature extractor 的 weight。&lt;/p>
&lt;p>&lt;strong>Step&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>获取 pre-trained model 参数&lt;/li>
&lt;li>&lt;code>load_state_dict()&lt;/code> 把参数加载到模型中&lt;/li>
&lt;li>修改输出层&lt;/li>
&lt;li>固定 feature extractor 的参数，通常有 2 种做法
&lt;ul>
&lt;li>固定 conv 层的预训练参数。可以设置 &lt;code>requires_grad = False&lt;/code> 或者 &lt;code>lr = 0&lt;/code>&lt;/li>
&lt;li>通过 &lt;code>params_group&lt;/code> 给 feature extractor 设置一个较小的 lr&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="28-function">2.8 Function&lt;/h2>
&lt;h3 id="281-torchtopk">2.8.1 torch.topk()&lt;/h3>
&lt;p>&lt;strong>作用：&lt;/strong> 取一个 tensor 的 topk 元素（降序后的前 k 个大小的元素值及索引）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>K &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>numel(data) &lt;span style="color:#f92672">//&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>shape[&lt;span style="color:#ae81ff">0&lt;/span>] &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#f92672">//&lt;/span> &lt;span style="color:#ae81ff">256&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _, index &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>topk(data&lt;span style="color:#f92672">.&lt;/span>abs(), K, dim &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, largest &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>, sorted &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="282-torchnumel">2.8.2 torch.numel&lt;/h3>
&lt;p>返回 tensor 中的元素总数量&lt;/p>
&lt;h1 id="3-pytorch-分布式训练">3. pytorch 分布式训练&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>dist&lt;span style="color:#f92672">.&lt;/span>init_process_group(backend&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;nccl&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># backend是后台利用nccl进行通信&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>调试时报错，如何在调试分布式训练的模型&lt;/p>
&lt;h2 id="31-debug-分布式训练的模型">3.1 debug 分布式训练的模型&lt;/h2>
&lt;p>修改 python &lt;code>launch.json&lt;/code> 文件，把 program 换成 torch.distribution 的 launch.py&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">//&lt;/span> Use IntelliSense to learn about possible attributes&lt;span style="color:#f92672">.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">//&lt;/span> Hover to view descriptions of existing attributes&lt;span style="color:#f92672">.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">//&lt;/span> For more information, visit: https:&lt;span style="color:#f92672">//&lt;/span>go&lt;span style="color:#f92672">.&lt;/span>microsoft&lt;span style="color:#f92672">.&lt;/span>com&lt;span style="color:#f92672">/&lt;/span>fwlink&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">?&lt;/span>linkid&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">830387&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;version&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;0.2.0&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;configurations&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;name&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Python: Current File&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;python&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;request&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;launch&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;program&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/nvme/wmhu/anaconda3/envs/ant/lib/python3.8/site-packages/torch/distributed/launch.py&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;console&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;integratedTerminal&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;justMyCode&amp;#34;&lt;/span>: true,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;args&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--nproc_per_node=1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;/nvme/wmhu/work/ANT/ImageNet/main.py&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--dataset=imagenet&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--model=vit_b_16&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--dataset_path=/nvme/imagenet&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--epoch=4&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--mode=int&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--wbit=4&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;--abit=4&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;env&amp;#34;&lt;/span>:{&lt;span style="color:#e6db74">&amp;#34;CUDA_VISIBLE_DIVICES&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意 &lt;code>nproc_per_node&lt;/code> 是 Python 自带的参数，因此可以写到里面，对于 &lt;code>--dataset=imagenet&lt;/code> 会有报错。&lt;/p>
&lt;p>&lt;code>--dataset=imagenet&lt;/code> 要放到 &lt;code>main.py&lt;/code> 的后面，这个方法相当于用调整参数的形式来达到目的。不太有通用性，相当于专门改了一个 &lt;code>launch.json&lt;/code> 文件。&lt;/p>
&lt;h2 id="32-几种并行的方式">3.2 几种并行的方式&lt;/h2>
&lt;p>转载自 &lt;a href="https://zhuanlan.zhihu.com/p/430383324">https://zhuanlan.zhihu.com/p/430383324&lt;/a>&lt;/p>
&lt;h3 id="321-data-parallelism">3.2.1 Data Parallelism&lt;/h3>
&lt;p>模型在forward和backward的中间计算过程都会有中间状态，这些中间状态通常占用的空间是和batch size成正比的。&lt;/p>
&lt;blockquote>
&lt;p>也就是梯度等信息吧&lt;/p>
&lt;/blockquote>
&lt;p>方法是将大的 batch size 切分都多个 GPU 上；不过这种方式主要切分的是 batch size 正比的部分中间状态。但是对于parameter, optimizer state等batch size无关的空间开销是无能为力的。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;strong>什么是 parameter？&lt;/strong>&lt;/p>
&lt;p>parameter: 模型可以根据数据可以自动学习出的变量，应该就是参数。比如，深度学习的权重，偏差等&lt;/p>
&lt;p>hyperparameter: 就是用来确定模型的一些参数，超参数不同，模型是不同的(这个模型不同的意思就是有微小的区别，比如假设都是CNN模型，如果层数不同，模型不一样，虽然都是CNN模型哈。)，超参数一般就是根据经验确定的变量。在深度学习中，超参数有：&lt;strong>学习速率，迭代次数，层数，每层神经元的个数&lt;/strong> 等等。&lt;/p>
&lt;h3 id="322-model-parallelism">3.2.2 Model Parallelism&lt;/h3>
&lt;p>把模型本身进行切分，使得每个 GPU 卡只需要存储模型的一部分。&lt;/p>
&lt;p>MP在一些应用场景（比如上面说的ResNet例子）在计算一个minibatch时，硬件是依次激活的，其他硬件都在等待，硬件的利用率会非常的低。&lt;/p>
&lt;blockquote>
&lt;p>简单地说，就是并行比较差&lt;/p>
&lt;/blockquote>
&lt;h3 id="323-pipeline-parallelism">3.2.3 Pipeline Parallelism&lt;/h3>
&lt;p>前面提到了MP一个比较大的问题是GPU利用率低。当没有计算到某个GPU上的模型分片时，这个GPU常常是闲着的。PP一定程度上解决了这个问题。&lt;/p>
&lt;p>PP的思想也比较简单，使用了经典的Pipeline思想。在模型计算流水线上，每个GPU只负责模型的一个分片，计算完就交给下一个GPU完成下一个模型分片的计算。当下个GPU在计算时，上一个GPU开始算下一个minibatch属于它的模型分片。&lt;/p>
&lt;blockquote>
&lt;p>经典的流水线设计思想&lt;/p>
&lt;/blockquote>
&lt;h1 id="4-hook">4. Hook&lt;/h1>
&lt;p>这个功能被广泛用于可视化神经网络中间层的 feature、gradient，从而诊断神经网络中可能出现的问题，分析网络有效性。&lt;/p>
&lt;p>视频：https://www.youtube.com/watch?v=syLFCVYua6Q&lt;/p>
&lt;p>pytorch 计算图似乎只会保留叶子节点的梯度，舍弃中间的梯度&lt;/p>
&lt;blockquote>
&lt;p>简而言之，register_hook的作用是，反向传播时，除了完成原有的反传，额外多完成一些任务。你可以定义一个中间变量的hook，将它的grad值打印出来，当然你也可以定义一个全局列表，将每次的grad值添加到里面去。&lt;/p>
&lt;/blockquote>
&lt;p>什么是中间变量：有的博客里有提到，似乎是没有直接指定数值，而是通过计算得到的变量。比如下面的 z 就是中间变量。z 的梯度是不会保存的&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor([&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>requires_grad_()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor([&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">7&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>requires_grad_()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>z &lt;span style="color:#f92672">=&lt;/span> x &lt;span style="color:#f92672">+&lt;/span> y &lt;span style="color:#75715e"># 中间变量&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>output &lt;span style="color:#f92672">=&lt;/span> model(input)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 此时会做几件事，一个是调用 forward 方法计算结果，一个是判断有没有注册 forward_hook，有的话就将 forward 的输入及结果作为 hook 的实参&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="41-register_hook">4.1 register_hook&lt;/h2>
&lt;p>&lt;code>z.register_hook(hook_fn)&lt;/code>，这个 hook_fn 是一个用户自定义函数，返回 Tensor （如果需要对 grad 进行修改）或者 None（用于直接打印，不修改），所以直接用 lambda 函数即可，&lt;code>z.register_hook(lambda grad: print(grad))&lt;/code>&lt;/p>
&lt;blockquote>
&lt;p>个人理解下来，register_hook 可以实现保留中间变量梯度的功能，而且不像 &lt;code>retain_grad&lt;/code> 那样会带来很大的开销&lt;/p>
&lt;/blockquote>
&lt;h3 id="411-register_forward_hook">4.1.1 register_forward_hook&lt;/h3>
&lt;p>&lt;strong>作用&lt;/strong>：获取中间层的 feature map&lt;/p>
&lt;p>通常，pytorch 只提供了网络整体的输入和输出，对于夹在网络中间的模块，很难获得他的输入输出。除非设计网络时，在 forward 函数的返回值中包含中间 module 的输出。总而言之别的方法都比较麻烦，pytorch 设计好了 register_forward_hook 和 register_backward_hook。&lt;/p>
&lt;p>相比针对 tensor 的 register_hook，这个 forward hook 没有返回值，也就是不能改变输入，只能打印。&lt;/p>
&lt;p>&lt;strong>注意&lt;/strong>，在 forward hook 中，input 是 x，而不包括 W 和 b。&lt;/p>
&lt;p>代码实例，讲的非常清晰，来自&lt;a href="https://cloud.tencent.com/developer/article/1475430">博客&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>Class Model(nn&lt;span style="color:#f92672">.&lt;/span>Module):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 全局变量，用于存储中间层的 feature&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total_feature_out &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total_feature_in &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> Model()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 定义 forward hook function&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">hook_fn_forward&lt;/span>(module, input, output):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(module) &lt;span style="color:#75715e"># 用于区分模块&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;input&amp;#39;&lt;/span>, input) &lt;span style="color:#75715e"># 首先打印出来&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;output&amp;#39;&lt;/span>, output)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> total_feature_out&lt;span style="color:#f92672">.&lt;/span>append(output) &lt;span style="color:#75715e"># 然后分别存入全局 list 中&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> total_feature_in&lt;span style="color:#f92672">.&lt;/span>append(input)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 给每个 module 都装上 hook&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> name, module &lt;span style="color:#f92672">in&lt;/span> model&lt;span style="color:#f92672">.&lt;/span>named_children():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> module&lt;span style="color:#f92672">.&lt;/span>register_forward_hook(hook_fn_forward)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 前向传播和回传&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor([[&lt;span style="color:#ae81ff">1.0&lt;/span>, &lt;span style="color:#ae81ff">1.0&lt;/span>, &lt;span style="color:#ae81ff">1.0&lt;/span>]])&lt;span style="color:#f92672">.&lt;/span>requires_grad_()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>o &lt;span style="color:#f92672">=&lt;/span> model(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>o&lt;span style="color:#f92672">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;==========Saved inputs and outputs==========&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> idx &lt;span style="color:#f92672">in&lt;/span> range(len(total_feature_in)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;input: &amp;#39;&lt;/span>, total_feature_out[idx])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;output: &amp;#39;&lt;/span>, total_feature_out[idx])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="412-register_backward_hook">4.1.2 register_backward_hook()&lt;/h3>
&lt;h4 id="4121-使用方法和示例">4.1.2.1 使用方法和示例&lt;/h4>
&lt;p>&lt;strong>作用&lt;/strong>：用于获取梯度&lt;/p>
&lt;p>&lt;strong>使用&lt;/strong>：&lt;code>module.register_backward_hook(hook_fn)&lt;/code>, &lt;code>hook_fn(module, grad_input, grad_output) -&amp;gt; Tensor or None&lt;/code>&lt;/p>
&lt;p>如果有多个输入或者输出，grad_input, grad_output 可以是 tuple 类型。比如对于线性模块，grad_input 是一个三元组，分别是 $g_{bias}$, $g_x$, $g_W$，对 bias 的导数，对 x 的导数以及对 weight 的导数。&lt;/p>
&lt;p>直接看代码，这个代码是可以直接跑的，不得不说写的确实很好。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> torch &lt;span style="color:#f92672">import&lt;/span> nn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Model&lt;/span>(nn&lt;span style="color:#f92672">.&lt;/span>Module):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> super(Model, self)&lt;span style="color:#f92672">.&lt;/span>__init__()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc1 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Linear(&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>relu1 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>ReLU()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc2 &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Linear(&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>initialize()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">initialize&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>no_grad():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc1&lt;span style="color:#f92672">.&lt;/span>weight &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>nn&lt;span style="color:#f92672">.&lt;/span>Parameter(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor([[&lt;span style="color:#ae81ff">1.&lt;/span>, &lt;span style="color:#ae81ff">2.&lt;/span>, &lt;span style="color:#ae81ff">3.&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">4.&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">5.&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">6.&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">7.&lt;/span>, &lt;span style="color:#ae81ff">8.&lt;/span>, &lt;span style="color:#ae81ff">9.&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">10.&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">11.&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">12.&lt;/span>]]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc1&lt;span style="color:#f92672">.&lt;/span>bias &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>nn&lt;span style="color:#f92672">.&lt;/span>Parameter(torch&lt;span style="color:#f92672">.&lt;/span>Tensor([&lt;span style="color:#ae81ff">1.0&lt;/span>, &lt;span style="color:#ae81ff">2.0&lt;/span>, &lt;span style="color:#ae81ff">3.0&lt;/span>, &lt;span style="color:#ae81ff">4.0&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc2&lt;span style="color:#f92672">.&lt;/span>weight &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>nn&lt;span style="color:#f92672">.&lt;/span>Parameter(torch&lt;span style="color:#f92672">.&lt;/span>Tensor([[&lt;span style="color:#ae81ff">1.0&lt;/span>, &lt;span style="color:#ae81ff">2.0&lt;/span>, &lt;span style="color:#ae81ff">3.0&lt;/span>, &lt;span style="color:#ae81ff">4.0&lt;/span>]]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>fc2&lt;span style="color:#f92672">.&lt;/span>bias &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>nn&lt;span style="color:#f92672">.&lt;/span>Parameter(torch&lt;span style="color:#f92672">.&lt;/span>Tensor([&lt;span style="color:#ae81ff">1.0&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">forward&lt;/span>(self, x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> o &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>fc1(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> o &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>relu1(o)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> o &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>fc2(o)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 全局变量，用于存储中间层的 feature&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total_grad_out &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total_grad_in &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> Model()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 定义 forward hook function&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">hook_fn_backward&lt;/span>(module, grad_input, grad_output):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(module) &lt;span style="color:#75715e"># 用于区分模块&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 为了符合反向传播顺序，先打印 grad_output&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;grad_output&amp;#39;&lt;/span>, grad_output)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;grad_input&amp;#39;&lt;/span>, grad_input)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> total_grad_out&lt;span style="color:#f92672">.&lt;/span>append(grad_output)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> total_grad_in&lt;span style="color:#f92672">.&lt;/span>append(grad_input)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 给每个 module 都装上 hook&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> name, module &lt;span style="color:#f92672">in&lt;/span> model&lt;span style="color:#f92672">.&lt;/span>named_children():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> module&lt;span style="color:#f92672">.&lt;/span>register_backward_hook(hook_fn_backward)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 前向传播和回传&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 这里的 requires_grad 很重要，如果不加，backward hook&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 执行到第一层，对 x 的导数将为 None，某英文博客作者这里疏忽了&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 此外再强调一遍 x 的维度，一定不能写成 torch.Tensor([1.0, 1.0, 1.0]).requires_grad_()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 否则 backward hook 会出问题。&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor([[&lt;span style="color:#ae81ff">1.0&lt;/span>, &lt;span style="color:#ae81ff">1.0&lt;/span>, &lt;span style="color:#ae81ff">1.0&lt;/span>]])&lt;span style="color:#f92672">.&lt;/span>requires_grad_()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>o &lt;span style="color:#f92672">=&lt;/span> model(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>o&lt;span style="color:#f92672">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;==========Saved inputs and outputs==========&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> idx &lt;span style="color:#f92672">in&lt;/span> range(len(total_grad_in)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;input: &amp;#39;&lt;/span>, total_grad_in[idx])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;output: &amp;#39;&lt;/span>, total_grad_out[idx])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>注意&lt;/strong>，作者提到“register_backward_hook只能操作简单模块，而不能操作包含多个子模块的复杂模块。如果对复杂模块用了 backward hook，那么我们只能得到该模块最后一次简单操作的梯度信息。”不太确定什么是简单模块，不太确定诸如 resnet18 这样的网络是不是简单模块。&lt;/p>
&lt;p>2022-08-06 23:14:22，这个地方应该是想说，用 for loop 遍历 model.named_children() 是有必要的，否则直接 &lt;code>model = Model()model.register_backward_hook(hook_fn_backward)&lt;/code> 会有问题。&lt;/p>
&lt;h4 id="4122-注意事项">4.1.2.2 注意事项&lt;/h4>
&lt;p>&lt;strong>形状&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>在卷积层中，weight 的梯度和 weight 的形状相同&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在全连接层中，weight 的梯度的形状是 weight 形状的转秩（观察上文中代码的输出可以验证）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>grad_input tuple 中各梯度的顺序&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>在卷积层中，bias 的梯度位于tuple 的末尾：grad_input = (对feature的导数，对权重 W 的导数，对 bias 的导数)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在全连接层中，bias 的梯度位于 tuple 的开头：grad_input=(对 bias 的导数，对 feature 的导数，对 W 的导数)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>当 batchsize &amp;gt; 1 时，对 bias 的梯度处理不同&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>在卷积层，对 bias 的梯度为整个 batch 的数据在 bias 上的梯度之和：grad_input = (对feature的导数，对权重 W 的导数，对 bias 的导数)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在全连接层，对 bias 的梯度是分开的，bach 中每条数据，对应一个 bias 的梯度：grad_input = ((data1 对 bias 的导数，data2 对 bias 的导数 &amp;hellip;)，对 feature 的导数，对 W 的导数)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="misc">Misc&lt;/h1>
&lt;p>@classmethod 用法&lt;/p>
&lt;p>想给初始类再新添功能，不需要改初始类，只要在下一个类内部新写一个方法，方法用@classmethod装饰一下即可。、&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@classmethod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">convert_sync_batchnorm&lt;/span>(cls, module, process_group&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>):
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="5-autodiff">5. AutoDiff&lt;/h1>
&lt;blockquote>
&lt;p>深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。 实际中，根据我们设计的模型，系统会构建一个计算图（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。 自动微分使系统能够随后反向传播梯度。 这里，反向传播（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。&lt;/p>
&lt;/blockquote>
&lt;p>by &lt;a href="https://zh-v2.d2l.ai/chapter_preliminaries/autograd.html">https://zh-v2.d2l.ai/chapter_preliminaries/autograd.html&lt;/a>&lt;/p>
&lt;h1 id="6-只使用一个-gpu">6. 只使用一个 GPU&lt;/h1>
&lt;h2 id="61-文件中">6.1 文件中&lt;/h2>
&lt;p>注意这个必须放在 &lt;del>&lt;code>import torch&lt;/code> 之前&lt;/del> 放在所有访问GPU的代码之前&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>os&lt;span style="color:#f92672">.&lt;/span>environ[&lt;span style="color:#e6db74">&amp;#39;CUDA_VISIBLE_DEVICES&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="问题">问题&lt;/h1>
&lt;ul>
&lt;li>Debug 的时候怎么看 tensor 变量的参数？&lt;/li>
&lt;/ul>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/265394674">https://zhuanlan.zhihu.com/p/265394674&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/">https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/&lt;/a> pytorch 中文文档&lt;/p>
&lt;p>&lt;a href="https://cloud.tencent.com/developer/article/1475430">https://cloud.tencent.com/developer/article/1475430#&lt;/a>&lt;/p></description></item><item><title>国内硕博如何提升自己的英语</title><link>https://huweim.github.io/post/%E5%8D%9A%E5%AE%A2_%E5%9B%BD%E5%86%85%E5%8D%9A%E5%A3%AB%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E8%87%AA%E5%B7%B1%E7%9A%84%E8%8B%B1%E8%AF%AD/</link><pubDate>Sat, 16 Jul 2022 16:39:35 +0800</pubDate><guid>https://huweim.github.io/post/%E5%8D%9A%E5%AE%A2_%E5%9B%BD%E5%86%85%E5%8D%9A%E5%A3%AB%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E8%87%AA%E5%B7%B1%E7%9A%84%E8%8B%B1%E8%AF%AD/</guid><description>&lt;p>这个是最近（2022-07-16 16:09:15）我一直在思考的问题。因为之后可能会选择在国内度过自己的博士生涯。目前的英语水平可以说是完全不够的。并不是说 paper 看多了，英语水平就上去了。听说读写是耦合在一起的，没有国外的英文环境，就需要有意识地去提升自己的英语水平。&lt;/p>
&lt;h1 id="1-一些建议">1. 一些建议&lt;/h1>
&lt;p>即使到了国外，可能也很难通过和外国人交朋友来提升自己的英文水平，英语提升还是需要刻意去练习的。&lt;/p>
&lt;ul>
&lt;li>可以根据自己的喜好，坚持地去阅读或者听一些东西，比如电视新闻评论，转播的篮球比赛，电视剧，TED 演讲等等。一个是选择自己喜欢的东西，做起来没有额外的开销，另一个是要 &lt;strong>坚持&lt;/strong>，自己的学习就非常零散。&lt;/li>
&lt;li>读自己写的东西，也就是读出声音。&lt;/li>
&lt;/ul>
&lt;h1 id="2-施一公如何提高科研写作能力">2. 施一公：如何提高科研写作能力&lt;/h1>
&lt;h2 id="21-他是怎么做的">2.1 &lt;strong>他是怎么做的&lt;/strong>？&lt;/h2>
&lt;ul>
&lt;li>每天花 45 分钟读《华盛顿邮报》。他每天早上安排完第一批实验后，会在十点左右花一个小时阅读《华盛顿邮报》，主要看新闻版
&lt;ul>
&lt;li>这里的重点其实不是读什么，而是每天都坚持&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>阅读变多了，他常常会有自己动笔去写的冲动。《巴尔的摩太阳报》也刊登了他的信刊。&lt;/li>
&lt;/ul>
&lt;h2 id="22-一些经历">2.2 &lt;strong>一些经历&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>他在 1994 年写完论文之后感觉很差，自己都不愿意再读第二遍，就交给了老板。（我自己也感觉自己写的是一坨屎，不想再看）&lt;/li>
&lt;li>他的老板花了 4 个小时把文章的整体写完了，只缺少 method 和 reference，并且根本没用施一公的初稿
&lt;ul>
&lt;li>&lt;strong>写文章贵在一气呵成&lt;/strong>，之后他也沿袭这个风格，两次一晚上通宵赶一篇文章。不过前提是对研究领域非常熟悉，对文章整体的大概思路已经深思熟虑，所有的 figures 已经做好了。&lt;/li>
&lt;li>这些前期工作，全身心投入也得花费 3-4 天。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="23-总结">2.3 &lt;strong>总结&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>保持阅读英文文章的习惯，每天 30-60 分钟。从英文报纸，英文新闻开始，逐渐转为专业的杂志&lt;/li>
&lt;li>写科研论文，最重要的是逻辑。必须先讨论出一套清晰的思路，根据思路作图（也就是逻辑 flow，或者结构），然后再动笔开始写&lt;/li>
&lt;li>写作时，根据思路写一个 subheading 框架，也就是设计好每个部分的小标题。第一稿切忌每句话都追求完美（这个深有体会，自己第一次写作时知道这一点，但是又忍不住反复琢磨一个词一句话，因为词汇量匮乏，这个要通过反复练习来避免）
&lt;ul>
&lt;li>第一稿追求的重点是逻辑（logic flow），要注意前后句的逻辑关系，相邻两段的逻辑关系&lt;/li>
&lt;li>写作时，全力以赴，不受任何事情干扰（关闭手机，座机，微信等），争取在最短时间内拿出第一稿&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>照葫芦画瓢&lt;/strong>。学习自己领域内文章的一些固定表达，整理一些局势，但切忌抄袭。在美国的一些机构，连续 7 个英文单词和别人完全一样，原则上就被认为是抄袭（plagiarism）&lt;/li>
&lt;li>第一稿写完后，给自己不超过一天的休息时间，开始改第二稿。修改时还是逻辑为主，每句话都要推敲，要学会同义替换（thesaurus），避免过多重复。第二稿非常关键，往后可能不会大改了。&lt;/li>
&lt;li>第二稿以后的修改，关注具体的字句，逻辑基本定型。投稿前，整体读一遍。一篇文章不会因为个别语法错误被拒，但一定会因为逻辑混乱被拒。&lt;/li>
&lt;/ul>
&lt;h1 id="3-可行的方案">3. 可行的方案&lt;/h1>
&lt;p>实际上，最难的部分还是每天坚持，下面列一些可行的方案。阅读 paper 自然不用说，这个是自然的。但是除了阅读 paper 以外，也应该坚持阅读一些新闻杂志。&lt;/p>
&lt;ul>
&lt;li>观看 &lt;strong>LinusTechTips&lt;/strong> 频道的视频。这是一个科技频道，每个视频 10 分钟左右，也是自己感兴趣的方向。（听，读）&lt;/li>
&lt;li>每天早上阅读一篇英文新闻。（读）&lt;/li>
&lt;li>每周，根据一周阅读的 paper，写一篇英文 reivew。一般 paper reading 都会记下笔记，前期可以把模板固定好。有了笔记的总结和格式模板，熟练之后的开销就只有写作了。（写）&lt;/li>
&lt;li>（option），italk，定期和别人对话，练习口语。（听，说）&lt;/li>
&lt;li>（option），B 站关注听说方面的 up，每天边听边跟读。（听，说）&lt;/li>
&lt;li>坚持&lt;/li>
&lt;li>坚持&lt;/li>
&lt;li>坚持，这个是最难的&lt;/li>
&lt;/ul></description></item><item><title>VSCode, Chrome 常用快捷键</title><link>https://huweim.github.io/post/%E5%B7%A5%E5%85%B7_%E5%BF%AB%E6%8D%B7%E9%94%AE_vscode_chrome/</link><pubDate>Fri, 10 Jun 2022 15:27:08 +0800</pubDate><guid>https://huweim.github.io/post/%E5%B7%A5%E5%85%B7_%E5%BF%AB%E6%8D%B7%E9%94%AE_vscode_chrome/</guid><description>&lt;h1 id="1-vscode">1. VSCode&lt;/h1>
&lt;p>&lt;strong>目前生疏但是需要常用的&lt;/strong> 2022-06-10 15:14:48&lt;/p>
&lt;ul>
&lt;li>&amp;#x2b50; 选择所有当前选中的字符（可以理解为全局版的 Ctrl + D）: Ctrl + Shift + L&lt;/li>
&lt;li>在选中行末尾插入光标：Alt + Shift + i&lt;/li>
&lt;li>在右侧打开 Markdown 预览：Ctrl + K, V&lt;/li>
&lt;li>查看定义：Alt + F12；只是小窗查看，比较方便，注意跳转和查看的区别&lt;/li>
&lt;li>重新打开最后关闭的标签页：Ctrl + Shift + T&lt;/li>
&lt;li>向左切换标签：Ctrl + Tab / Ctrl + PgDn&lt;/li>
&lt;li>向右切换标签：Ctrl + Shift + Tab / Ctrl + PgUp&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>快捷键的意义不在于记住每一个键位，而是你需要知道某个操作是可以通过快捷键达到的。当你需要多次重复这个操作时，可以去查找这个快捷键。&lt;/p>
&lt;/blockquote>
&lt;h2 id="11-编辑">1.1 编辑&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>选中当前单词 Ctrl + D，多次按的话可以批量更改变量&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&amp;#x2b50; 选择所有当前选中的字符（可以理解为全局版的 Ctrl + D）: Ctrl + Shift + L&lt;/p>
&lt;/li>
&lt;li>
&lt;p>选择所有出现的当前单词：Ctrl + F2；不用选中，光标放在单词上即可，相当于先 Ctrl + D 然后 Ctrl + Shift + L&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>控制台终端显示与隐藏&lt;/strong>：Ctrl + ~&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>选中代码 ：&lt;/strong> Shift + Home/End/方向键 （配置 Ctrl 使用效果更佳）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>全局替换：&lt;/strong> Ctrl + Shift + H&lt;/p>
&lt;/li>
&lt;li>
&lt;p>分屏 Ctrl + \&lt;/p>
&lt;/li>
&lt;li>
&lt;p>合并分屏 Ctrl + Alt + \&lt;/p>
&lt;/li>
&lt;li>
&lt;p>重新打开最后关闭的标签页：Ctrl + Shift + T&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在选中行末尾插入光标/也就是 1.3 中的多行编辑：Alt + Shift + i&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在右侧打开 Markdown 预览：Ctrl + K, V&lt;/p>
&lt;/li>
&lt;li>
&lt;p>向左切换标签：Ctrl + Tab / Ctrl + PgDn&lt;/p>
&lt;/li>
&lt;li>
&lt;p>向右切换标签：Ctrl + Shift + Tab / Ctrl + PgUp&lt;/p>
&lt;/li>
&lt;li>
&lt;p>按单词跳转 &amp;#x2b50; Ctrl + 方向键&lt;/p>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>这个非常常用，可以快速地在单行的单词之前跳转光标&lt;/p>
&lt;/blockquote>
&lt;p>行操作&lt;/p>
&lt;ul>
&lt;li>&lt;strong>复制当前行&lt;/strong>：Shift + Alt + Up/Down / Ctrl + C&lt;/li>
&lt;li>剪切当前行 Ctrl + X&lt;/li>
&lt;li>&lt;strong>删除当前行&lt;/strong>：Shift + Ctrl + K&lt;/li>
&lt;li>选择整行 Ctrl + L&lt;/li>
&lt;li>移动选中的行：Alt + Up/Down&lt;/li>
&lt;li>跳转到指定行 Ctrl + G&lt;/li>
&lt;/ul>
&lt;h2 id="12-编程">1.2 编程&lt;/h2>
&lt;ul>
&lt;li>Go to definition: Ctrl + 鼠标左键/F12&lt;/li>
&lt;li>显示所有引用：Shift + F12&lt;/li>
&lt;li>跳转到光标的上一个位置： Alt + 方向键←&lt;/li>
&lt;li>参数提示：Ctrl + Shift + Space&lt;/li>
&lt;li>查看定义：Alt + F12；只是小窗查看，比较方便，注意跳转和查看的区别&lt;/li>
&lt;/ul>
&lt;h2 id="13-多行编辑">1.3 多行编辑&lt;/h2>
&lt;p>Step&lt;/p>
&lt;ul>
&lt;li>选中多行；可以用鼠标，也可以用 Ctrl + Shift + 方向键/Home/End&lt;/li>
&lt;li>按下快捷键 Alt + Shift + i，进入多行编辑状态&lt;/li>
&lt;/ul>
&lt;h2 id="14-文件">1.4 文件&lt;/h2>
&lt;p>打开新窗口：Ctrl + N
打开文件：Ctrl + P
选择文件：Ctrl + O
最近打开的 workplace: Ctrl + R&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="2-chrome">2. Chrome&lt;/h1>
&lt;p>&lt;strong>最常用&lt;/strong>并且目前比较生疏 2022-06-10 14:45:52&lt;/p>
&lt;ul>
&lt;li>新建标签页：Ctrl + T&lt;/li>
&lt;li>向左切换标签：Ctrl + Tab / Ctrl + PgDn&lt;/li>
&lt;li>向右切换标签：Ctrl + Shift + Tab / Ctrl + PgUp&lt;/li>
&lt;li>跳转到地址栏：Ctrl + l / Alt + D / F6&lt;/li>
&lt;/ul>
&lt;h2 id="21-标签和窗口">2.1 标签和窗口&lt;/h2>
&lt;p>个人认为会比较常用的&lt;/p>
&lt;ul>
&lt;li>新建标签页：Ctrl + T&lt;/li>
&lt;li>重新打开最后关闭的标签页：Ctrl + Shift + T&lt;/li>
&lt;li>向左切换标签：Ctrl + Tab / Ctrl + PgDn&lt;/li>
&lt;li>向右切换标签：Ctrl + Shift + Tab / Ctrl + PgUp&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>2022-06-10 14:24:50，向左右切换标签正是在寻找的功能，这个也可以用在 VSCode 窗口中使用。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>在新的后台标签页中打开链接：Ctrl + 单击 / 鼠标滚轮单机&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>可以代替 右键 -&amp;gt; 在新标签页中打开链接&lt;/p>
&lt;/blockquote>
&lt;p>其他&lt;/p>
&lt;ul>
&lt;li>新建窗口：Ctrl + N&lt;/li>
&lt;li>新建无痕窗口：Ctrl + Shift + N&lt;/li>
&lt;li>标签内打开 Home 页面：Alt + Home&lt;/li>
&lt;li>最小化当前窗口：Alt + 空格键 + N&lt;/li>
&lt;li>最大化当前窗口：Alt + 空格键 + X&lt;/li>
&lt;li>在新窗口打开链接： Shift + 单击&lt;/li>
&lt;/ul>
&lt;h2 id="22-功能">2.2 功能&lt;/h2>
&lt;p>个人认为常用，好像没有特别常用的。。&lt;/p>
&lt;p>其他&lt;/p>
&lt;ul>
&lt;li>下载内容：Ctrl + J&lt;/li>
&lt;li>历史记录：Ctrl + H&lt;/li>
&lt;li>开发者工具：F12 / Ctrl + Shift + J / Ctrl + Shift + I&lt;/li>
&lt;li>保存网页：Ctrl + S&lt;/li>
&lt;li>添加书签：Ctrl + D&lt;/li>
&lt;li>添加所有打开的网页添加书签：Ctrl + Shift + D&lt;/li>
&lt;li>书签管理器：Ctrl + Shift + O&lt;/li>
&lt;li>用浏览器打开文件：Ctrl + O&lt;/li>
&lt;li>任务管理器：Shift + Esc&lt;/li>
&lt;li>清除历史记录：Ctrl + Shift + Del&lt;/li>
&lt;/ul>
&lt;h2 id="23-地址栏">2.3 地址栏&lt;/h2>
&lt;p>&lt;strong>个人认为常用&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>地址栏搜索：Ctrl + K / Ctrl + E&lt;/li>
&lt;li>跳转到地址栏：Ctrl + l / Alt + D / F6&lt;/li>
&lt;li>站内搜索：关键字 + site：网址&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>快速跳转到地址栏是需要掌握的
站内搜索：关键字 + site：网址，这个如果使用 google 需要翻墙，并不是单纯地字符串匹配。&lt;/p>
&lt;/blockquote>
&lt;p>其他&lt;/p>
&lt;ul>
&lt;li>使用其他搜索引擎进行搜索：Tab&lt;/li>
&lt;li>为网站名称添加 www. 和 .com：Ctrl + Enter&lt;/li>
&lt;/ul>
&lt;h2 id="24-页面">2.4 页面&lt;/h2>
&lt;p>个人认为常用&lt;/p>
&lt;ul>
&lt;li>搜索：Ctrl + F&lt;/li>
&lt;li>刷新：Ctrl + R / F5 / Ctrl + F5&lt;/li>
&lt;li>调整页面字体大小：Ctrl + &amp;lsquo;&amp;rsquo;+&amp;rsquo;&amp;rsquo; / Ctrl + &amp;lsquo;&amp;rsquo;-&amp;rsquo;&amp;rsquo; 或者 Ctrl + 鼠标滚轮上/下&lt;/li>
&lt;/ul>
&lt;p>其他&lt;/p>
&lt;ul>
&lt;li>先下翻页：PgUp&lt;/li>
&lt;li>向上翻页：PgDn&lt;/li>
&lt;li>滑动到最顶部：Home&lt;/li>
&lt;li>滑动到最底部：End&lt;/li>
&lt;li>打印：Ctrl + P&lt;/li>
&lt;li>页面字体恢复默认：Ctrl + 0&lt;/li>
&lt;li>全屏切换：F11&lt;/li>
&lt;/ul>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/43730820#:~:text=Chrome%20%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%A4%A7%E5%85%A8%201%20%E5%90%8C%E4%B8%AA%E7%AA%97%E5%8F%A3%E6%96%B0%E5%BB%BA%E6%A0%87%E7%AD%BE%EF%BC%9ACtrl%20%2B%20T%202%20%E9%87%8D%E6%96%B0%E6%89%93%E5%BC%80%E6%9C%80%E5%90%8E%E5%85%B3%E9%97%AD%E7%9A%84%E6%A0%87%E7%AD%BE%E9%A1%B5%EF%BC%9ACtrl,%2F%20Ctrl%20%2B%20Shift%20%2B%20...%20%E6%9B%B4%E5%A4%9A%E7%BB%93%E6%9E%9C...%20">https://zhuanlan.zhihu.com/p/43730820#:~:text=Chrome%20%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%A4%A7%E5%85%A8%201%20%E5%90%8C%E4%B8%AA%E7%AA%97%E5%8F%A3%E6%96%B0%E5%BB%BA%E6%A0%87%E7%AD%BE%EF%BC%9ACtrl%20%2B%20T%202%20%E9%87%8D%E6%96%B0%E6%89%93%E5%BC%80%E6%9C%80%E5%90%8E%E5%85%B3%E9%97%AD%E7%9A%84%E6%A0%87%E7%AD%BE%E9%A1%B5%EF%BC%9ACtrl,%2F%20Ctrl%20%2B%20Shift%20%2B%20...%20%E6%9B%B4%E5%A4%9A%E7%BB%93%E6%9E%9C...%20&lt;/a>&lt;/p></description></item><item><title>（转载）MLSys 个方向综述</title><link>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_%E8%BD%AC%E8%BD%BDmlsys-%E4%B8%AA%E6%96%B9%E5%90%91%E7%BB%BC%E8%BF%B0/</link><pubDate>Mon, 09 May 2022 22:17:43 +0800</pubDate><guid>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_%E8%BD%AC%E8%BD%BDmlsys-%E4%B8%AA%E6%96%B9%E5%90%91%E7%BB%BC%E8%BF%B0/</guid><description>&lt;p>最近在试着寻找ML + sys可做的方向，发现涉及到的坑太多了，有点眼花缭乱的感觉&amp;hellip;&amp;hellip;不如写点东西总结一哈，帮自己理一下思路。&lt;/p>
&lt;p>个人感觉MLsys不能算是一种方向，而是一种思路&amp;hellip;&amp;hellip;比如对于system研究者来说，可以把ML作为我们开发的系统要适配的一种benchmark，就像transaction对于数据库、某种文件场景对于File System的意义一样。这样一想可做的空间就宽广多了。就算ML哪天又进入寒冬，之前所学的技术也仍然是可持续的。传统的system研究者也应该适应这个潮流，不能简单的把MLsys一律归为大水漫灌..&lt;/p>
&lt;p>有很多topic我也是初次接触，还不是很熟悉。如有错误还请批评指点~&lt;/p>
&lt;h1 id="1-分布式机器学习distributed-dnn-training">1. 分布式机器学习（Distributed DNN Training）&lt;/h1>
&lt;p>这个又可以分为两个方面：from ML / system perspective。安利一下刘铁岩老师的《分布式机器学习》这本书（[ch_]表示引用这本书中的一些章节），还有UCB cs294 19fall的这一节。&lt;/p>
&lt;h2 id="11-ml">1.1 ML&lt;/h2>
&lt;p>从ML的角度做，主要是发明或改进分布式训练算法[ch4] [ch5]，保证在分布式加速的同时，仍然能达到原来的学习效果（loss/accuracy）。因此很多工作也被投在像ICML、NIPS这种专业ML会议上。主要用到的方法包括优化（optimization）和统计学习理论（statistical learning theory）。&lt;/p>
&lt;p>还有一类工作涉及到如何把单机算法改造成分布式[ch9]，比如同步/异步SGD等。这里主要涉及到的问题是如何降低分布式环境下的通信开销，提高加速比。&lt;/p>
&lt;p>这方面了解不多就少写点了&amp;hellip; 可以参考这里。&lt;/p>
&lt;h2 id="12-system">1.2 System&lt;/h2>
&lt;p>还有一个就是从System的角度做。从分布式计算的角度来看，可以把相关工作分为以下几类：&lt;/p>
&lt;p>对于计算量太大的场景（计算并行），可以多线程/多节点并行计算，多节点共享公共的存储空间。常用的一个算法就是同步随机梯度下降（synchronous stochastic gradient descent），含义大致相当于K个（K是节点数）mini-batch SGD [ch6.2]
对于训练数据太多，单机放不下的场景（数据并行，也是最主要的场景），需要将数据划分到多个节点上训练。每个节点先用本地的数据先训练出一个子模型，同时和其他节点保持通信（比如更新参数）以保证最终可以有效整合来自各个节点的训练结果，并得到全局的ML模型。 [ch6.3]
对于模型太大的场景，需要把模型（例如NN中的不同层）划分到不同节点上进行训练。此时不同节点之间可能需要频繁的sync。这个叫做模型并行。 [ch6.4]
Pipeline Parallelism：这是去年（SOSP19 PipeDream）才出现的概念，参考这里的第90、95页 以及这里的简介。Pipeline Parallelism相当于把数据并行和模型并行结合起来，把数据划分成多个chunk，也把训练模型的过程分成了Forward Pass和Backward Pass两个stage。然后用流水线的思想进行计算。
另外，分布式ML本质上还是分布式系统嘛，所以像传统分布式系统里的一些topic（比如一致性、fault tolerance、通信、load balance等等）也可以放到这个背景下进行研究。&lt;/p>
&lt;p>最近挖的比较多的坑大致涉及以下几个点：&lt;/p>
&lt;h3 id="111-分布式ml系统设计">1.1.1 分布式ML系统设计&lt;/h3>
&lt;p>[ch7.3] 最著名的就是几大分布式DL模型：Parameter Server / AllReduce等。&lt;/p>
&lt;p>个人感觉这里面一个可以挖的坑是Decentralized Training。地里一位大佬也在做这个方向。&lt;/p>
&lt;h3 id="112-edge-computing">1.1.2 Edge Computing&lt;/h3>
&lt;p>很多ML模型是需要在手机上运行的（比如毁图秀秀）。针对这一场景，一个是要对手机这种低功耗设备对ML model进行裁剪加速（后面会提到），还有一个要做的就是运行在多个device上的分布式ML。&lt;/p>
&lt;p>这里有个最近非常火的概念：Federated Learning。其实本质还是炒数据并行的冷饭&amp;hellip;不过应用场景比较不一样。FL更多是为了Privacy的考虑，而分布式加速训练在这里倒是个次要目标。FL还涉及到了模型聚合[ch8]，也就是如何把多个device本地训练出的模型合并到一起。&lt;/p>
&lt;h3 id="113-大量计算资源的scheduling--device-placement">1.1.3 大量计算资源的Scheduling / device placement&lt;/h3>
&lt;p>UCB的CS294 19spring对这一节有过介绍。&lt;/p>
&lt;p>这里的计算资源的数量级是很大的&amp;hellip;&amp;hellip;比如工业界会有万台CPU服务器 / 上千台GPU服务器搭建的DL平台。这个小方向要解决的问题就是如何充分利用它们的性能。比如在阿里PAI组的JD里就有这么一条：“设计探索高效的分布式Placement算法，以更系统化的方式来解决大规模深度学习高效训练的问题”。&lt;/p>
&lt;p>这方面比较早的工作大概是这篇paper，说的是如何为TensorFlow计算图里的不同算子分配不同的device，最后用强化学习实现了这个目标。这个工作看起来有点prototype，但提出了一个新的思路。另外还有很多猛如虎的类似Train XX model in y minutes的工作。这种就不仅是placement好就能完成的了，还需要涉及系统拓扑的设计、降低communication开销等等。&lt;/p>
&lt;p>对于集群调度，工业界的一个热点是使用容器平台（例如k8s）来运行分布式机器学习应用。虽然k8s本身就有容器集群调度的功能，但为了让它更好地适应ML的workload，人们开发了一些新的轮子，比如针对TensorFlow（Parameter Server模型）和PyTorch的KubeFlow。还有用k8s来跑AutoML的katib。学术界对这方面的一个研究热点是GPU集群调度，在下面2.2节会介绍。&lt;/p>
&lt;h3 id="114-communication相关">1.1.4 communication相关&lt;/h3>
&lt;p>[ch3.5] [ch7]介绍了一些宏观上的通信模型，但深入进去还有很多可搞的坑。传统搞网络/分布式系统的组比较契合这个小方向。&lt;/p>
&lt;p>例如我校的分布式组原来有一些geo-distributed system的工作，现在也可以往ML上装。&lt;/p>
&lt;h3 id="115-其他sys-for-ml可做的坑">1.1.5 其他sys for ML可做的坑&lt;/h3>
&lt;p>工业界的一个ML pipeline不仅仅是训练，还涉及到很多其他的坑。这些是目前被挖的还比较少的：&lt;/p>
&lt;p>存储 / Data Management：&lt;/p>
&lt;ol>
&lt;li>训练数据的规模是很大的。如何为ML设计一个专用的文件系统（类似大数据界的HDFS）或者数据库来加速读数据呢？ 类似的工作有管理ML model的ModelDB.&lt;/li>
&lt;li>在ML framework中，以及Parameter Server中，需要用一个KV storage system来存储参数。可不可以针对ML的场景优化这个KV存储系统呢？ 关于这个可以参考neopenx大神的blog。&lt;/li>
&lt;/ol>
&lt;h1 id="2-深度学习模型压缩加速-star">2. 深度学习模型压缩/加速 &amp;#x2b50;&lt;/h1>
&lt;p>这方面和architecture结合比较紧密。CS229有这一节，也可以参考NIPS19上的这个talk。&lt;/p>
&lt;p>对DL model进行压缩主要考虑两个角度：减少计算量（例如conv层的计算量） / 内存占用（NN的参数数量）。不仅要考虑ML上的metric，也要考虑system层面的performance（例如latency / throughput / 功耗。有时候这些比ML模型的accuracy还重要）。具体的方式大概有以下几种：&lt;/p>
&lt;ol>
&lt;li>Architectural Compression
Layer Design -&amp;gt; Typically using factorization techniques to reduce storage and computation
Pruning（剪枝） -&amp;gt; Eliminating weights, layers, or channels to reduce storage and computation from large pre-trained models. 减少卷积核大小 / 通道数等等&lt;/li>
&lt;li>Weight Compression
Low Bit Precision Arithmetic -&amp;gt; Weights and activations are stored and computed using low bit precision
Quantized（量化） Weight Encoding -&amp;gt; Weights are quantized and stored using dictionary encodings.
很多相关的工作是在ML的角度来压缩模型的（也就是Arch Compression，特别是针对CNN和RNN。比如很著名的MobileNet）。这里我们先(kan)略(bu)过(dong)，来看从System的角度是如何加速的。&lt;/li>
&lt;/ol>
&lt;h2 id="21-通过quantized量化降低计算精度要求-starstar">2.1 通过Quantized（量化）降低计算精度要求 &amp;#x2b50;&amp;#x2b50;&lt;/h2>
&lt;p>量化的含义是将卷积层（the weights and / or activations of a CNN）通常要用到的32位浮点数用更低位的数来表示，如int32, int16, int8等等，来降低资源占用（float32无论是计算还是存储都是很吃资源的..）。量化之后无疑会损失一部分精度，但神经网络对噪声并不是特别敏感，因此控制好量化的程度之后对ML任务的影响可以很小。&lt;/p>
&lt;p>一种常用的量化方法是train in floating point and then quantize the resulting weights，训练时还是用float32（因为要涉及到反向传播和梯度下降，全是int就很难搞了..），但在inference的阶段就可以加速啦。一个直观的方法是事先找好一般网络参数的min / max值，然后将训练好的网络参数乘一个scala factor来映射到[MIN_INT, MAX_INT]区间内的整数存起来。在inference时先按int来计算，最后结果再转换回float32。这一过程中其实加速了大量的卷积计算。比如这篇paper就实现了float32到int8的量化。&lt;/p>
&lt;p>混合精度计算：上面讲的方法是用在inference阶段的，其实在模型训练时也可以用类似的方法来加速，只不过再用int就不大行了。一种比较新的方法是用float16（也就是俗称的半精度），fp16占用空间是单精度(fp32)的一半，双精度(double，也就是fp64)的1/4。&lt;/p>
&lt;p>量化的具体实现方法可以参考这里。NVIDIA专门推出了针对inference阶段量化加速的工具包TensorRT&lt;/p>
&lt;h2 id="22-新硬件--dl-acclerator-starstar">2.2 新硬件 / DL Acclerator &amp;#x2b50;&amp;#x2b50;&lt;/h2>
&lt;p>在纯硬件方面针对DL workload的工作也有很多，这里来看几个parallel相关的技术。最近Data-Level Parallelism不仅在深度学习中，在其他一些领域（比如数据库）也有了越来越多的应用。&lt;/p>
&lt;p>CPU：尽管GPU已经成了深度学习计算的标配，有时候仍然是需要CPU运算的。例如要在手机等辣鸡设备上进行inference。&lt;/p>
&lt;p>SIMD：SIMD的含义是同一条指令在多个数据流上操作，和在向量处理器中一样。在具体实现中（例如SSE指令集）是把一个128位SSE寄存器（这是新增加的SIMD专用寄存器，和早期借用FPU寄存器的MMX不同。在SSE指令集中是增加了8个这种寄存器）划分成4个块，同时存放4个float32单精度浮点数，4个块可以同时进行运算（有多个运算单元，作用于不同的地址），这样就提高了并行度。后来的SSE2 / SSE3 / SSE4 / AVX指令集在此基础上又增加对float64 / 更多运算的支持，以及扩展了SIMD专用寄存器的位数，但本质上还是一样的。　　另外，SIMD带来的并行和超标量处理器的并行性（一个周期issue多个指令，用于instruction level parallelism）不是一个概念。非超标量处理器也可以SIMD，而超标量处理器可以更并行issue多个SIMD操作。&lt;/p>
&lt;p>VLIW：和一次issue多条指令，然后靠硬件进行ILP调度（也叫动态多发射。需要硬件实现乱序执行、分支预测等操作）的超标量处理器不同，VLIW（Very Large Instruction Width，采用这种技术的处理器也叫做静态多发射处理器）的含义是一次只issue一条可以完成多个操作的复杂长指令（也叫发射包，其实从软件的角度看是多条指令的集合）。因此一条指令的位宽可以很大。VLIW是通过编译器来进行指令级并行调度的（比如一个常用的方法是循环展开，通过识别出可并行的重叠跨循环体指令块来实现ILP）。VLIW的本意是希望在编译阶段就识别出程序中的依赖关系（静态调度），得到可以并行执行的发射包，硬件只需要根据调度好的发射包直接执行即可，这样就简化了硬件实现，从而实现更大宽度发射包的并行执行。intel Itanium的IA64指令集就使用了这个技术，但它在当年并没有取得成功。一个重要的原因是它只适合计算密集、算法固定可控的workload。传统的通用应用程序可能很难具备这个属性（有很多run-time才能确定的值，另外cache访问也是不确定的），但深度学习任务具备这些性质。&lt;/p>
&lt;p>GPU：GPU的本质可以看做SIMT（Single Instruction Multiple Threads）。&lt;/p>
&lt;ul>
&lt;li>GPU集群：DL框架一般都支持GPU和分布式训练，已经可以在GPU集群环境下运行了，但实际上还存在一些问题导致分布式场景下资源的使用率提不上去：1). CPU和GPU之间memcpy开销太大、2). 参数通信开销太大、3). 显存不够用、4). GPU很难虚拟化(多任务共享)、5).需要针对ML workload的更好的集群调度策略。 对于1和3其实也可以用前面提到的神经网络压缩、模型并行等方法解决； 对于2一个解决方案是尽量让计算和通信在时间上重叠起来，参考ATC17的Poseidon； MSR对于5做了很多工作，一方面是对大规模GPU集群上的真实日志数据进行分析，得出了一些经验（发表在ATC19）。另一方面是设计一些更好的scheduling策略，例如OSDI2018的Gandiva（针对DL workload自身的特点来提高GPU集群使用率）和NSDI2019的Tiresias； 对于4目前还没啥很好的解决方案，但可以通过一些软调度方案来模拟。&lt;/li>
&lt;li>这学期8205课上会有GPGPU的topic，到时候再补充 &amp;#x2b50;&amp;#x2b50;&amp;#x2b50;&lt;/li>
&lt;/ul>
&lt;p>系统结构：这个和纯计算关系不是很大，可能暂时和ML加速也没啥关系（事实上目前在计算机网络研究中用的还多一些）&amp;hellip;&amp;hellip;但对于优化整体性能会有帮助&lt;/p>
&lt;ul>
&lt;li>NUMA：当单个CPU性能已经到瓶颈时，多处理器就成了比较好的解决方案。为了方便编程，需要保证能为应用程序提供跨越所有处理器的单一物理地址空间，这种也叫做共享内存处理器（Shared Memory Processor）。SMP又可以分为两种类型：1) 任何处理器访问任何地址的仿存时间都是相同的，叫做统一存储访问（Uniform Memory Access）。 2) 对于每个核心，访问某些字会比访问其他字快一些，整个内存空间被分割并分配给不同处理器 / 内存控制器，这叫做非统一存储访问（NonUniform Memory Access，NUMA）。NUMA虽然看起来复杂，但可以支持更大的规模（更多的核心），并且访问附近的存储器时具有较低的延迟。 在过去内存控制器还在北桥的时代，多处理器用的是UMA（所有处理器都通过FSB总线连接北桥，再访问内存）。后来随着核心越来越多，为提高访存速度，内存处理器被做到了CPU内，每个CPU有（或者很少的几个核心共享）一个内存控制器，然后直连一部分内存空间，这些核心就被归为一个NUMA node。而跨NUMA node之间的内存访问需要走QPI总线。可以参考这里的图解。 在一些涉及many core的工作中会经常用到NUMA的概念&lt;/li>
&lt;li>RDMA：在网络环境中会用到。RDMA全称是Remote Direct Memory Access，用于实现不需要OS参与的远程内存访问（因为message passing through kernel会浪费本来很大的内存和网络带宽）。具体的技术细节可以参考这里。不过最近（Eurosys2019）已经有了应用RDMA来加速分布式机器学习的工作。&lt;/li>
&lt;/ul>
&lt;p>专用硬件：CPU性能太菜，GPU又太庞大，于是人们开发了AI专用芯片&lt;/p>
&lt;ul>
&lt;li>FPGA：全称是Field Programmable Gate Array，是可以多次烧写的。因为本质上属于软件所以可以快速开发 / 迭代。&lt;/li>
&lt;li>ASIC：全称是application-specific integrated circuits，出厂后电路就不可以改变了（需要流片）。但是性能比FPGA高。Google的TPU就属于一种ASIC。&lt;/li>
&lt;/ul>
&lt;h2 id="23-矩阵算子优化">2.3 矩阵算子优化&lt;/h2>
&lt;p>神经网络中的很多运算本质上就是对矩阵运算，因此可以用一些矩阵乘法优化方案来加速。比如cublas就是封装好的针对矩阵和向量运算的加速库，而对于神经网络加速则会使用cudnn&lt;/p>
&lt;p>算子优化是个非常贴近hardware的工作，对多种设备都人工调优这些算子其实是比较难的&amp;hellip;如果能简化一部分工作就最好啦。于是就有了下面会提到的深度学习编译器。&lt;/p>
&lt;blockquote>
&lt;p>这个工作可能偏向于工业界&lt;/p>
&lt;/blockquote>
&lt;h2 id="24-automl">2.4 AutoML&lt;/h2>
&lt;p>这个严格来说可能不算MLsys了&amp;hellip;但它的思路在很多MLsys问题中也会被用到&lt;/p>
&lt;p>AutoML最早只能调很有限的几种参数，用的方法也比较暴力（启发式搜索）。后来能调的东西越来越多，方法也更加猛如虎&amp;hellip;一个里程碑是NAS，标志着神经网络结构也可以Auto了。&lt;/p>
&lt;p>常用的调参方法大致可以分为这几种：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>随机搜索，或者说叫启发式搜索。包括 GridSearch 和 RandomSearch。这种方法的改进空间主要体现在使用不同的采样方法生成配置，但本质上仍然是随机试验不同的配置，没有根据跑出来的结果来反馈指导采样过程，效率比较低。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Multi-armed Bandit。这种方法综合考虑了“探索”和“利用”两个问题，既可以配置更多资源（也就是采样机会）给搜索空间中效果更优的一部分，也会考虑尝试尽量多的可能性。Bandit 结合贝叶斯优化，就构成了传统的 AutoML 的核心。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>深度强化学习。强化学习在 AutoML 中最著名的应用就是 NAS，用于自动生成神经网络结构。另外它在 深度学习参数调优 中也有应用。它的优点是从“从数据中学习”转变为“从动作中学习”（比如某个参数从小调到大），既可以从性能好的样本中学习，也可以从性能坏的样本中学习。但强化学习的坑也比较多，体现在训练可能比较困难，有时结果比较难复现。
之所以把AutoML也列出来，是因为这些方法在下面提到的ML for system问题中会很有用。比如之前做过的AutoTiKV就应用了一种贝叶斯优化方法来调节数据库参数。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>cs294中给出了几个可提高的方向：&lt;/p>
&lt;p>Accelerate data collection and preparation&lt;/p>
&lt;ul>
&lt;li>Automatic data discovery&lt;/li>
&lt;li>Distributed data processing, esp. for image and video data&lt;/li>
&lt;li>Data cleaning and schema driven auto-featurization&lt;/li>
&lt;/ul>
&lt;p>Accelerate model selection and hyper-parameter search&lt;/p>
&lt;ul>
&lt;li>Parallel and distributed execution&lt;/li>
&lt;li>Data and feature caching across training runs&lt;/li>
&lt;/ul>
&lt;p>Provenance&lt;/p>
&lt;ul>
&lt;li>Track previous model development to inform future decisions&lt;/li>
&lt;li>Connect errors in production with decisions in model development&lt;/li>
&lt;/ul>
&lt;h1 id="3-深度学习框架系统设计">3. 深度学习框架/系统设计&lt;/h1>
&lt;p>和Distributed Training的区别是这里更关注一些工程上的东西（框架设计、API设计等等）。一个Deep Learning Framework大致需要以下几个元素：&lt;/p>
&lt;ul>
&lt;li>支持各种算子(op) 和 tensor (data)&lt;/li>
&lt;li>计算图的定义方式（动态 v.s. 静态）&lt;/li>
&lt;li>Auto Diff&lt;/li>
&lt;li>Optimizer（例如Adam）&lt;/li>
&lt;li>各种加速和优化的库：cudnn, openblas,mkl等&lt;/li>
&lt;/ul>
&lt;h2 id="31-deep-learning-framework">3.1 Deep Learning Framework&lt;/h2>
&lt;p>这一节重点关注这几个方向：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Differentiable Programming：如果用过Keras或者PyTorch就会记得它可以简单得像搭积木一样摞一个NN出来，只需要定义一个一个的层（前向传播逻辑）和损失函数就行了。而NN的训练需要Backward Propagation / Forward Propagation，也就是计算微分，运算时framework可以根据定义好的计算图自动求导算梯度。只要可微分就可以保证这个积木能摞出来，然后使用链式法则就可以自动计算微分（Automatic Differentiation）。如果一个语言或者framework具备了Differentiable Programming的性质，就可以更简单的在它上面开发Deep Learning应用（可以类比python手写NN和Keras的区别）。这篇文章对Auto Diff的实现做了很详细的介绍。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Embedded Domain Specific Languages：DSL的概念我们都知道，比如SQL就是数据库系统中的DSL，但这已经相当于一个全新的语言了。Embedded DSL是在现有语言上（例如Python）针对某个特定任务做的扩展。比如为了让Python做矩阵计算更方便发明了numpy；为了进行机器学习就有了TensorFlow / PyTorch等等。Embedded DSL的作用是完成 Linear Algebra -&amp;gt; Pipelines -&amp;gt; Differentiable Programs 的转化。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>根据计算图的定义方式，可以分为Declarative Abstraction（Embedded DSL先生成静态计算图，类似编译执行 define-and-run，例如Tensorflow、Caffe）和Imperative（Embedded DSL生成动态计算图并直接输出结果，类似解释执行 define-by-run，例如PyTorch、Tensorflow Eager）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>对于具体的DL框架来说，虽然很多公司都开始自研框架了，但最流行的基本就TensorFlow、PyTorch、mxnet等等那几家了。不过最近又出现了分布式强化学习框架Ray，也具有很好的落地潜能。&lt;/p>
&lt;blockquote>
&lt;p>确实如此，工业界很多公司都在做自己的框架了。&lt;/p>
&lt;/blockquote>
&lt;h2 id="32-inference--model-serving">3.2 Inference / Model Serving&lt;/h2>
&lt;p>之前关注了很多训练ML模型中会遇到的问题。但实际应用场景里，inference（直接使用训练好的模型predict）的次数会比training多很多，因此inference的性能也很重要。&lt;/p>
&lt;p>Inference可以再分为以下两种：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Offline: Pre-Materialize Predictions：所有可能的query都是已知的，就事先predict好存起来。一般没有这么玩的&amp;hellip;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Online: Compute Predictions on the fly：根据用户的输入实时predict。这才是最常见的场景&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>一个典型的ML inference pipeline大致涉及到以下工序：&lt;/p>
&lt;ul>
&lt;li>input data&lt;/li>
&lt;li>-&amp;gt; Preprocessing(比如图片要resize)&lt;/li>
&lt;li>-&amp;gt; model prediction(有时候会同时用很多model，还要ensemble起来)&lt;/li>
&lt;li>-&amp;gt; 输出结果，有时候还要处理一下&lt;/li>
&lt;/ul>
&lt;p>这个pipeline的衡量指标包括Latency、Throughput等（和传统的system问题一样呀）。cs294里列出了几个最近的工作，可以参考这里的paper解读。个人感觉这里可做的坑不多&amp;hellip;.大多是修修补补&amp;hellip;&lt;/p>
&lt;h2 id="33深度学习编译器">3.3深度学习编译器&lt;/h2>
&lt;p>这里值得提一下TVM。这篇文章对TVM进行了非常详细的介绍。&lt;/p>
&lt;p>简单的说TVM是在把训练好的ML model部署在不同设备上时用的，重点关注的是Inference而不是Training（也就是推理引擎）。在这一过程中，模型本身可能用了不同的framework来写（比如tensorflow / PyTorch / MXNet，本质区别在于使用的算子类型可能不一样），而要部署到的设备也可能有不同的硬件架构（比如x86 / ARM / GPU / FPGA）。inference的过程也就是将framework X写出来的model放在硬件Y上运行的过程，这一过程和编译器是非常相似的（将语言X写的程序编译到硬件Y上运行），这也就是深度学习编译器的含义。&lt;/p>
&lt;p>为了设计一个高效的深度学习编译器，TVM借鉴了传统编译器LLVM的设计思想：抽象出编译器前端[ 高级语言C/java -&amp;gt; IR ]，编译器中端[ 优化IR，这种是不同编译器平台共享的 ]，编译器后端[ IR -&amp;gt; 目标硬件上的binary ]等概念，引入IR (Intermediate Representation。深度学习问题中可以将计算图作为IR，称为Graph IR)。这样不同硬件/framework都对标同一套IR，就避免了需要对每种硬件和framework排列组合适配的问题。TVM主要解决的是后端的问题[在目标硬件上高效运行IR]。而前端的问题[生成和优化IR]就交给深度学习框架们完成（针对这一步，在TVM stack中提供了NNVM，作用是represent workloads from different frameworks into standardized computation graphs）。&lt;/p>
&lt;p>TVM是和硬件深度集成的，也就是需要针对每种硬件平台实现相关的AI算子（类似NVIDIA GPU上的cuDNN）。然而人工调优这些算子的实现是很费精力的（特别是要针对不同形状的业务模型），这里面也有一些knob需要调整。为了让这个过程也能ML化，于是后来有了AutoTVM。&lt;/p>
&lt;p>cs294 sp19还提出了几个可能的future work：&lt;/p>
&lt;ul>
&lt;li>Compilers are great at Ahead of Time scheduling, what about Just-In-Time scheduling?&lt;/li>
&lt;li>Any way we can share GPU in predictable way and maximize utilization for DNN inference?&lt;/li>
&lt;li>Can we optimize for “fitness” of the kernel when it’s executed along with other kernels instead of its latency?&lt;/li>
&lt;/ul>
&lt;h1 id="4-用ml优化传统的system问题">4. 用ML优化传统的system问题&lt;/h1>
&lt;p>这里面的花样就更多了&amp;hellip;在上学期Jon的ML system课上有过较详细的接触。大部分是用ML去优化一个传统system问题中，一些需要人工经验调整、或者说可以从历史情况learn到一些东西的模块。比如数据库参数、操作系统页表、数据库索引等等。一个模块可以被ML化的前提是它必须是empirical的，参考它在页表（OS的工作集原理）、数据库（DBA是个很吃经验的活&amp;hellip;）中的应用。如果人工都看不出来啥规律就别指望它能ML了&amp;hellip;&lt;/p>
&lt;p>一般认为用ML优化system的思想是起源于Jeff Dean在NIPS2017的workshop。这方面的工作很多发表在纯system的顶级会议以及下属的AI for xxx workshop上，另外一些AI会议的workshop也会收录一些这方面的工作，比如nips 2018的MLsys workshop。从2017年开始已经有很多坑被做过了，但个人感觉还是有一些搞头的。感觉可以从下面两个角度再来搞：&lt;/p>
&lt;p>同样的scenario，使用更合适的ML算法。注意这里是更合适，而不是更高大上猛如虎。
比如这篇ML+Database的paper，使用了LSTM来预测未来的workload pattern，还要用GPU训练，但生产环境上要求数据库服务器也安个显卡是不现实的。工程上的一个解决方案是搞个集中式的训练集群（类似OtterTune），在DBaaS的情况下这种方法倒是行得通，但在对外发布的数据库产品中就不行了。
这里感觉可以参考早期AutoML的一些工作，因为它们本质是很类似的（都是调参嘛&amp;hellip;）。传统方法有启发式搜索/贝叶斯优化。最近也有很多人用强化学习去搞，但还是存在太吃资源的问题&amp;hellip;
这方面对ML知识的要求高一点。
寻找system界更多可以ML化的场景。这个更适合专业的system researcher来做，对ML倒是略有了解即可。
有一类思路是把ML深度集成到系统设计中，比如Andy在2019年的15-721课上提到过Self-Driving Database的概念，和之前用ML优化数据库的工作不同的是，Self-Driving DB更关注如何把ML和DB深度集成，而不是搞一个又一个外挂的模块了。
一个类似的工作是在OS领域：https://engineering.purdue.edu/WukLab/LearnedOS-OSR19.pdf 。
另外还有个工作是在Key-Value Storage Engine的领域：https://arxiv.org/pdf/1907.05443.pdf。它提出了Design Continuum的概念：存储系统中的很多数据结构本质上是很像的（arise from the very same set of fundamental design principles），例如B+tree, LSM-tree, LSH-table等，但它们却有不同的应用场景（比如KV Store中用LSM就比B+ Tree更合适），很难有一个十全十美的设计。这说明它们有相互替换的空间。这样我们可以将不同数据结构的选择也作为存储系统的一个knob，根据具体workload和硬件的情况来自动选择一个合适的底层数据结构（find a close to optimal data structure design for a key-value store given a target workload and hardware environment）。
一个更宏观一些的思路是做system and algorithm co-design，让任意计算机系统都能和ml深度集成。虽然具体的target system不一样，但其中有很多模块都是类似的（例如training、inference、system monitor等等）。针对这一目标MSR提出了AutoSys，对这些通用模块进行了整合。&lt;/p>
&lt;blockquote>
&lt;p>这部分就如同用 ML 方法去选择调度算法一样，比较 trick。&lt;/p>
&lt;/blockquote>
&lt;h1 id="5-其他">5. 其他&lt;/h1>
&lt;p>方向不是很契合就先不看了&amp;hellip;等用到了再填坑&lt;/p>
&lt;p>ML pipeline / lifecycle：https://ucbrise.github.io/cs294-ai-sys-fa19/assets/lectures/lec03/03_ml-lifecycle.pdf
Privacy：https://ucbrise.github.io/cs294-ai-sys-fa19/assets/lectures/lec10/10_adversarial_ml.pdf
图神经网络训练系统：https://www.msra.cn/zh-cn/news/features/2019-review-machine-learning-system [ATC19 NeuGraph]&lt;/p>
&lt;p>需要的技能树
这是从一些公司ML System Research Scientist岗位的招聘要求中整理出来的，更侧重system一些。&lt;/p>
&lt;p>System：&lt;/p>
&lt;p>工程基础：C/C++、OO programming。阅读源码是个很好的学习方式
OS
分布式系统
编译原理。特别是编译器优化技术、LLVM、memory optimization。Parser之类不喜欢也可以不看
Computer Architecture。另外还需要了解：1.GPU架构，例如显存分配机制、CPU与GPU交互。 2.CPU、存储系统相关的新技术。 3.有条件可以了解下深度学习专用硬件。
常见的并行计算框架，例如MPI/OpenMP/CUDA
ML framework的底层原理，扒源码
工业界的一些新东西：例如k8s、KubeFlow、ElasticDL
ML：&lt;/p>
&lt;p>机器学习基础
常见的分布式机器学习算法、DL模型压缩、模型加速方法（根据具体方向而定）
数理基础不要太菜…不要被人吐槽像没学过高中数学…&lt;/p>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/104444471">https://zhuanlan.zhihu.com/p/104444471&lt;/a>&lt;/p></description></item><item><title>cmake 目录结构和使用</title><link>https://huweim.github.io/post/%E5%B7%A5%E5%85%B7_cmake-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 09 May 2022 22:17:43 +0800</pubDate><guid>https://huweim.github.io/post/%E5%B7%A5%E5%85%B7_cmake-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E4%BD%BF%E7%94%A8/</guid><description>&lt;h1 id="0-前言">0. 前言&lt;/h1>
&lt;p>cuTLASS 使用到了 cmake，之前没有接触过，先学习一下他的目录结构和编译过程。&lt;/p>
&lt;p>2023-03-16 11:25:11，在学习一个工具时，Getting Started 或许是最快的入门方式。&lt;/p>
&lt;h2 id="01-cmake-简介">0.1 Cmake 简介&lt;/h2>
&lt;p>对于 C++ 程序，手动编写 Makefile 非常麻烦。cmake 用于自动编写 Makefile。通过读取 CMakeLists.txt 文件，可以自动生成 make 文件。cmake 中 macro 和 function 的使用，使得 cmake 更像是一个脚本语言。&lt;/p>
&lt;h2 id="02-安装">0.2 安装&lt;/h2>
&lt;p>官方给出了建议的环境，cmake 没有安装，apt-get install 安装的是 3.12 版本，不符合要求。手动安装一下 3.20 cmake，&lt;a href="https://gist.github.com/bmegli/4049b7394f9cfa016c24ed67e5041930">教程&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># get and build CMake&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>wget https://github.com/Kitware/CMake/releases/download/v3.24.0/cmake-3.24.0.tar.gz
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tar -zvxf cmake-3.24.0.tar.gz
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cd cmake-3.24.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./bootstrap
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make -j8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># add path&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export PATH&lt;span style="color:#f92672">=&lt;/span>$PATH:$CUDA_INSTALL_PATH/bin:~/cmake-3.24.0/bin
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意有个 BUG，&lt;code> Could NOT find OpenSSL,&lt;/code>，&lt;code>apt-get install libssl-dev&lt;/code> 即可&lt;/p>
&lt;h2 id="03-基本特性">0.3 基本特性&lt;/h2>
&lt;p>cmake 命令不区分大小写，但是变量区分大小写。&lt;/p>
&lt;h1 id="1-简介">1. 简介&lt;/h1>
&lt;h2 id="11-带有-cmake-的项目">1.1 带有 cmake 的项目&lt;/h2>
&lt;p>介绍最基本的，带有 cmake 的项目的整体结构&lt;/p>
&lt;h3 id="111-目录结构">1.1.1 目录结构&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>|-- bin &lt;span style="color:#75715e">#存放可执行文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>|-- build &lt;span style="color:#75715e">#目录用于存放编译生成的文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- dependencies &lt;span style="color:#75715e">#存放 external libraries or dependencies that are required by the project being built&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- CMakeFiles
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>|-- CMakeLists.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>|-- include &lt;span style="color:#75715e">#统一存放头文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- hello.h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- gpgpu.h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>|-- lib
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>|-- README.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>|-- src
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- CMakeLists.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- main.cpp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- model1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| | |-- CMakeLists.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| | |-- gpgpu.cpp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| | |-- model.cpp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| |-- model2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| | |-- CMakeLists.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| | |-- hello.cpp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>| | |-- model.cpp
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于大一点的项目可能还会需要 util 目录，library 目录夹或者 tool 目录&lt;/p>
&lt;p>&lt;strong>src&lt;/strong>: 这个 example 包含了 2 models，main.cpp 依赖于 2 基础 models，另外，注意到他们都包含 &lt;code>CMakeLists.txt&lt;/code> 文件&lt;/p>
&lt;h2 id="112-理解-cmakeliststxt">1.1.2 理解 CMakeLists.txt&lt;/h2>
&lt;p>注意 cmake 文件中不区分大小写&lt;/p>
&lt;blockquote>
&lt;p>In a CMake-based project, each directory containing C++ source code should contain a CMakeLists.txt file. This file describes the rules for building the code in that directory.&lt;/p>
&lt;/blockquote>
&lt;p>2023-03-16 14:19:11，每个 dir 下都要有一个 CMakeLists.txt&lt;/p>
&lt;p>最基础的包含以下一些信息，&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 规定该CMakeLists.txt适用的cmake最小版本，这里是 3.12，自己手动安装了 3.20 版本&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cmake_minimum_required&lt;span style="color:#f92672">(&lt;/span>VERSION 3.12.4 FATAL_ERROR&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 项目名称，也就是 cutlass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>project&lt;span style="color:#f92672">(&lt;/span>CUTLASS VERSION 2.9.0 LANGUAGES CXX&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 定义生成的可执行文件(程序)的名称，假设为 gemm&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 这里没找到 cutlass 对应的，cutlass 中有一个 function(cutlass_add_executable_tests NAME TARGET)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>add_executable &lt;span style="color:#f92672">(&lt;/span>gemm gemm.cxx&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 指定头文件搜索路径，根目录下 include&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>include_directories &lt;span style="color:#f92672">(&lt;/span>include&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="12-cmake-编译过程">1.2 cmake 编译过程&lt;/h2>
&lt;h3 id="121-build-编译并运行">1.2.1 build, 编译并运行&lt;/h3>
&lt;p>build 目录用于存放编译生成的文件，一般的编译过程：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ mkdir build &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> cd build
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">75&lt;/span> &lt;span style="color:#75715e"># compile for NVIDIA Turing GPU architecture&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="122-问题可执行程序在哪个目录生成">1.2.2 问题，可执行程序在哪个目录生成？&lt;/h3>
&lt;p>看起来似乎是和 Makefile 文件同一目录，而 cutlass 中，执行 make 操作之后，会对程序进行编译，然后直接运行。由于在 sim 上运行需要把 gpgpusim.config 放到程序运行的目录下，所以我们需要知道是在哪个目录运行的。&lt;/p>
&lt;p>cmake 设置 library and executable 文件的存放路径：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>set&lt;span style="color:#f92672">(&lt;/span>LIBRARY_OUTPUT_PATH path&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>set&lt;span style="color:#f92672">(&lt;/span>EXECUTABLE_OUTPUT_PATH path&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>如果子目录中的某个CMakeLists.txt中设置了 set(&amp;hellip;)，就以当前文件中设置的路径为主，否则以父目录中设置的路径为主&lt;/p>
&lt;/blockquote>
&lt;p>如果都没设置呢？从简单的程序来看，在 &lt;code>build&lt;/code> 目录下 &lt;code>cmake .. XXXX&lt;/code>，在 &lt;code>build&lt;/code> 目录下生成 Makefile，执行 &lt;code>make &amp;amp; make install&lt;/code>，可执行程序就在当前（&lt;code>build&lt;/code>） 目录下。&lt;/p>
&lt;h3 id="123-cmake-文件变量赋值">1.2.3 cmake 文件变量赋值&lt;/h3>
&lt;p>cutlass 编译 example 报错，不确定问题是不是出在变量的传递。&lt;/p>
&lt;p>2023-03-14 15:49:24，似乎是编译 example 的方式不对。&lt;/p>
&lt;h3 id="124-制定-cuda-编译器">1.2.4 制定 cuda 编译器&lt;/h3>
&lt;p>使用 CMAKE_CUDA_COMPILER 这个内建变量可以做到。&lt;/p>
&lt;p>可以通过命令 &lt;code>cmake -DCMAKE_CUDA_COMPILER=&amp;quot;xxx&amp;quot;&lt;/code> 来修改&lt;/p>
&lt;h1 id="2-命令行参数编译选项-command-line-option">2. 命令行参数，编译选项 command line option&lt;/h1>
&lt;h2 id="21--d">2.1 -D&lt;/h2>
&lt;p>原来 -D 是一个传参选项，怪不得在 CMakeList 里面直接搜索 -DCUTLASS_NVCC_ARCHS，没有找到这个命令。&lt;/p>
&lt;p>-D 的作用就是定义变量的默认值，比如 &lt;code>-DCUTLASS_NVCC_ARCHS=75&lt;/code>，也就是定义了 &lt;code>CUTLASS_NVCC_ARCHS&lt;/code> 的值&lt;/p>
&lt;p>此外，&lt;code>CUTLASS_NVCC_ARCHS&lt;/code> 的属性应该得是一个 CACHE STRING，否则可能无法被改变&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>set&lt;span style="color:#f92672">(&lt;/span>CUTLASS_NVCC_ARCHS &lt;span style="color:#e6db74">${&lt;/span>CUTLASS_NVCC_ARCHS_SUPPORTED&lt;span style="color:#e6db74">}&lt;/span> CACHE STRING &lt;span style="color:#e6db74">&amp;#34;The SM architectures requested.&amp;#34;&lt;/span>&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>set&lt;span style="color:#f92672">(&lt;/span>CUTLASS_LIBRARY_KERNELS &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span> CACHE STRING &lt;span style="color:#e6db74">&amp;#34;Comma delimited list of kernel name filters. If unspecified, only the largest tile size is enabled. If &amp;#39;all&amp;#39; is specified, all kernels are enabled.&amp;#34;&lt;/span>&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>那么，尝试修改 &lt;code>CMAKE_CUDA_ARCHITECTURES&lt;/code>，找到给其赋值，并且属性为 CACHE STRING 的 &lt;code>TCNN_CUDA_ARCHITECTURES&lt;/code>，使用命令行实现：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>cmake . -B build -DTCNN_CUDA_ARCHITECTURES&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;75&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="23-cmake_progress_start">2.3 cmake_progress_start&lt;/h2>
&lt;h2 id="24--b-指定构建目录的路径--s-指定源代码目录">2.4 -B 指定构建目录的路径 -S 指定源代码目录&lt;/h2>
&lt;p>&lt;code>/home/wmhu/cmake-3.24.0/bin/cmake -S/home/wmhu/work/tiny-cuda-nn -B/home/wmhu/work/tiny-cuda-nn/build --check-build-system CMakeFiles/Makefile.cmake 0&lt;/code>&lt;/p>
&lt;p>&lt;code>--check-build-system&lt;/code> 选项用于检查构建系统是否可用，以及检查是否需要重新构建&lt;/p>
&lt;p>0 是一个可选的参数，用于设置生成Makefile时的调试级别。&lt;/p>
&lt;h1 id="3-command-命令">3. Command 命令&lt;/h1>
&lt;p>有点像函数，但是英文是 command&lt;/p>
&lt;h2 id="31-set-系列">3.1 set 系列&lt;/h2>
&lt;h3 id="311-set-normal-value">3.1.1 Set Normal Value&lt;/h3>
&lt;p>&lt;code>set (&amp;lt;variable&amp;gt; &amp;lt;value&amp;gt;... [PARENT_SCOPE])&lt;/code>
&lt;code>set(CMAKE_CXX_FLAGS &amp;quot;-std=c++11 ${CMAKE_CXX_FLAGS}&amp;quot;)&lt;/code>&lt;/p>
&lt;blockquote>
&lt;p>If the PARENT_SCOPE option is given the variable will be set in the scope above the current scope. Each new directory or function() command creates a new scope. A scope can also be created with the block() command.&lt;/p>
&lt;/blockquote>
&lt;p>目前还没有太明白 scope 的概念。&lt;/p>
&lt;h3 id="312-set-cache-entry">3.1.2 Set Cache Entry&lt;/h3>
&lt;p>&lt;code>set(&amp;lt;variable&amp;gt; &amp;lt;value&amp;gt;... CACHE &amp;lt;type&amp;gt; &amp;lt;docstring&amp;gt; [FORCE])&lt;/code>&lt;/p>
&lt;p>&lt;code>FORCE&lt;/code> option to overwrite existing entries&lt;/p>
&lt;h2 id="32-add-系列">3.2 add 系列&lt;/h2>
&lt;h3 id="321-添加编译选项-add_compilie_options">3.2.1 添加编译选项 add_compilie_options&lt;/h3>
&lt;p>对于 C/C++ 代码，一般来说，编译选项命名为 FLAG。可以通过 &lt;code>add_compilie_options&lt;/code> 命令设置编译选项，也可以通过 &lt;code>set&lt;/code> 命令修改 &lt;code>CMAKE_CXX_FLAGS&lt;/code> 或者 &lt;code>CMAKE_C_FLAGS&lt;/code>。&lt;/p>
&lt;ul>
&lt;li>&lt;code>add_compile_options&lt;/code> 添加的选项是针对所有编译器，包括 C 和 C++&lt;/li>
&lt;li>set 命令设置的 &lt;code>CMAKE_CXX_FLAGS&lt;/code> 或者 &lt;code>CMAKE_C_FLAGS&lt;/code> 变量分别针对 C 和 C++&lt;/li>
&lt;/ul>
&lt;p>e.g.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cmake" data-lang="cmake">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#判断编译器类型,如果是gcc编译器,则在编译选项中加入c++11支持
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>if(&lt;span style="color:#e6db74">CMAKE_COMPILER_IS_GNUCXX&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span> set(&lt;span style="color:#e6db74">CMAKE_CXX_FLAGS&lt;/span> &lt;span style="color:#e6db74">&amp;#34;-std=c++11 ${CMAKE_CXX_FLAGS}&amp;#34;&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span> message(&lt;span style="color:#e6db74">STATUS&lt;/span> &lt;span style="color:#e6db74">&amp;#34;optional:-std=c++11&amp;#34;&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span>endif(&lt;span style="color:#e6db74">CMAKE_COMPILER_IS_GNUCXX&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span>add_compile_options(&lt;span style="color:#e6db74">&amp;lt;option&amp;gt;&lt;/span> &lt;span style="color:#e6db74">...&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span>&lt;span style="color:#75715e"># 例子
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>add_compile_options(&lt;span style="color:#e6db74">-Wall&lt;/span> &lt;span style="color:#e6db74">-Wextra&lt;/span> &lt;span style="color:#e6db74">-pedantic&lt;/span> &lt;span style="color:#e6db74">-Werror&lt;/span> &lt;span style="color:#e6db74">-g&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="33-message">3.3 message&lt;/h2>
&lt;p>这个函数的功能是打印&lt;/p>
&lt;p>&lt;code>message(STATUS &amp;quot;Obtained CUDA architectures from CMake variable TCNN_CUDA_ARCHITECTURES=${TCNN_CUDA_ARCHITECTURES}&amp;quot;)&lt;/code>&lt;/p>
&lt;h2 id="34-function">3.4 function&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cmake" data-lang="cmake">&lt;span style="display:flex;">&lt;span>function(&lt;span style="color:#e6db74">&amp;lt;name&amp;gt;&lt;/span> &lt;span style="color:#e6db74">[&amp;lt;arg1&amp;gt;&lt;/span> &lt;span style="color:#e6db74">...]&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">&amp;lt;commands&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span>endfunction()&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>NOTE: A function opens a new scope: see set(var PARENT_SCOPE) for details.&lt;/p>
&lt;p>function 伴随 scope 的概念，或许可以用局部变量和全局变量去理解。&lt;/p>
&lt;h2 id="35-list">3.5 list&lt;/h2>
&lt;p>list 有很多子命令，包括 &lt;code>APPEND&lt;/code>, &lt;code>INSERT&lt;/code> 等，用于修改变量。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cmake" data-lang="cmake">&lt;span style="display:flex;">&lt;span>if (&lt;span style="color:#e6db74">MSVC&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span> list(&lt;span style="color:#e6db74">APPEND&lt;/span> &lt;span style="color:#e6db74">CUDA_NVCC_FLAGS&lt;/span> &lt;span style="color:#e6db74">&amp;#34;-Xcompiler=/bigobj&amp;#34;&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span>else()&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span> list(&lt;span style="color:#e6db74">APPEND&lt;/span> &lt;span style="color:#e6db74">CUDA_NVCC_FLAGS&lt;/span> &lt;span style="color:#e6db74">&amp;#34;-Xcompiler=-Wno-float-conversion&amp;#34;&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span> list(&lt;span style="color:#e6db74">APPEND&lt;/span> &lt;span style="color:#e6db74">CUDA_NVCC_FLAGS&lt;/span> &lt;span style="color:#e6db74">&amp;#34;-Xcompiler=-fno-strict-aliasing&amp;#34;&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span> list(&lt;span style="color:#e6db74">APPEND&lt;/span> &lt;span style="color:#e6db74">CUDA_NVCC_FLAGS&lt;/span> &lt;span style="color:#e6db74">&amp;#34;-Xcudafe=--diag_suppress=unrecognized_gcc_pragma&amp;#34;&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="4-属性-property">4. 属性 Property&lt;/h1>
&lt;p>在 CMake 中，Properties（属性）是一种用于设置目标属性的机制。一个目标可以有多个属性，每个属性有一个名称和一个值。&lt;/p>
&lt;p>例如，一个目标可以有一个名为“CXX_STANDARD”的属性，其值为“11”。属性可以影响编译和链接过程中的行为，包括编译器和链接器选项、编译器和链接器特性，以及构建目标的方式。可以使用 set_target_properties() 命令来设置目标属性。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cmake" data-lang="cmake">&lt;span style="display:flex;">&lt;span>set_target_properties(&lt;span style="color:#e6db74">MyTarget&lt;/span> &lt;span style="color:#e6db74">PROPERTIES&lt;/span> &lt;span style="color:#e6db74">CXX_STANDARD&lt;/span> &lt;span style="color:#e6db74">11&lt;/span>)&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="5-模块和包管理-module-package">5. 模块和包管理 module, package&lt;/h1>
&lt;h1 id="object-file-and-link">Object file and link&lt;/h1>
&lt;p>在目录 &lt;code>mlp_learning_an_image.dir&lt;/code> 生成 &lt;code>.o&lt;/code> 文件之后，同一个目录下有 &lt;code>link.txt&lt;/code> 文件，这个文件就是用来进行链接的。&lt;/p>
&lt;p>解析一下&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>/usr/bin/c++ -O3 -DNDEBUG CMakeFiles/mlp_learning_an_image.dir/mlp_learning_an_image.cu.o CMakeFiles/mlp_learning_an_image.dir/__/dependencies/stbi/stbi_wrapper.cpp.o -o ../mlp_learning_an_image -L/usr/local/cuda/targets/x86_64-linux/lib ../libtiny-cuda-nn.a -lcuda ../dependencies/fmt/libfmt.a -lcudadevrt -lcudart_static -lrt -lpthread -ldl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># ../libtiny-cuda-nn.a 这个是 tiny-cuda-nn 那一堆编译生成的，也会被链接进来&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nvcc -o mlp_learning_an_image CMakeFiles/mlp_learning_an_image.dir/mlp_learning_an_image.cu.o CMakeFiles/mlp_learning_an_image.dir/__/dependencies/stbi/stbi_wrapper.cpp.o -L/usr/local/cuda/targets/x86_64-linux/lib ../libtiny-cuda-nn.a -lcuda ../dependencies/fmt/libfmt.a -lcudadevrt -lcudart_static -lrt -lpthread -ldl
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>/usr/bin/ar qc libtiny-cuda-nn.a &amp;quot;CMakeFiles/tiny-cuda-nn.dir/src/common.cu.o&amp;quot;...&lt;/code>，&lt;code>ar&lt;/code> 命令用于创建和管理 static lib, qc 是其 opti&lt;/p>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/93895403">https://zhuanlan.zhihu.com/p/93895403&lt;/a>&lt;/p></description></item><item><title>Hugo_让你的博客被Google收录</title><link>https://huweim.github.io/post/blog_hugo_%E8%AE%A9%E4%BD%A0%E7%9A%84%E5%8D%9A%E5%AE%A2%E8%A2%ABgoogle%E6%94%B6%E5%BD%95/</link><pubDate>Mon, 09 May 2022 22:17:43 +0800</pubDate><guid>https://huweim.github.io/post/blog_hugo_%E8%AE%A9%E4%BD%A0%E7%9A%84%E5%8D%9A%E5%AE%A2%E8%A2%ABgoogle%E6%94%B6%E5%BD%95/</guid><description>&lt;h1 id="1-step">1. Step&lt;/h1>
&lt;p>网站在没有提交搜索引擎收录之前，直接搜索你网站的内容是搜不到的，因为搜索引擎不会去检索你的Github仓库。下面的解决方法&lt;/p>
&lt;h2 id="11-check-是否被谷歌收录">1.1 Check 是否被谷歌收录&lt;/h2>
&lt;p>打开谷歌搜索，在搜索框中输入&lt;/p>
&lt;p>site:https://huweim.github.io/&lt;/p>
&lt;p>如果提示说：找不到和您查询的“site:https://huweim.github.io/ ” 相符的内容或信息，说明未被收录。&lt;/p>
&lt;p>如果搜索结果的第一条就是你的博客站点，说明已被收录，不用再继续看下面的内容了。&lt;/p>
&lt;h2 id="12-提交谷歌搜索">1.2 提交谷歌搜索&lt;/h2>
&lt;p>进入Google Web Master Search Console，登录之后提交你的博客网址&lt;/p>
&lt;p>提交后需要通过 DNS 记录验证域名所有权，Github DNS 服务器配置教程：https://docs.github.com/cn/enterprise-server@3.2/admin/configuration/configuring-network-settings/configuring-dns-nameservers&lt;/p>
&lt;p>&amp;#x274c; 1.2.1 ssh 链接到 GitHub Enterprise Server instance，不使用域名验证方法，使用上传 html 文件的方法&lt;/p>
&lt;h2 id="13-上传-html-文件">1.3 上传 html 文件&lt;/h2>
&lt;h3 id="131-放在-content">1.3.1 放在 content&lt;/h3>
&lt;p>将下载的 html 文件放置在 &lt;code>content&lt;/code> 目录下，开启服务后，&lt;code>http://localhost:1313/googlead4e3c06724927ae/&lt;/code> 能够索引到即可，然后 push to Github. &amp;#x274c;&lt;/p>
&lt;h3 id="132-放在-themelayouts">1.3.2 放在 theme/layouts&lt;/h3>
&lt;p>放在 content 目录下不行，检索不到后缀 .html，比如 &lt;code>http://localhost:1313/googlead4e3c06724927ae.html/&lt;/code> 就索引不到了。折腾了半个小时，发现应该放在 &lt;code>themes\jane\layouts&lt;/code> 目录下，因为发现 &lt;code>http://localhost:1313/index.html&lt;/code> 才能够有效地索引，那么对于 &lt;code>googlead4e3c06724927ae.html&lt;/code> 也是一样的道理。&lt;/p>
&lt;p>不过仍然找不到，不是说复制到&lt;code>themes\jane\layouts&lt;/code> 目录下就能索引到，比如我复制了一个 &lt;code>404.html&lt;/code>，改名为 &lt;code>40411.html&lt;/code>，是无法直接找到的。&lt;/p>
&lt;h3 id="133-static">1.3.3 static&lt;/h3>
&lt;p>知识：static这个文件夹有一个特性就是可以将里面的文件复制到public文件夹里面。我们可以将我们自定义的页面放到这个目录下，因为它不是hugo生成的，所以不会被覆盖。&lt;/p>
&lt;p>首先在根目录下的 &lt;code>static&lt;/code> 下创建一个目录，目录名是你的页面名（googlead4e3c06724927ae.html）。然后在这个目录下创建 &lt;code>index.html&lt;/code>，把 &lt;code>googlead4e3c06724927ae.html&lt;/code> 中的内容复制到 &lt;code>index.html&lt;/code>，目的就达到了。这样，访问 &lt;code>http://localhost:1313/googlead4e3c06724927ae.html/&lt;/code> 页面时加载的就是 &lt;code>googlead4e3c06724927ae.html&lt;/code> 的内容。&lt;/p>
&lt;p>2022-05-09 11:13:15，这一方法验证成功。&lt;/p>
&lt;p>&lt;img src="./Img/Verify.png">&lt;/p>
&lt;h2 id="14-等待">1.4 等待&lt;/h2>
&lt;p>提交博客之后，需要等待一段时间才能在Google上搜到，因为Google需要时间来处理我们的请求、抓取相应网页并将其编入索引。&lt;/p>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://huiyu-li.github.io/2019/11/27/Tools/2019-11-27-%E8%AE%A9%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0%E8%87%AA%E5%B7%B1%E5%86%8DGitHub%E4%B8%8A%E7%9A%84%E5%8D%9A%E5%AE%A2/">https://huiyu-li.github.io/2019/11/27/Tools/2019-11-27-%E8%AE%A9%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0%E8%87%AA%E5%B7%B1%E5%86%8DGitHub%E4%B8%8A%E7%9A%84%E5%8D%9A%E5%AE%A2/&lt;/a>&lt;/p></description></item><item><title>编译运行 CUTLASS 和 cuBLAS</title><link>https://huweim.github.io/post/%E5%AE%9E%E9%AA%8C_%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Ccutlass%E5%92%8Ccublas/</link><pubDate>Mon, 09 May 2022 22:17:43 +0800</pubDate><guid>https://huweim.github.io/post/%E5%AE%9E%E9%AA%8C_%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Ccutlass%E5%92%8Ccublas/</guid><description>&lt;h1 id="0-前言">0. 前言&lt;/h1>
&lt;p>内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。&lt;/p>
&lt;p>包括根据官方文档运行 cuBLAS 的实例，过程中遇到的问题。&lt;/p>
&lt;h1 id="1-环境">1. 环境&lt;/h1>
&lt;h2 id="10-project-的目录结构">1.0 project 的目录结构&lt;/h2>
&lt;p>为什么会有这么多 .cmake 文件？应该是提供了其他功能的模板&lt;/p>
&lt;ul>
&lt;li>For a project with cmake, why there is a CMakeFiles dir in build dir, and there is &amp;ldquo;Makefile2&amp;rdquo; in CMakeFiles dir
&lt;ul>
&lt;li>The &lt;code>CMakeFiles&lt;/code> directory is generated during the CMake build process and contains all the necessary &lt;strong>intermediate files&lt;/strong> used to build the project.&lt;/li>
&lt;li>&lt;code>Makefile2&lt;/code> 文件不是用来由用户直接修改的，而是由CMake生成，并由make根据CMakeLists.txt文件中指定的指示来构建项目。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="11-prerequisites">1.1 Prerequisites&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ git clone https://github.com/NVIDIA/cutlass
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>CUTLASS requires:&lt;/p>
&lt;ul>
&lt;li>NVIDIA CUDA Toolkit (9.2 or later required, 11.1 recommended)&lt;/li>
&lt;li>CMake 3.12+&lt;/li>
&lt;li>host compiler supporting C++11 or greater (g++ 7.3.0 or Microsoft Visual Studio 2015 recommended)&lt;/li>
&lt;li>Python 3.6+&lt;/li>
&lt;/ul>
&lt;p>CUTLASS may be optionally compiled and linked with&lt;/p>
&lt;ul>
&lt;li>cuBLAS&lt;/li>
&lt;li>cuDNN v7.6 or later&lt;/li>
&lt;/ul>
&lt;h3 id="111-cmake">1.1.1 cmake&lt;/h3>
&lt;p>官方给出了建议的环境，cmake 没有安装，apt-get install 安装的是 3.12 版本，不符合要求。手动安装一下 3.20 cmake，&lt;a href="https://gist.github.com/bmegli/4049b7394f9cfa016c24ed67e5041930">教程&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># get and build CMake&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>wget https://github.com/Kitware/CMake/releases/download/v3.20.0/cmake-3.20.0.tar.gz
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tar -zvxf cmake-3.20.0.tar.gz
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cd cmake-3.20.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./bootstrap
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make -j8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># add path&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export PATH&lt;span style="color:#f92672">=&lt;/span>$PATH:$CUDA_INSTALL_PATH/bin:~/cmake-3.20.0/bin
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意有个 BUG，&lt;code> Could NOT find OpenSSL,&lt;/code>，&lt;code>apt-get install libssl-dev&lt;/code> 即可&lt;/p>
&lt;h3 id="112-gcc">1.1.2 gcc&lt;/h3>
&lt;h2 id="12-build">1.2 Build&lt;/h2>
&lt;p>2023-03-16 15:31:43，编译的逻辑是吧多个 cutlass 算子都链接到 cutlass_profiler 文件中。&lt;/p>
&lt;p>之后就可以 build 了。这里用 Turing 架构&lt;/p>
&lt;p>Construct a build directory and run CMake.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ export CUDACXX&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>CUDA_INSTALL_PATH&lt;span style="color:#e6db74">}&lt;/span>/bin/nvcc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ mkdir build &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> cd build
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">75&lt;/span> &lt;span style="color:#75715e"># compiles for NVIDIA Turing GPU architecture&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 在 ~/cutlass/build/tools/library/generated/ 目录下生成 conv2d and gemm 的所有抽象组合&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">75&lt;/span> -DCUTLASS_LIBRARY_KERNELS&lt;span style="color:#f92672">=&lt;/span>all
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 仅需要 subset of gemm kernels with FP32 accumulation and FP16 input, in Ampere and Turing&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;75;80&amp;#39;&lt;/span> -DCUTLASS_LIBRARY_KERNELS&lt;span style="color:#f92672">=&lt;/span>cutlass_tensorop_s*gemm_f16_*_nt_align8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 我想这个 * 应该表示正则表达式&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ make cutlass_profiler -j16
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>需求&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">75&lt;/span> -DCUTLASS_LIBRARY_KERNELS&lt;span style="color:#f92672">=&lt;/span>cutlass_tensorop_i88*gemm_s*_256x128_*x2_tn_align*
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">75&lt;/span> -DCUTLASS_LIBRARY_KERNELS&lt;span style="color:#f92672">=&lt;/span>cutlass_tensorop_i8832gemm_s4_256x128_128x2_tn_align32
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">75&lt;/span> -DCUTLASS_LIBRARY_KERNELS&lt;span style="color:#f92672">=&lt;/span>cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ make cutlass_profiler -j16
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ nsys profile --stats&lt;span style="color:#f92672">=&lt;/span>true ./turing_tensorop_gemm
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="121-cmake-在做什么">1.2.1 cmake 在做什么&lt;/h3>
&lt;p>&lt;code>cmake .. -DCUTLASS_NVCC_ARCHS=75 -DCUTLASS_LIBRARY_KERNELS=all &lt;/code>，在 &lt;code>~/cutlass/build/tools/library/generated/&lt;/code> 目录下生成相应的 .cu 接口&lt;/p>
&lt;h3 id="122-make-在做什么">1.2.2 make 在做什么&lt;/h3>
&lt;p>&lt;code>Building CUDA object tools/library/CMakeFiles/cutlass_library_objs.dir/generated/gemm/cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16.cu.o&lt;/code>&lt;/p>
&lt;p>猜测是根据 cmake 中生成的接口文件，生成 &lt;code>cutlass_profiler&lt;/code> 能够运行/调用的目标文件。&lt;/p>
&lt;blockquote>
&lt;p>2023-03-23 14:19:09，以上的猜测基本没有问题。generated 目录下的 .cu 文件应该只是给出一个配置的实例，其对应的 kernel 已经全部编译到 &lt;code>/tools/profiler/cutlass_profiler&lt;/code> 这个 bin 文件中。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;code>make cutlass_profiler -j16&lt;/code> 之后，使用 &lt;code>./tools/profiler/cutlass_profiler --kernels=cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16&lt;/code> 来运行。&lt;/p>
&lt;h3 id="123-test-in-real-gpu">1.2.3 Test in real GPU&lt;/h3>
&lt;p>工作站 GPU 是 GTX980，SM_50&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ cmake .. -DCUTLASS_NVCC_ARCHS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">50&lt;/span> -DCUTLASS_LIBRARY_KERNELS&lt;span style="color:#f92672">=&lt;/span>cutlass_simt_sgemm_128x128_8x2_nn_align1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ make cutlass_profiler -j16
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ ./tools/profiler/cutlass_profiler --kernels&lt;span style="color:#f92672">=&lt;/span>cutlass_simt_sgemm_128x128_8x2_nn_align1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="13-build-and-run-the-cutlass-profiler">1.3 Build and run the CUTLASS Profiler&lt;/h2>
&lt;blockquote>
&lt;p>2023-03-23 14:22:54，要注意的是，实际上 1.2 描述的就是 build profiler 的过程&lt;/p>
&lt;/blockquote>
&lt;p>From the &lt;code>build/&lt;/code> directory created above, compile the the CUTLASS Profiler. 主要是 build &lt;code>build/tool/profiler&lt;/code> 目录。 &amp;#x2714;&amp;#xfe0f;&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ make cutlass_profiler -j12
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then execute the CUTLASS Profiler computing GEMM, execute the following command. &amp;#x274c;&lt;/p>
&lt;p>这一步果然不行，cudaGetDeviceProperties() failed for given device，找不到 device&lt;/p>
&lt;p>2022-05-08 14:41:46，&amp;#x2714;&amp;#xfe0f;，在工作站上就可以用 gpgpu-sim 运行，很奇怪，明明都是同一个 Docker 环境，只是自己电脑没有 GPU 而已&lt;/p>
&lt;p>运行给出的输出信息如下，给出了可以自己设置的 option，也给出了性能（GFLOPS）&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ ./tools/profiler/cutlass_profiler --kernels&lt;span style="color:#f92672">=&lt;/span>sgemm --m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4352&lt;/span> --n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --k&lt;span style="color:#f92672">=&lt;/span>4096
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">=============================&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Problem ID: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Provider: CUTLASS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Operation: cutlass_simt_sgemm_128x128_nn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Disposition: Passed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Status: Success
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Arguments: --m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4352&lt;/span> --n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --A&lt;span style="color:#f92672">=&lt;/span>f32:column --B&lt;span style="color:#f92672">=&lt;/span>f32:column --C&lt;span style="color:#f92672">=&lt;/span>f32:column --alpha&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --beta&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --split_k_slices&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --batch_count&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --op_class&lt;span style="color:#f92672">=&lt;/span>simt --accum&lt;span style="color:#f92672">=&lt;/span>f32 --cta_m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">128&lt;/span> --cta_n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">128&lt;/span> --cta_k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --stages&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> --warps_m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> --warps_n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> --warps_k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --inst_m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --inst_n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --inst_k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> --min_cc&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">50&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --max_cc&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1024&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Bytes: &lt;span style="color:#ae81ff">52428800&lt;/span> bytes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> FLOPs: &lt;span style="color:#ae81ff">146064539648&lt;/span> flops
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Runtime: 10.5424 ms
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Memory: 4.63158 GiB/s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Math: 13854.9 GFLOP/s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="14-build-and-run-cutlass-unit-tests">1.4 Build and run CUTLASS Unit Tests&lt;/h2>
&lt;h3 id="141-自己的-workspace">1.4.1 自己的 Workspace&lt;/h3>
&lt;p>From the &lt;code>build/&lt;/code> directory created above, simply build the target &lt;code>test_unit&lt;/code> to compile and run all unit tests. &amp;#x274c;&lt;/p>
&lt;p>这一步失败，看起来是 gcc 版本的问题。换了 gcc 版本，还是直接崩掉。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ make test_unit -j
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span>----------&lt;span style="color:#f92672">]&lt;/span> Global test environment tear-down
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[==========]&lt;/span> &lt;span style="color:#ae81ff">946&lt;/span> tests from &lt;span style="color:#ae81ff">57&lt;/span> test cases ran. &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#ae81ff">10812&lt;/span> ms total&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">[&lt;/span> PASSED &lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#ae81ff">946&lt;/span> tests.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>指定一个 unit，会 building 目录 &lt;code>test/unit/gemm/warp/CMakeFiles&lt;/code> 中的内容，仍然是找不到 GPU Device ID&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ make test_unit_gemm_warp -j
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="142-工作站">1.4.2 工作站&lt;/h3>
&lt;p>&lt;strong>工作站：&lt;/strong> 还是找不到 gpgpusim.config，这个应该找到对应的执行目录，把 config 文件复制过去即可。&lt;code>cp ~/gpgpu-sim_distribution/configs/tested-cfgs/SM75_RTX2060/* ~/cutlass/build/test/unit/gemm/warp/CMakeFiles/test_unit_gemm_warp.dir/&lt;/code>&lt;/p>
&lt;p>2022-05-09 15:31:59，猜测是在 &lt;code>/cutlass/build/test/unit/gemm/warp&lt;/code> 目录下执行，把 gpgpusim.config 文件复制过去。&amp;#x2714;&amp;#xfe0f;&lt;/p>
&lt;p>可以成功运行，新的问题是之前遇到的一个问题，wmma 指令的 align syntax 错误。&lt;/p>
&lt;h2 id="15-profiler-和-test-unit-的执行有什么区别">1.5 Profiler 和 Test Unit 的执行有什么区别？&lt;/h2>
&lt;p>2023-03-23 14:25:03，结合文档的说明和个人的理解。单元测试就是测试功能正确性，保证矩阵的计算不出错，在单元测试情况下矩阵的 size，data type 可以多样一点。
性能测试的话自己手动设置的东西就比较多，粒度更细，同时会给出性能的报告。&lt;/p>
&lt;h2 id="16-gemm-运行参数">1.6 gemm 运行参数&lt;/h2>
&lt;p>cutlass_profiler 支持非常自由的运行参数，并且支持参数的批处理（用 , 间隔）。参数如下，f32 应该就是对应的 data type 设置。&lt;/p>
&lt;p>2022-05-09 20:34:24 找到了官方的 &lt;a href="https://github.com/NVIDIA/cutlass#documentation">Documentation&lt;/a>，可以看 Section 3 中的详细解释。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>cutlass_profiler &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --operation&lt;span style="color:#f92672">=&lt;/span>Gemm &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8192&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8192&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8192&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --A&lt;span style="color:#f92672">=&lt;/span>f32:column &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --B&lt;span style="color:#f92672">=&lt;/span>f32:column &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --C&lt;span style="color:#f92672">=&lt;/span>f32:column &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --beta&lt;span style="color:#f92672">=&lt;/span>0,1,2 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --profiling-iterations&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --providers&lt;span style="color:#f92672">=&lt;/span>cutlass &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --output&lt;span style="color:#f92672">=&lt;/span>functional-test.csv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>尝试修改 data type，是否有 i8? 这个语句执行结束后生成了一堆 .csv 文件，包括 conv2d, conv3d, gemm, rank_k, rank_2k，难道是一次执行了这么多程序？而且没有成功跑起来 &amp;#x274c;&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ ./tools/profiler/cutlass_profiler --kernels&lt;span style="color:#f92672">=&lt;/span>cutlass_tensorop_s*gemm_f16_*_nt_align8 --m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3456&lt;/span> --n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --A&lt;span style="color:#f92672">=&lt;/span>i8:column --B&lt;span style="color:#f92672">=&lt;/span>i8:column --C&lt;span style="color:#f92672">=&lt;/span>i8:column --output&lt;span style="color:#f92672">=&lt;/span>test.csv &amp;gt; ~/output/tensor_op3.log.lrr &amp;amp;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>去掉 output 选项，data type 改成 f32&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ ./tools/profiler/cutlass_profiler --kernels&lt;span style="color:#f92672">=&lt;/span>cutlass_tensorop_s*gemm_f16_*_nt_align8 --m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3456&lt;/span> --n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --A&lt;span style="color:#f92672">=&lt;/span>f32:column --B&lt;span style="color:#f92672">=&lt;/span>f32:column --C&lt;span style="color:#f92672">=&lt;/span>f32:column &amp;gt; ~/output/tensor_op3.log.lrr &amp;amp;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="2-cutlass-examples">2. cutlass examples&lt;/h1>
&lt;p>使用官方 README.md 编译会因为没有 Device 而失败，那么换一个思路，尝试利用 cmake 编译运行 examples 中提供的文件。&lt;/p>
&lt;blockquote>
&lt;p>2023-03-23 14:27:07，在学习了 cmake 之后，可以查看 &lt;code>build&lt;/code> 目录中生成的 &lt;code>Makefile&lt;/code> 文件。Makefile 文件中提供了每个 example 的 target，可以编译生成对应的 bin 文件。&lt;/p>
&lt;/blockquote>
&lt;h2 id="21-cmake-编译流程">2.1 cmake 编译流程&lt;/h2>
&lt;ul>
&lt;li>编写 CMakeLists.txt&lt;/li>
&lt;li>通过 cmake 生成 Makefile&lt;/li>
&lt;li>make 编译&lt;/li>
&lt;/ul>
&lt;p>cuTLASS 在 &lt;code>example&lt;/code> 目录下提供了 CMakeLists.txt。用法&lt;/p>
&lt;ul>
&lt;li>进入 example 目录，新建 build 文件夹；&lt;code>$ mkdir build; cd build&lt;/code>&lt;/li>
&lt;li>&lt;code>cmake ../&lt;/code>; cmake会在找到上级目录找到 CMakeLists.txt，生成 makefile 和一些其它文件&lt;/li>
&lt;li>在 makefile 所在目录，调用 make 命令，会根据 makefile 对程序进行编译生成。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>2023-03-23 14:28:43，这里要注意并不是进入到每个目录去单独编译，而是 &lt;code>build&lt;/code> 根目录下已经提供了这个接口和 target，每个 example 中的 Makefile 文件可能是更加具体的实现，但是在根目录下调用即可。&lt;/p>
&lt;/blockquote>
&lt;h1 id="3-documentation">3. Documentation&lt;/h1>
&lt;p>check 官方文档&lt;/p>
&lt;h2 id="32-functionality">3.2 Functionality&lt;/h2>
&lt;p>这个部分介绍了 opcode class, *&lt;strong>data type&lt;/strong>, layout. data type 正是我们所需要的。&lt;/p>
&lt;p>opcode class, including Simt, TensorOp, SpTensorOp&lt;/p>
&lt;h3 id="322-device-level-implicit-gemm-convolution">3.2.2 Device-level Implicit GEMM convolution&lt;/h3>
&lt;p>列出了 Device-level Implicit GEMM convolution 的 opcode class, data type, layout&lt;/p>
&lt;h3 id="323-warp-level-matrix-multiply-with-tensor-cores">3.2.3 Warp-level Matrix Multiply with Tensor Cores&lt;/h3>
&lt;p>TensorOp 16-by-8-by-64. 支持 int4b_t，&lt;/p>
&lt;h3 id="324-warp-level-matrix-multiply-with-cuda-wmma-api">3.2.4 Warp-level Matrix Multiply with CUDA WMMA API&lt;/h3>
&lt;p>WmmaTensorOp,&lt;/p>
&lt;p>Instruction Shape ( 16-by-16-by-16, 8-by-32-by-16)&lt;/p>
&lt;p>Warp Shapes (32x32x16, 32x64x16, 64x32x16; 32x32x16, 32x64x16, 64x32x16)&lt;/p>
&lt;h2 id="33-efficient-gemm-in-cuda">3.3 Efficient GEMM in CUDA&lt;/h2>
&lt;h3 id="331-threadblock-level-gemm">3.3.1 Threadblock-level GEMM&lt;/h3>
&lt;p>Each threadblock computes its portion of the output GEMM by iteratively loading tiles of input matrices and computing an accumulated matrix product.&lt;/p>
&lt;h3 id="332-warp-level-gemm">3.3.2 Warp-level GEMM&lt;/h3>
&lt;p>Multiple warps within a threadblock fetch data from shared memory into registers and perform computations. Warp-level GEMMs may be implemented either by TensorCores issuing mma.sync or wmma instructions or by thread-level matrix computations issued to CUDA cores. For maximum performance, access to shared memory should be bank conflict free. To maximize data reuse within the warp, a large warp-level GEMM tile should be chosen.&lt;/p>
&lt;p>使用到了 wmma 指令，shared memory。&lt;/p>
&lt;h3 id="333-thread-level-gemm">3.3.3 Thread-level GEMM&lt;/h3>
&lt;p>SGEMM, IGEMM, HGEMM, and DGEMM are computed by SIMT math instructions issued by thread-level matrix multiply procedures.&lt;/p>
&lt;p>所以现在跑的是 thread-level GEMM&lt;/p>
&lt;h2 id="34-terminology">3.4 Terminology&lt;/h2>
&lt;p>Layout: functor mapping logical coordinates of a tensor to linear offset (as LongIndex); owns stride vectors, if any.&lt;/p>
&lt;p>Operator: an object performing a computation on matrix or tensor objects. May be further refined by scope within the execution model hierarchy.&lt;/p>
&lt;p>Tile: partitions of a tensor that have constant extents and layout known at compile time&lt;/p>
&lt;h2 id="35-align-含义">3.5 align 含义&lt;/h2>
&lt;p>&lt;code>cutlass_tensorop_f16_s884gemm_f16_64x64_32x2_tn_align8.cu&lt;/code>&lt;/p>
&lt;p>In the case of this Cutlass file, the &amp;ldquo;align8&amp;rdquo; suffix indicates that the matrix data is aligned to an 8-byte boundary. This can help improve performance when the matrix multiplication algorithm accesses the matrix data.&lt;/p>
&lt;h2 id="35-cutlass-profiler-star">3.5 CUTLASS Profiler &amp;#x2b50;&lt;/h2>
&lt;p>The CUTLASS Profiler is a command-line driven test and profiling environment for CUTLASS computations defined in the CUTLASS Instance Library. The CUTLASS Profiler is capable of executing each GEMM, Sparse Gemm, Conv2d, and Conv3d kernel.&lt;/p>
&lt;p>&lt;code>cutlass_profiler&lt;/code> 就是一个封装好的脚本，运行各类程序&lt;/p>
&lt;p>进入到目录 &lt;code>build/tools/profiler&lt;/code>，运行 &lt;code>cutlass_profiler --help&lt;/code> 可以查看一些有用的信息，直接 &lt;code>cutlass_profiler --help&lt;/code> 找不到 cutlass_profiler；用 &lt;code>./cutlass_profiler --help&lt;/code> 就开始跑程序了，有点不知道怎么用这个 &amp;ndash;help。&lt;/p>
&lt;p>2022-05-09 20:22:30，还是用 &lt;code>./cutlass_profiler --help&lt;/code> 就可以跑，不过神奇的是这是用 gpgpu-sim 跑得，最后会把需要的信息 print 在屏幕上。&lt;/p>
&lt;h3 id="351-gemm">3.5.1 GEMM&lt;/h3>
&lt;p>The CUTLASS Profiler is capable of executing GEMM and Sparse GEMM problems.&lt;/p>
&lt;h4 id="3511-gemm-arguments-star">3.5.1.1 GEMM Arguments &amp;#x2b50;&lt;/h4>
&lt;p>The complete set of arguments available to each operation may be viewed by specifying the operation name in addition to &amp;ndash;help. The argument flags and their aliases usable for GEMM appear as follows.&lt;/p>
&lt;p>可以通过 option &lt;code>--help&lt;/code> 查看完整的 operation，他这里给出的例子是 &lt;code>./tools/profiler/cutlass_profiler --operation=gemm --help&lt;/code>，所以还是得执行这个脚本吧。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>To execute kernels targeting Tensor Core operations, supply the flag &lt;code>--op_class=tensorop&lt;/code> in the command line.&lt;/p>
&lt;p>实际上，op_class 也就是选择 TensorOp or SIMT&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ ./tools/profiler/cutlass_profiler --op_class&lt;span style="color:#f92672">=&lt;/span>tensorop --m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3456&lt;/span> --n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">4096&lt;/span> --k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8192&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="3513-自己运行">3.5.1.3 自己运行&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>./tools/profiler/cutlass_profiler --operation&lt;span style="color:#f92672">=&lt;/span>Gemm --op_class&lt;span style="color:#f92672">=&lt;/span>tensorop --m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1024&lt;/span> --n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1024&lt;/span> --k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">128&lt;/span> --inst_m&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span> --inst_n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span> --inst_k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">32&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>如何使用 4-bit 进行计算&lt;/strong>: 对于 TensorOp, Instruction Shape 8-by-8-by-32 对应的是 A-int4b_t, B-int4b_t, C-int32_t，通过参数 &lt;code>--inst_m&lt;/code>, &lt;code>--inst_n&lt;/code>, &lt;code>inst_k&lt;/code> 来决定&lt;/p>
&lt;h3 id="352-conv">3.5.2 Conv&lt;/h3>
&lt;p>和 gemm 也是类似的，重点还是搞懂他们的参数。&lt;/p>
&lt;h2 id="36-gemm-api-components">3.6 GEMM API Components&lt;/h2>
&lt;p>This document focuses on device-level, threadblock-level GEMMs, warp-level GEMMs, thread-level GEMMs, and instruction-level GEMMs.&lt;/p>
&lt;h3 id="361-device-wide-gemm-api">3.6.1 Device-wide GEMM API&lt;/h3>
&lt;p>The device-wide GEMM API is embodied by the following operators&lt;/p>
&lt;ul>
&lt;li>cutlass::gemm::device::Gemm - basic GEMM operation&lt;/li>
&lt;li>cutlass::gemm::device::GemmArray - batched GEMM operation in which input matrices are read from arrays of pointers&lt;/li>
&lt;li>cutlass::gemm::device::GemmBatched - batched GEMM operation in which input matrices are separated by a constant stride&lt;/li>
&lt;li>cutlass::gemm::device::GemmSplitKParallel - GEMM operation that partitions the GEMM K dimension then launches a separate reduction kernel&lt;/li>
&lt;/ul>
&lt;p>都在 &lt;code>cutlass/include/cutlass/gemm/device/&lt;/code> 目录下，basic GEMM 对应 &lt;code>gemm.h&lt;/code> 文件&lt;/p>
&lt;h1 id="4-在-gpgpu-sim-上运行">4. 在 GPGPU-Sim 上运行&lt;/h1>
&lt;h2 id="41-cutlass-sim">4.1 cutlass-sim&lt;/h2>
&lt;p>尝试了 Admodt 提供的 &lt;code>https://github.com/gpgpu-sim/cutlass-gpgpu-sim&lt;/code>，仍然是 syntax error，估计是新版本编译的 PTX 有问题。2022-05-26 15:53:30，确实如此。&lt;/p>
&lt;p>不同 CUDA 版本对应不同的 PTX .version，得到的 PTX 指令是不一样的。这就是为什么 CUDA 11.4 wmma 指令会报错。&lt;/p>
&lt;h2 id="42-step">4.2 Step&lt;/h2>
&lt;ul>
&lt;li>下载并安装 CUDA Toolkit 9.2，使用这个版本编译模拟器。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="5-cutlass-in-detail">5. CUTLASS in detail&lt;/h1>
&lt;p>通过 cutlass 深入理解其 makefile 以及 cmake；同时，比较深入地 trace GEMM kernel 函数，目的是对应 SASS 去看。&lt;/p>
&lt;h2 id="51-makefile-and-cmake-in-detail">5.1 Makefile and cmake in detail&lt;/h2>
&lt;h3 id="511-s-文件">5.1.1 .s 文件&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">cd&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">/home/data2/Workspace/huwm/share/work/cutlass/build&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>MAKE&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>MAKESILENT&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">-f&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">tools/library/CMakeFiles/cutlass_library_objs.dir/build.make&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">tools/library/CMakeFiles/cutlass_library_objs.dir/generated/trmm/cutlass_tensorop_z884trmm_128x64_8x3_tn_rs_u_un_align1.cu.s&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>.s 文件就是 assembly code.&lt;/p>
&lt;h3 id="512-makefile-中这个-rule-的意义">5.1.2 Makefile 中这个 rule 的意义&lt;/h3>
&lt;p>这里 rule 的作用是什么&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-makefile" data-lang="makefile">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">tools/profiler/CMakeFiles/cutlass_profiler.dir/rule&lt;/span>&lt;span style="color:#f92672">:&lt;/span> cmake_check_build_system
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>CMAKE_COMMAND&lt;span style="color:#66d9ef">)&lt;/span> -E cmake_progress_start /home/data2/Workspace/huwm/share/work/cutlass/build/CMakeFiles &lt;span style="color:#ae81ff">50&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>MAKE&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#66d9ef">$(&lt;/span>MAKESILENT&lt;span style="color:#66d9ef">)&lt;/span> -f CMakeFiles/Makefile2 tools/profiler/CMakeFiles/cutlass_profiler.dir/all
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">$(&lt;/span>CMAKE_COMMAND&lt;span style="color:#66d9ef">)&lt;/span> -E cmake_progress_start /home/data2/Workspace/huwm/share/work/cutlass/build/CMakeFiles &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">.PHONY &lt;/span>&lt;span style="color:#f92672">:&lt;/span> tools/profiler/CMakeFiles/cutlass_profiler.dir/rule
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="513-d-文件">5.1.3 .d 文件&lt;/h3>
&lt;blockquote>
&lt;p>The .d file is a dependency file that specifies the dependencies of the source file&lt;/p>
&lt;/blockquote>
&lt;p>列出源文件的依赖关系，是一个可读的文本文件。&lt;/p>
&lt;h3 id="514-make-cutlass_profiler-and-test_unit">5.1.4 make cutlass_profiler and test_unit&lt;/h3>
&lt;p>cutlass 提供了两种 target，理解为 test_unit 是用于测试程序的正确性，而 cutalss_profiler 内置了评估性能的代码。&lt;/p>
&lt;h3 id="515-tiny-cuda-nn-link-所有-o-文件">5.1.5 tiny-cuda-nn link 所有 .o 文件&lt;/h3>
&lt;p>都在 &lt;code>build/CMakeFiles/tiny-cuda-nn.dir/build.make&lt;/code> 中，&lt;code>libtiny-cuda-nn.a:&lt;/code> target，这个 target 中，列出了所有的依赖文件&lt;/p>
&lt;h2 id="52-gemm-iteration">5.2 GEMM iteration&lt;/h2>
&lt;p>2023-03-22 15:45:45，终于找到了 cutlass 的 real loop&lt;/p>
&lt;p>&lt;code>void gemm_iters&lt;/code> in &lt;code>cutlass/gemm/threadblock/mma_pipelined.h&lt;/code>，在这个 kernel function 中，最终会调用 &lt;code>warp_mma()&lt;/code>，这又是一个操作符重载的对象，通过对象本身直接调用其 &lt;code>operator&lt;/code> 函数。&lt;/p>
&lt;p>&lt;code>warp_mma()&lt;/code> 调用的就是 &lt;code>cutlass/gemm/warp/mma_tensor_op.h&lt;/code> 中的 &lt;code>void operator()&lt;/code> 函数&lt;/p>
&lt;h3 id="521-mma_pipelinedh-void-gemm_iters">5.2.1 mma_pipelined.h void gemm_iters()&lt;/h3>
&lt;p>SASS 指令中的 &lt;code>.L_5&lt;/code> 部分就是这个函数中 &lt;code>for (int warp_mma_k = 0; warp_mma_k &amp;lt; Base::kWarpGemmIterations; ++warp_mma_k)&lt;/code> 的循环展开。&lt;/p>
&lt;hr>
&lt;h1 id="cublas">cuBLAS&lt;/h1>
&lt;p>接下来是编译运行 cuBLAS 的过程&lt;/p>
&lt;h1 id="1-nvidia-samples">1. NVIDIA Samples&lt;/h1>
&lt;p>&lt;a href="https://github.com/NVIDIA/cuda-samples/">https://github.com/NVIDIA/cuda-samples/&lt;/a> 在 library 目录中有提供调用 cublas 的代码，果然官方提供的资源才是最好的。git clone 下来就可以在 A10 上编译运行。重点是理解不同 API 的含义，需要的 parameter，gemm 的 data type, shape 等等，这一点需要多看文档。&lt;/p>
&lt;h2 id="11-如何确定调用了-tensor-core">1.1 如何确定调用了 tensor core?&lt;/h2>
&lt;blockquote>
&lt;p>Tensor cores were first introduced with Volta GPUs (compute capability&amp;gt;=sm_70) and significantly accelerate matrix multiplications. Starting with cuBLAS version 11.0.0, the library will automatically make use of Tensor Core capabilities wherever possible, unless they are explicitly disabled by selecting pedantic compute modes in cuBLAS (see cublasSetMathMode(), cublasMath_t).&lt;/p>
&lt;/blockquote>
&lt;p>文档中说 cublas 会自动调用 tensor core&lt;/p>
&lt;blockquote>
&lt;p>2023-03-23 14:30:21，可以通过 nsys 调用 Nsight 工具来查看具体的 kernel 信息，也可以使用 &lt;code>cuobjdump -sass&lt;/code> 得到 SASS 指令，通过指令的信息来判断。&lt;/p>
&lt;/blockquote>
&lt;h1 id="2-documentation">2. Documentation&lt;/h1>
&lt;h2 id="21-using-the-cublas-api">2.1 Using the cuBLAS API&lt;/h2>
&lt;blockquote>
&lt;p>cuBLAS库提供了现成的矩阵乘法算子，例如&lt;code>cublasGemmEx&lt;/code>和&lt;code>cublasLtMatmul&lt;/code>。其中后者是轻量级版本，API调用更灵活。&lt;/p>
&lt;/blockquote>
&lt;p>cublasGemmEx&lt;/p>
&lt;h2 id="211-general-description">2.1.1 General Description&lt;/h2>
&lt;blockquote>
&lt;p>应该注意的是，该库将选择启用 Tensor Core 的实现，只要它确定它将提供最佳性能。&lt;/p>
&lt;/blockquote>
&lt;p>cuBLAS 11.0.0 之后支持任何 size 的矩阵，只是对齐的 size 能够更好地发挥 Tensor core 的性能。&lt;/p>
&lt;h2 id="212-cublas-datatypes-reference">2.1.2 cuBLAS Datatypes Reference&lt;/h2>
&lt;p>&lt;code>cublasDataType_t handle&lt;/code>，一个有关cuBLAS库的上下文的句柄，之后需要传递给API函数，即计算乘法的函数&lt;/p>
&lt;p>&lt;code>cublasOperation_t&lt;/code>, N, 非转置；T，转置；C，共轭转置。&lt;/p>
&lt;p>&lt;code>cublasGemmEx&lt;/code> 中的 &lt;code>cublasGemmAlgo_t&lt;/code>，&lt;code>cublasGemmAlgo_t&lt;/code> 最高支持 sm_75，sm_80 已经不支持了，所以在 sm_80 中指定了也是无效的，在 sm_80 中所有枚举都等同于 &lt;code>CUBLAS_GEMM_DEFAULT&lt;/code> 或者 &lt;code>CUBLAS_GEMM_DEFAULT_TENSOR_OP&lt;/code>。在更新的架构中也会 deprecated&lt;/p>
&lt;p>&lt;code>cudaDataType_t&lt;/code>, 直接作为 &lt;code>cublasGemmEx&lt;/code> 的参数，支持 int8 到 double 类型。&lt;/p>
&lt;h3 id="213-cublas-level---3-function-reference">2.1.3 cuBLAS Level - 3 Function Reference&lt;/h3>
&lt;p>&lt;code>cublasSgemm&lt;/code>, &lt;code>cublasDgemm&lt;/code>, &lt;code>cublasCgemm&lt;/code>, &lt;code>cublasZgemm&lt;/code>, &lt;code>cublasHgemm&lt;/code> 应该是比较初始的 API。&lt;/p>
&lt;h3 id="214-blas-like-extension">2.1.4 BLAS-like Extension&lt;/h3>
&lt;blockquote>
&lt;p>&lt;code>cublasGemmEx()&lt;/code>. This function is an extension of cublas&lt;!-- raw HTML omitted -->gemm that allows the user to individually specify the data types for each of the A, B and C matrices, the precision of computation and the GEMM algorithm to be run. Supported combinations of arguments are listed further down in this section.&lt;/p>
&lt;/blockquote>
&lt;p>自定义 data types，自己在 int8 中就用的这个 API，支持 sm_50 以上的架构。&lt;/p>
&lt;h2 id="22-using-the-cublaslt-api">2.2 Using the cuBLASLt API&lt;/h2>
&lt;p>cuBLASLt, a lightweight library dedicated to GEMM&lt;/p>
&lt;blockquote>
&lt;p>The cuBLASLt in general does not guarantee to support all possible sizes and configurations.&lt;/p>
&lt;/blockquote>
&lt;p>不一定支持任何 size&lt;/p>
&lt;h3 id="221-cublaslt-datatypes-reference">2.2.1 cuBLASLt Datatypes Reference&lt;/h3>
&lt;p>&lt;code>cublasLtMatmulTile_t&lt;/code> 提供多种 tile size&lt;/p>
&lt;h2 id="23-using-the-cublasxt-api">2.3 Using the cuBLASXt API&lt;/h2>
&lt;p>The cuBLASXt API of cuBLAS exposes a multi-GPU capable Host interface&lt;/p>
&lt;p>cuBLASXT 似乎可以调用多个 GPU，比如有 4 A10 in QZ Server，code 限制只用两个 GPU。通过 cuBLASXT 执行 FP32 gemm，TFLOPS 应该不具备参考性了。&lt;/p>
&lt;h1 id="bug">BUG&lt;/h1>
&lt;p>2022&lt;/p>
&lt;h4 id="1212">12.12&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>CMake Error at CMakeLists.txt:31 &lt;span style="color:#f92672">(&lt;/span>cutlass_example_add_executable&lt;span style="color:#f92672">)&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Unknown CMake command &lt;span style="color:#e6db74">&amp;#34;cutlass_example_add_executable&amp;#34;&lt;/span>.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>原因：可能是 gcc 版本问题，官方说的是 gcc7.3+，用的是 gcc5.5。&lt;/p>
&lt;p>切换到 gcc7.5.0 没有解决这个问题。&lt;/p>
&lt;p>2024-03-26 17:45:54，总结一下这个问题。使用 cmake 编译 cutlass 要处在主目录下，我自己是进入到 example 的子目录去了。在主目录编译之后，在 build 中可以找到 example 的 makefile 等文件。&lt;/p>
&lt;h4 id="314">3.14&lt;/h4>
&lt;p>2023.3.14 继续解决这个问题。&lt;/p>
&lt;p>2023-03-14 15:49:24，似乎是编译 example 的方式不对，根据一个模板，使用以下方式来编译&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 根目录下编译整个 projec&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ mkdir build &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> cd build
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ cmake ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ make 00_basic_gemm
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 00_basic_gemm bin 会生成在 cutlass/build/examples/00_basic_gemm 目录下&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>参考：https://github.com/sxzhang1993/Run-cutlass-with-gpgpu-sim&lt;/p></description></item><item><title>关于 Deep Work</title><link>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_deep_work/</link><pubDate>Sun, 08 May 2022 20:56:54 +0800</pubDate><guid>https://huweim.github.io/post/%E6%80%BB%E7%BB%93_deep_work/</guid><description>&lt;h2 id="01-知乎">0.1 知乎&lt;/h2>
&lt;p>知乎一位作者写的自我观察非常好，在我需要去完成论文的那段时间，我也是进入了这样一种状态。这个任务必须去交付（DDL 4.14），而且需要交互（修改之后给娄老师，并且完成娄老师交代的改动），是一种紧张，紧凑的任务，但是不觉得效率很高，写初稿反而磕磕盼盼，但是事后来看，在一段比较短的时间内（4.4-4.13）产出了一篇有结构的初稿并且慢慢完善并投稿。而现在，你需要记住、重拾这种状态，并把他融入到你的日常工作中。&lt;/p>
&lt;blockquote>
&lt;p>我观察到自己真正非常高效地推进困难任务，产出自己想要的结果往往发生在连续的长时间的工作中，并且我的心理状态是这样的：我一定要在这个任务上有重大突破或者完成它，不然饭也先别吃了，于是我往往会在同一个任务上从下午一点工作到六七点，或者从下午五点工作到晚上十点十一点，碰到问题就解决问题，没有头绪就尝试各种可能推进任务的可能性。别看这一下子时间花的挺长，产生的结果和进展常常令我感到惊讶。以我常规的工作方式（如每天固定投入1-2小时），往往拖了一两周都毫无进展的困难任务，我一整个下午就解决了。这样的情况发生了很多次，并且反差如此的强烈，于是我打算将这个现象思考清楚，总结出其中的原因。我很自然地联想到了Cal Newport的《Deep Work》，隐隐感觉和他提出的“深度工作”的这个概念有关。当然在总结他书中的观点之前，我会想梳理一下自己的思考。&lt;/p>
&lt;/blockquote>
&lt;h2 id="02-知乎总结">0.2 知乎总结&lt;/h2>
&lt;blockquote>
&lt;p>最小阻力定律 （The Law of Least Resistance），我们人类天生倾向于选择一条阻力最小的路径，也就是说我们倾向于回避困难任务，选择更轻松、更简单的事情先做。因此在常规工作方式下，你太容易不自觉地回避困难任务了，虽然你可能计划要在某件事上工作1-2小时，但其实在这些时间内，你都很可能有意无意地远离真正能推进任务的困难的点，只是做些表层的简单的事，并且很容易被别的事情分心从而中断在这个任务上的投入（比如，查看回复邮件，肚子饿了想着先回家吃饭）；于是你在这个困难任务上真正的有效投入其实非常有限，也就不奇怪几周时间也没什么进展了。而另一种深度工作方式，由于我在一开始就和自己约定好了：不解决问题，饭都不吃，做好了打持久战的准备，所以退无可退，避无可避，只能直面最困难的点。&lt;/p>
&lt;/blockquote>
&lt;p>毫无疑问，我会倾向于在简单任务（LeetCode简单题，回复邮件，刷知乎，读paper的intruction和abstract，浅层的阅读代码）上花费时间来获取反馈、满足感和完成感。面对困难任务时，总是在解决掉困难任务的一个简单部分\有所进展之后，就想回到床上躺一会儿。这时最近（2022-05-07 14:40:33）工作的普遍现象。&lt;/p>
&lt;blockquote>
&lt;p>尽量不要切换任务，因为有各种成本（意志力成本，任务启动成本）。意志力成本：我们对困难任务多少会有些恐惧，所以启动它本身就要消耗一些意志力，如果你按照常规的工作方式拖着很多天都没解决，那么每次启动这个任务的时候都要一次又一次地消耗意志力成本。任务启动成本：启动任务直到在最困难的点想办法推进任务之前，你需要回顾涉及到的各种背景知识、约束条件和细节，因此你在不同的时间段启动任务时，每次这个任务启动成本也是不能省的。因此一件事干大半天、一整天的收益和产生的价值远远超过你一天在几个任务间切换，每个任务各花1-2小时。当我们把指数效应放到较大的时间尺度下，我们看到的现象是一件事你坚持很多天，很多个月，很多年，越到后期你越能获得指数级的丰厚回报；其实我们也可以把指数效应放到较小的时间尺度下，比如一天，在一天中，你坚持做一件事一直做下去，越到后面你也越能获得指数级的回报，而如果你只在一件事上花了1-2小时，很可能你还没等到收益指数级增长的时候。（而像盖茨这样的大神，在创业初期写程序的时候，可能连续几周几个月连轴转都在高度专注地推进一件事，可以想象到后面所产生的恐怖的指数级的价值。）&lt;/p>
&lt;/blockquote>
&lt;p>没错，启动任务会消耗大量的精神力，而自己老是在启动后自我中断，这无疑大大降低了自己的效率。自己能认识到中断任务的负面反映，知道过于固定的任务时间（比如严格 2h paper reading）是不可取的，这也是我寻求 time management 方法的原因。&lt;/p>
&lt;blockquote>
&lt;p>当然不是所有事情都适合用深度工作的方式，现在看来自认为的困难任务是适合的，而比较简单但工作量巨大的任务却不适合，原因其实就在上面写的两条中了。
更新一条：长时间专注于同一个任务，越到后面越会有指数级的效应和产出，还很可能和cognitive workload theory有关，越到后面，因为在之前的时间里你已经将那些基础性的东西都弄得很熟悉了，所以也就不再占据你的认知工作负荷（cognitive workload），这样到最后你大脑的认知思考能力全部被解放出来集中在最难的点上，不断地取得之前浅度工作（shallow work）所不能取得的突破。&lt;/p>
&lt;p>Cal自己是”深度工作“的践行者，他的一整天都会深度围绕着一项核心的工作，然后将那些无法避免的浅层工作压缩到自己日程的边角料时间段里。这样一天仅仅三到四个小时的无中断的高度专注的工作，一周五天就能创造出很多有价值的东西。Cal自己还是两个孩子的父亲，这样的工作方式也让他有更多的时间留给家人，并且让他有时间阅读惊人数量的书籍。&lt;/p>
&lt;/blockquote>
&lt;h1 id="1-youtube">1. Youtube&lt;/h1>
&lt;p>举了几个例子，JK 罗琳为了避免干扰，找了家酒店写作，她原本没打算一直待在那里。但是第一天工作的效果很好，所以他就继续下去了，直到完成《哈利波特》。&lt;/p>
&lt;p>比尔盖茨 1974 年用 deep work 理论完成 basic 的第一版，在 8 个周的时间内，他一直在写代码，累了就在键盘上趴一会儿，睡一个小时。最后 8 周完成了这个软件。&lt;/p>
&lt;p>MIT 和一些学校的学生、老师发现 deep work 对他们研究工作的帮助，于是创作了这本书。普通人可能没法像他们那样一次在一个工作上投入 8 weeks，但是仍然有进入 deep work 的方法。&lt;/p>
&lt;p>deep work 很难，也很稀少。我们的世界有很多分散注意力的东西，比如合作时需要立刻回邮件，回消息，比如社交媒体的影响，刷虎扑，微博等等。&lt;/p>
&lt;p>一些 deep work 的方法&lt;/p>
&lt;h2 id="11-schedule-distraction">1.1 Schedule Distraction&lt;/h2>
&lt;p>大概就是说统一一个时间来处理分散注意力的事项。这个和我最近在做的其实很像，比如昨天（2022-05-07）在想去看一些信息的时候（研究院）没有立刻去，而是把它记录下来，之一统一处理。这是一个避免分散注意力，保持高效的方法。玩手机，回邮件也应该有意识地去克制。&lt;/p>
&lt;h2 id="12-deep-work-ritual">1.2 Deep Work Ritual&lt;/h2>
&lt;p>简而言之就是，保持节奏，养成习惯。养成习惯这个技巧，在有意识地学习。&lt;/p>
&lt;p>一周 7 天，你可能习惯在晚上进入 deep work，那就 7 天都保持这个节奏，把会议，事项安排到早上，把需要 deep work 的工作安排在晚上。&lt;/p>
&lt;p>研究表明新手大概能保持 1h deep work，但是 deep work master 能够保持大概 4h，要争取做到这个强度。&lt;/p>
&lt;h2 id="13-evening-shundown">1.3 Evening Shundown&lt;/h2>
&lt;p>休息好很重要。没做完的事情，拆分成比较具体的事情，写入第二天的计划中。因为此时一天的工作还保存在大脑的 cache 中，主要是还没有断开连接，列好计划，第二天可以减少很多开销。对于需要 deep work 的工作，需要及时 shutdown，列好计划之后在第二天留出充足的时间来完成，而不是强行低效率地去磨。&lt;/p>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/39759254">https://zhuanlan.zhihu.com/p/39759254&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=gTaJhjQHcf8">https://www.youtube.com/watch?v=gTaJhjQHcf8&lt;/a>&lt;/p></description></item></channel></rss>