<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Huggingface on Weiming Hu</title><link>https://huweim.github.io/tags/huggingface/</link><description>Recent content in Huggingface on Weiming Hu</description><generator>Hugo</generator><language>en</language><lastBuildDate>Sat, 26 Nov 2022 16:17:41 +0800</lastBuildDate><atom:link href="https://huweim.github.io/tags/huggingface/index.xml" rel="self" type="application/rss+xml"/><item><title>自己动手部署transformer模型 by huggingface</title><link>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E9%83%A8%E7%BD%B2transformer%E6%A8%A1%E5%9E%8B_huggingface/</link><pubDate>Sun, 23 Oct 2022 11:00:17 +0800</pubDate><guid>https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E9%83%A8%E7%BD%B2transformer%E6%A8%A1%E5%9E%8B_huggingface/</guid><description>&lt;h1 id="0-前言">0. 前言&lt;/h1>
&lt;p>这部分内容还是很重要的，预计会设计常见的 pytorch 模型部署方法，理解框架中，每个模块在做什么。另外，这也是工程上必备的技能。&lt;/p>
&lt;h2 id="01-模型及下载地址">0.1 模型及下载地址&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Model&lt;/th>
 &lt;th>Repo&lt;/th>
 &lt;th>Paper&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>ResNet (18: 12M; 50: 26M; 152: 60M)&lt;/td>
 &lt;td>&lt;a href="https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py">https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py&lt;/a>&lt;/td>
 &lt;td>&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>BERT (110 / 330M)&lt;/td>
 &lt;td>&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT">https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://arxiv.org/abs/1810.04805">https://arxiv.org/abs/1810.04805&lt;/a>&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>GPT-2 (1.5B)&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/gpt-2">https://github.com/openai/gpt-2&lt;/a>&lt;/td>
 &lt;td>&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>OPT (125 / 350M; 1.3 / 2.7 / 6.7 / 13 / 30 / 66 / 175B)&lt;/td>
 &lt;td>&lt;a href="https://github.com/facebookresearch/metaseq">https://github.com/facebookresearch/metaseq&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://arxiv.org/pdf/2205.01068.pdf">https://arxiv.org/pdf/2205.01068.pdf&lt;/a>&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>BLOOM (560M; 1.1 / 1.7 / 3 / 7.1 / 176B)&lt;/td>
 &lt;td>&lt;a href="https://huggingface.co/docs/transformers/model_doc/bloom">https://huggingface.co/docs/transformers/model_doc/bloom&lt;/a>&lt;/td>
 &lt;td>&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>T5 (60 / 220 / 770M; 3 / 11B)&lt;/td>
 &lt;td>&lt;a href="https://github.com/google-research/text-to-text-transfer-transformer#released-model-checkpoints">https://github.com/google-research/text-to-text-transfer-transformer#released-model-checkpoints&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://jmlr.org/papers/volume21/20-074/20-074.pdf">https://jmlr.org/papers/volume21/20-074/20-074.pdf&lt;/a>&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h2 id="02-模型下载方法">0.2 模型下载方法&lt;/h2>
&lt;p>2023-07-08 20:10:12，重新回顾 22 年关于大模型研究的工作。从 chatgpt 爆火之后，大模型应用的框架变得火热，语言模型的社区也变得火热起来。准备在 ant_ext 工作中加入一些新的模型的评估，但是期智连接 huggingface 的网络老是抽风，导致试图从 huggingface 下载模型时出现错误。现在总结一些其他的下载方法。&lt;/p></description></item></channel></rss>