<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>编程 on Cory Code</title><link>https://huweim.github.io/tags/%E7%BC%96%E7%A8%8B/</link><description>Recent content in 编程 on Cory Code</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© Athul</copyright><lastBuildDate>Tue, 17 Aug 2021 14:12:38 +0800</lastBuildDate><atom:link href="https://huweim.github.io/tags/%E7%BC%96%E7%A8%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>CUDA_set_gridDim</title><link>https://huweim.github.io/posts/cuda_set_griddim/</link><pubDate>Tue, 17 Aug 2021 14:12:38 +0800</pubDate><guid>https://huweim.github.io/posts/cuda_set_griddim/</guid><description>0. 前言 在一个 CUDA 课程的考试中由于这个地方的理解问题导致没有成功 pass，应该如何设置 BlockNum 呢？
1. 参数 compute capability, CC 这个也就是计算架构，对应于具体的 NVIDIA 显卡型号，可以在编译时作为 option 输入
ThreadsPerBlock 这个参数是最常见的，也就是 blockDim, 自己设置的是1024, 计算架构会决定 block 内线程数的上限
RegistersPerThread 一直没有设置过这个参数，ptxas info 会给给出具体的使用数据
1.1 问题 接下来问题出现了，到底应该怎么设置 gridDim 呢？也就是 BlockNums. 在测试代码中数据量 N=10000000, 自己的理解是我一个 block 用1024个 threads，使用 256 个block，这样的话总共有 256*1024 个 threads 可以并行工作，那么我用 for 循环加上步长 stride = blockDim.x * gridDim.x 来实现 N 个数据的计算，也就是
#define N 10000000 #define THREADS_PER_BLOCK 1024 #define BLOCK_NUMS 256 //#define BLOCK_NUMS ((N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK) __global__ void gpu_histogram(int *input, int count, int *output) { int index = blockIdx.</description></item></channel></rss>