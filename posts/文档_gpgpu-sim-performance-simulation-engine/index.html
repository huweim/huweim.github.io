<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>文档_GPGPU-sim - Performance Simulation Engine - Cory Code</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta itemprop="name" content="文档_GPGPU-sim - Performance Simulation Engine">
<meta itemprop="description" content="GPGPU-sim - Performance Simulation Engine
1 Performance Model Software Objects ldst_unit *m_ldst_unit; 前面的 m 可能表示这个类型的变量
1.2 SIMT Core Class SIMT Core 中的微架构在 shader.h/cc 的类 shader_core_ctx 中实现
 shd_warp_t objects 的集合用于建模每个 warp 在 core 中的状态 simt_stack object, 处理每个 warp 的分支 set of scheduler_unit obj, 选择 set 中 warp 的一条 or 多条指令发射执行 Scoreboard obj 处理 data hazard opndcoll_rfu_t obj, model operand collector set of simd_function_unit obj 实现 ALU pipeline ldst_unit 实现 memory pipeline shader_memroy_interface 将 SIMT Core 连接到相应的 SIMT Core Cluster  每个 core cycle, 调用 shader_core_ctx::cycle() 来模拟 SIMT Core 的一个 cycle。cycle function 以按从下往上的顺序 (也就是从 writeback() 到 fetch()) 调用下列函数">
<meta itemprop="datePublished" content="2021-09-28T14:59:35&#43;08:00" />
<meta itemprop="dateModified" content="2021-09-28T15:44:35&#43;08:00" />
<meta itemprop="wordCount" content="980">



<meta itemprop="keywords" content="官方文档,GPGPU-Sim," /><meta property="og:title" content="文档_GPGPU-sim - Performance Simulation Engine" />
<meta property="og:description" content="GPGPU-sim - Performance Simulation Engine
1 Performance Model Software Objects ldst_unit *m_ldst_unit; 前面的 m 可能表示这个类型的变量
1.2 SIMT Core Class SIMT Core 中的微架构在 shader.h/cc 的类 shader_core_ctx 中实现
 shd_warp_t objects 的集合用于建模每个 warp 在 core 中的状态 simt_stack object, 处理每个 warp 的分支 set of scheduler_unit obj, 选择 set 中 warp 的一条 or 多条指令发射执行 Scoreboard obj 处理 data hazard opndcoll_rfu_t obj, model operand collector set of simd_function_unit obj 实现 ALU pipeline ldst_unit 实现 memory pipeline shader_memroy_interface 将 SIMT Core 连接到相应的 SIMT Core Cluster  每个 core cycle, 调用 shader_core_ctx::cycle() 来模拟 SIMT Core 的一个 cycle。cycle function 以按从下往上的顺序 (也就是从 writeback() 到 fetch()) 调用下列函数" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://huweim.github.io/posts/%E6%96%87%E6%A1%A3_gpgpu-sim-performance-simulation-engine/" />
<meta property="article:published_time" content="2021-09-28T14:59:35+08:00" />
<meta property="article:modified_time" content="2021-09-28T15:44:35+08:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="文档_GPGPU-sim - Performance Simulation Engine"/>
<meta name="twitter:description" content="GPGPU-sim - Performance Simulation Engine
1 Performance Model Software Objects ldst_unit *m_ldst_unit; 前面的 m 可能表示这个类型的变量
1.2 SIMT Core Class SIMT Core 中的微架构在 shader.h/cc 的类 shader_core_ctx 中实现
 shd_warp_t objects 的集合用于建模每个 warp 在 core 中的状态 simt_stack object, 处理每个 warp 的分支 set of scheduler_unit obj, 选择 set 中 warp 的一条 or 多条指令发射执行 Scoreboard obj 处理 data hazard opndcoll_rfu_t obj, model operand collector set of simd_function_unit obj 实现 ALU pipeline ldst_unit 实现 memory pipeline shader_memroy_interface 将 SIMT Core 连接到相应的 SIMT Core Cluster  每个 core cycle, 调用 shader_core_ctx::cycle() 来模拟 SIMT Core 的一个 cycle。cycle function 以按从下往上的顺序 (也就是从 writeback() 到 fetch()) 调用下列函数"/>
<link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="screen" href="https://huweim.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://huweim.github.io/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://huweim.github.io/css/dark.css" />

	<script src="https://huweim.github.io/js/feather.min.js"></script>
	
		<script src="https://huweim.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	
	<h1 class="site-title"><a href="https://huweim.github.io/">Cory Code</a></h1>
	<div class="site-description"><p>Minimal and Clean <a href="https://github.com/athul/hugo-ink">blog theme for Hugo</a></p><nav class="nav social">
			<ul class="flat"><li><a href="https://github.com/huweim" title="GitHub"><i data-feather="github"></i></a></li><li><a href="https://twitter.com/athulcajay/" title="Twitter"><i data-feather="twitter"></i></a></li><li><a href="https://gitlab.com/athul/" title="GitLab"><i data-feather="gitlab"></i></a></li><li><a href="#" class="scheme-toggle" id="scheme-toggle"></a></li></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/posts">All posts</a>
			</li>
			
			<li>
				<a href="/categories/">Categories</a>
			</li>
			
			<li>
				<a href="/archives">Archives</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
			<li>
				<a href="/about/">About</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post">
			<div class="post-header">
				
					<div class="meta">
						<div class="date">
							<span class="day">28</span>
							<span class="rest">Sep 2021</span>
						</div>
					</div>
				
				<div class="matter">
					<h1 class="title">文档_GPGPU-sim - Performance Simulation Engine</h1>
				</div>
			</div>
					
			<div class="markdown">
				<p>GPGPU-sim - Performance Simulation Engine</p>
<h1 id="1-performance-model-software-objects">1 Performance Model Software Objects</h1>
<div class="highlight"><pre class="chroma"><code class="language-c++" data-lang="c++"><span class="n">ldst_unit</span> <span class="o">*</span><span class="n">m_ldst_unit</span><span class="p">;</span>
</code></pre></div><p>前面的 m 可能表示这个类型的变量</p>
<h2 id="12-simt-core-class">1.2 SIMT Core Class</h2>
<p>SIMT Core 中的微架构在 shader.h/cc 的类 shader_core_ctx 中实现</p>
<ul>
<li>shd_warp_t objects 的集合用于建模每个 warp 在 core 中的状态</li>
<li>simt_stack object, 处理每个 warp 的分支</li>
<li>set of scheduler_unit obj, 选择 set 中 warp 的一条 or 多条指令发射执行</li>
<li>Scoreboard obj 处理 data hazard</li>
<li>opndcoll_rfu_t obj, model operand collector</li>
<li>set of <code>simd_function_unit</code> obj 实现 ALU pipeline</li>
<li><code>ldst_unit</code> 实现 memory pipeline</li>
<li><code>shader_memroy_interface</code> 将 SIMT Core 连接到相应的 SIMT Core Cluster</li>
</ul>
<p>每个 core cycle, 调用 <code>shader_core_ctx::cycle()</code> 来模拟 SIMT Core 的一个 cycle。cycle function 以按从下往上的顺序 (也就是从 writeback() 到 fetch()) 调用下列函数</p>
<ul>
<li>fetch()</li>
<li>decode()</li>
<li>issue()</li>
<li>read_operand()</li>
<li>execute()</li>
<li>writeback()</li>
</ul>
<p>多个流水线阶段通过一组指向 <code>warp_inst_t</code> 的流水线寄存器链接 (除了 Fetch and Decode, 它们通过 <code>ifetch_buffer_t</code> 连接)</p>
<blockquote>
<p>也就是 Fetch 和 Decode 函数中的变量 m_inst_fetch_buffer</p>
</blockquote>
<p>当访问特定于 SIMT core 的配置选项时，每个 <code>shader_core_ctx</code> 对象引用一个公共 <code>shader_core_config</code> 对象。所有 <code>shader_core_ctx</code> 对象也链接到 <code>shader_core_stats</code> 对象的一个普通实例，该对象跟踪所有 SIMT core 的一组性能测量值。</p>
<h3 id="121-fetch-and-decode-software-model">1.2.1 Fetch and Decode Software Model</h3>
<p>I-Buffer 在 <code>shd_warp_t</code>  类中作为数组实现，每个 <code>shd_warp_t</code> 有集合 m_ibuffer，默认大小为 2</p>
<blockquote>
<p>可以修改 IBUFFER_SIZE 来调整每个 warp 的 I-Buffer slot 大小</p>
</blockquote>
<p><code>shd_warp_t</code> 也有标志位决定 warp 的 eligibility 以备发射。解码的指令存在 ibuffer_entry，作为指针指向 <code>warp_inst_t</code> object, <code>warp_inst_t</code> 保留指令使用的操作类型和操作数的信息</p>
<p><strong>Fetch</strong></p>
<p>如果 decode stage 没有 stall, 即 <code>m_inst_fetch_buffer</code> 没有有效指令，那么 fetch unit 就可以工作 (<code>shader_core_ctx::m_inst_fetch_buffer</code> 作为 fetch 和 decode stage 之间的 pipeline register)</p>
<blockquote>
<p>也就是 fetch() 函数中的 !m_inst_fetch_buffer.m_valid 时进入最外层 if 语句</p>
</blockquote>
<p>外层循环用于实现轮询调度器，最新调度的 warp id 存在 <code>m_last_warp_fetched</code>。</p>
<p>在 fetch() 函数中，进入最外层 if 语句，以及第2层中的 else 语句后，</p>
<ul>
<li>第3层中的第1个 if 语句检查 warp 是否已经完成执行</li>
<li>第3层中的第2个 if 语句完成实际的从指令 cache 中取数据 (hit)，或者生成内存访问 (miss) 的操作。
<ul>
<li>第2个 if 语句主要是检查当前 warp 对应的 entry 是否已经存储了有效的指令
<ul>
<li>条件语句中的 <code>m_warp[warp_id]-&gt;ibuffer_empty()</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Decode</strong></p>
<p>decode stage 简单地检查 <code>shader_core_ctx::m_inst_fetch_buffer</code>，然后开始解码指令，当前配置是一个周期解码2条指令，并将其存入对应的 I-Buffer entry (也就是 <code>m_ibuffer </code>)</p>
<h3 id="122-schedule-and-issue-software-model">1.2.2 Schedule and Issue Software Model</h3>
<p>每个 core 中，有数量可配置的 scheduler unit. 在函数 <code>shader_core_ctx::issue()</code> 中，会使用一个 for loop 遍历这些 scheduler unit，每个 scheduler unit 都调用 <code>scheduler_unit::cycle()</code> 函数</p>
<ul>
<li>在 <code>scheduler_unit::cycle()</code> 函数中，通过调用 <code>shader_core_ctx::issue_warp()</code> 将指令发送到执行流水线</li>
<li><strong>在 <code>shader_core_ctx::issue_warp()</code> 函数中</strong>，指令通过调用 <code>shader_core_ctx::func_exec_inst()</code> 来执行，调用 <code>updateSIMTStack()</code> 中的 <code>simt_stack::update()</code> 来更新 SIMT Stack。指令也会因为 <code>warp_t:set_membar()</code> 以及 <code>set_t::warp_reaches_barrier</code> 而等待/释放</li>
</ul>
<p>另一方面，寄存器信息由 <code>Scoreboard::reserveRegisters()</code> 保存。<code>scheduler_unit::m_sp_out, scheduler_unit::m_sfu_out, scheduler_unit::m_mem_out</code> 分别指向 SP, SFU, Mem 流水线的 issue stage and execution stage 之间的第一个 pipeline register。这也是为什么在每条指令发射之前都要检查这些单元</p>
<h3 id="123-simt-stack-software-model">1.2.3 SIMT Stack Software Model</h3>
<p>每个scheduler unit 有一个 SIMT stacks. 每个 SIMT stack 对应一个 warp</p>
<blockquote>
<p>所以 SIMT Stack 可以作为 warp scheduler unit 中的硬件实现，为一个 warp 服务</p>
</blockquote>
<p>在 <code>scheduler_unit::cycle()</code> 函数中，被调度的 warp 对应的 SIMT Stack 中的栈顶 entry 决定被发射的指令。栈顶 entry 的 PC value 通常与该 warp 对应 I-Buffer 下一条指令的 PC value 一致 (一致说明没有出现分支)。否则出现 control hazard, 它们如果不匹配，I-Buffer 中的指令会被 flush.</p>
<blockquote>
<p>也就是说这是一个简单的分支跳转检测机制。SIMT Stack 的栈顶存放的是下一条指令，也就是 next PC value. 无跳转情况下 I-Buffer 中的下一条指令的 PC value 应该和 SIMT Stack 栈顶的 next PC value 一致。</p>
<p>如果不一致说明出现了跳转，那么在 I-Buffer 中的下一条指令的 PC value 是无效的，需要刷掉 I-Buffer</p>
</blockquote>
<p>:question: SIMT Stack 在类 <code>simt_stack</code> 中实现。SIMT Stack 在每次发射后通过函数 <code>simt_stack::update(...)</code> 更新。函数 <code>simt_stack::update(...)</code> (in abstarct_hardware_model.cc) 实现了在发散点和聚合点所需的算法。Functional execution (参见4.5，这个部分讲述了指令的执行) 是在更新 SIMT stack 之前的发射阶段执行的。这允许发射阶段拥有每个线程的 next PC 的信息，因此，可以根据需要更新 SIMT stack.</p>
<blockquote>
<p>Functional execution 是什么？可能要看了4.5才知道</p>
</blockquote>
<h3 id="124-scoreboard-software-model">1.2.4 Scoreboard Software Model</h3>
<p>scoreboard unit 在 <code>shader_core_ctx</code> 作为成员对象被实例化，通过引用 (指针) 传递到 <code>scheduler_unit </code>。</p>
<blockquote>
<p>理解为 scoreboard 作为 core 的一个硬件单元</p>
</blockquote>
<p>它存储了 shader core id (<code>m_sid</code>) 和一个通过 warp id 索引的寄存器表 (<code>reg_table</code>)。寄存器表存储了每个 warp 保留的寄存器的数量。 函数 <code>Scoreboard::reserveRegisters(...), Scoreboard::releaseRegisters(...) and Scoreboard::checkCollision(...)</code> 分别用于保留寄存器，释放寄存器，在 warp 发射前检查冲突。</p>
<h3 id="125-operand-collector-software-model">1.2.5 Operand Collector Software Model</h3>
<p>Operand Collector 建模在主流水线的一个阶段，由函数 <code>shader_core_ctx::cycle()</code> 调用执行。这个阶段由函数 <code> shader_core_ctx::read_operands()</code> 表示。关于 ALU Pipeline 的更多细节在下一节 1.2.6</p>
<p>类 <code>opndcoll_rfu_t </code> 基于寄存器文件单元建模了 operand collector. 包括 collector unit 集合，仲裁器，dispatch 单元的抽象。</p>
<p><code>opndcoll_rfu_t::allocate_cu(...)</code> 用于将 <code>warp_inst_t </code> 分配到给定 operand collector 集合中的空闲 operand collector. 它也将所有源操作数的读请求添加到仲裁器中相应的 bank 队列</p>
<p>然而，<code>opndcoll_rfu_t::allocate_reads(...)</code> 处理没有冲突的读请求，也就是不同寄存器 bank 中并且没有进入同一个 operand collector 的读请求将从仲裁器队列中出队。写请求总是优先于读请求。</p>
<p>函数 <code>opndcoll_rfu_t::dispatch_ready_cu()</code> 会 dispatch ready operand collectors 的操作数寄存器到执行阶段</p>
<p>函数 <code>opndcoll_rfu_t::writeback( const warp_inst_t &amp;inst )</code> 在内存流水线的写回阶段被调用。用于分配写请求。</p>
<p>上述内容总结了建模 operand collector 的主要函数的重点，更多的细节在源代码中的 <code>shader.cc/h</code> 中的类 <code>opndcoll_rfu_t</code></p>
<h3 id="126-alu-pipeline-software-model">1.2.6 ALU Pipeline Software Model</h3>
<p>SP 单元和 SFU 单元的时间模型主要在 <code>shader.h</code> 中的类 <code>pipelined_simd_unit</code> 中实现。建模这两个单元的特定类 (<code>sp_unit</code> and <code>sfu</code>) 派生自这个类 (<code>pipelined_simd_unit</code>)，其中包含被重写的成员函数 <code>can_issue()</code> ，用于指定单元可执行的指令类型。</p>
<blockquote>
<p>比如源代码中，类 <code>sfu</code> 可以执行执行类型 <code>SFU_OP, ALU_SFU_OP, DP_OP</code></p>
</blockquote>
<p>SP 单元通过流水线寄存器 <code>OC_EX_SP</code> 连接 operand collector, SFU 单元通过流水线寄存器 <code>OC_EX_SFU</code> 连接 operand collector. 两个单元通过流水线寄存器 <code>WB_EX</code> 共享写回阶段。为了避免两个单元在写回阶段冲突而停滞，每一条进入任一单元的指令都必须在结果总线(<code>m_result_bus</code>)中分配一个 slot，然后才会被发送到指定单元 (细节在 <code>shader_core_ctx::execute()</code>)</p>
<blockquote>
<p>OC -&gt; operand collector</p>
</blockquote>
<p>下图说明了 <code>pipelined_simd_unit</code> 如何建模不同类型指令的吞吐量和延迟</p>
<p><!-- raw HTML omitted --></p>
<p>在每个 <code>pipelined_simd_unit</code>, 成员函数 <code>issue(warp_inst_t*&amp;)</code> 将给定的流水线寄存器的内容移动到 <code>m_dispatch_reg</code>. 指令在 <code>m_dispatch_reg</code> 中等待 <code>initiation_interval</code> cycles. 同时，没有其他指令被发射到这个单元，所以这个等待建模了指令的吞吐量。在等待后，指令派遣 (dispatch) 到内部流水线寄存器 <code>m_pipeline_reg</code> 以建模延迟 (可以得到指令等待了多久才被派遣到 <code>m_pipeline_reg</code>)。派遣位置是确定的，这样花费在 <code>m_dispatch_reg</code> 中的时间也被计入延迟。每个周期，指令将通过流水线寄存器前进，最终进入 <code>m_result_port</code>，这是 SP and SFU 单元的公共回写阶段的共享流水线寄存器 (<code>WB_EX</code>)。</p>
<p>每种指令类型的吞吐量和延迟在 <code>cuda-sim.cc</code> 中的<code>ptx_instruction::set_opcode_and_latency()</code> 中指定。这个函数在预解码期间被调用。</p>
<blockquote>
<p>指令吞吐量，一个 cycle 内处理指令的条数，也就是 ipc?</p>
<p>延迟也就是指令等待的时间</p>
<p>指令执行吞吐一般指的是每个时钟周期内可以执行的指令数目，不同指令的吞吐会有所不同。通常GPU的指令吞吐用每个SM每周期可以执行多少指令来计量。对于多数算术逻辑指令而言，指令执行吞吐只与SM内的单元有关，整个GPU的吞吐就是每个SM的吞吐乘以SM的数目。</p>
<p>主要受以下因素影响</p>
<ul>
<li><strong>功能单元</strong>的数目</li>
<li>指令<strong>Dispatch Port</strong>和<strong>Dispatch Unit</strong>的吞吐。
<ul>
<li>一个 warp 的指令要发射，首先要 eligible, 也就是没有等待 cache miss, 通过了 scoreboard 等待。</li>
<li>其次要被 warp scheduler 选中，由 Dispatch Unit 发送到相应的 Dispatch Port. Kepler、Maxwell和Pascal是一个Warp Scheduler有两个Dispatch Unit，所以每cycle最多可以发射两个指令，也就是双发射。而Turing、Ampere每个Warp Scheduler只有一个Dispatch Unit，没有双发射，那每个周期就最多只能发一个指令。但是Kepler、Maxwell和Pascal都是一个Scheduler带32个单元（这里指full-throughput的单元），每周期都可以发新的warp。而Turing、Ampere是一个Scheduler带16个单元，每个指令要发两cycle，从而空出另一个cycle给别的指令用。</li>
<li><strong>最后要求Dispatch Port或其他资源不被占用</strong>，port被占的原因可能是前一个指令的执行吞吐小于发射吞吐，导致要Dispatch多次，比如Turing的两个FFMA至少要stall 2cycle，LDG之类的指令至少是4cycle。更详细的介绍大家可以参考之前的专栏文章。</li>
</ul>
</li>
<li><strong>GPR读写吞吐</strong>。绝大部分的指令都要涉及GPR的读写，由于Register File每个bank每个cycle的吞吐是有限的（一般是32bit），如果一个指令读取的GPR过多或是GPR之间有bank conflict，都会导致指令吞吐受影响。GPR的吞吐设计是影响指令发射的重要原因之一，有的时候甚至占主导地位，功能单元的数目配置会根据它和指令集功能的设计来定。比如NV常用的配置是4个Bank，每个bank每个周期可以输出一个32bit的GPR。这样FFMA这种指令就是3输入1输出，在没有bank conflict的时候可以一个cycle读完。其他如DFMA、HFMA2指令也会根据实际的输入输出需求，进行功能单元的配置。</li>
<li>很多指令有<strong>replay</strong>的逻辑（<a href="https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/35566178/how-to-explain-instruction-replay-in-cuda">参考Greg Smith在StackOverflow上的一个回答</a>）。这就意味着有的指令一次发射可能不够。这并不是之前提过的由于功能单元少而连续占用多轮dispath port，而是指令处理的逻辑上有需要分批或是多次处理的部分。比如constant memory做立即数时的cache miss，memory load时的地址分散，shared memory的bank conflict，atomic的地址conflict，甚至是普通的cache miss或是TLB的miss之类。根据上面Greg的介绍，Maxwell之前，这些replay都是在warp scheduler里做的，maxwell开始将它们下放到了各级功能单元，从而节约最上层的发射吞吐。不过，只要有replay，相应dispath port的占用应该是必然的，这样同类指令的总发射和执行吞吐自然也就会受影响。
<ul>
<li>L1 cache miss 也有进行 replay 的逻辑</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="127-memory-stage-software-model">1.2.7 Memory Stage Software Model</h3>
<p><code>shader.cc</code> 中的类 <code>ldst_unit</code> 实现了 shader 流水线的内存阶段。这个类实例化了所有 in-shader 内存的操作: texture (<code>m_L1T</code>), constant (<code>m_L1C</code>) and data (<code>m_L1D</code>). <code>ldst_unit::cycle()</code> implements the guts of the unit&rsquo;s operation and is pumped <code>m_config-&gt;mem_warp_parts</code> times pre core cycle. 完全对齐的内存访问 (fully coalesced memory access) 可以在一个 shader cycle 内被处理。<code>ldst_unit::cycle()</code> 处理来自 interconnect 的内存响应 (存在 <code>m_response_fifo</code>), 填充 cache 并将存储标记为完成。这个函数还 cycles the caches 以便它们可以将未命中数据的请求发送给 interconnect.</p>
<p>每种 L1 内存类型的 cache 访问分别在 <code>shared_cycle(), constant_cycle(), texture_cycle()</code> and <code>memory_cycle()</code> 中完成。<code>memory_cycle()</code> 用于访问 L1 data cache. 每个函数会调用 <code>process_memory_access_queue()</code>, 这是一个通用函数，它从指令内部访问队列中提取访问并将这个请求发送到 cache 中。如果访问不能再这个 cycle 中被处理 (即没有未命中，也没有命中 (也就是之前介绍中提到的第三个状态 reserved fail)，这可能发生在系统队列满的时候，或是所有 cache line reserved 但还没有 fill)，那么会在下个 cycle 再次试图访问。</p>
<p>值得注意的是，并不是所有的指令都到达单元的写回阶段。在所有请求的 cache block 命中时，所有的 ST 指令和 LD 指令都将在 <code>cycle</code> 函数中退出流水线。这是因为它们不需要等待来自 interconnect 的响应，并且可以 by-pass 写回逻辑，该逻辑保存指令所请求的 cache line 和那些已经返回的 cache line。</p>
<h3 id="128-cache-software-model">1.2.8 Cache Software Model</h3>
<p><code>gpu-cache.h</code> 实现了 <code>ldst_unit</code> 用到的所有 cache. constant cache and data cache 都包含一个成员对象 <code>tag_array</code>，用于实现保留和替换的逻辑。函数 <code>probe()</code>  检查 cache block 地址而不影响相关数据的 LRU 位置, 函数 <code>access()</code> 旨在建模影响 LRU 位置的查找，生成未命中和访问的统计信息。MSHR 用类 <code>msgr_table</code> 建模，它建模了一个全相联 table, 合并有限数量的请求。请求通过 <code>next_access()</code> 函数从MSHR释放。</p>
<p>类 <code>read_only_cache</code> 被 constant cache 使用，并作为类 <code>data_cache</code> 的基类。这个层次结构可能有点令人困惑，因为 R/W data cache 是从 <code>read_only_cache</code> 扩展的 (理解为 R/W data cache 就是在只读 cache 类基础上加了一些功能来实现，从代码角度很好理解这句话)。原因是它们共享很多相同功能的函数，除了函数 <code>access</code> 需要写 <code>data_cacje</code> 这一点有所区别。L2 cache 也是通过类 <code>data_cache</code> 实现。</p>
<blockquote>
<p>这一点从 C 语言中类的角度去理解就好</p>
</blockquote>
<p>类 <code>tex_cache</code> 实现 texture cache. 它没有使用 <code>tag_array</code> 或是 <code>mshr_table</code>，因为它的操作和传统 cache 不太一样</p>
<h3 id="129-thread-block--cta--work-group-scheduling">1.2.9 Thread Block / CTA / Work Group Scheduling</h3>
<p>Thread Block 向 SIMT cores 的调度在 <code>shader_core_ctx::issue_block2core(...)</code> 中实现。一个 core 中可以并行调度的最大 block 数量由函数 <code>shader_core_config::max_cta(...)</code> 计算。这个函数基于程序中定义的 ThreadPerBlock (CUDA 编程中由程序员定义), 以及每个线程的寄存器使用情况、共享内存使用情况以及每个 core 的最大线程块数量的配置限制来计算上述 <strong>可以并行调度的最大 block 数量</strong>。具体地说，计算可以分配给 SIMT core 的 block 数量，上面的每个标准都是限制因素。其中的最小值是可以分配给 SIMT core 的最大 block 数量。</p>
<blockquote>
<p>各种资源中的短板决定了最多可以有多少个 block 并行。CUDA 编程的知识</p>
</blockquote>
<p>在函数 <code>shader_core_ctx::issue_block2core(...)</code> 中，block size 首先被填充为 warp size 的倍数。然后决定一个空闲硬件 thread id 的范围。通过调用函数 <code>ptx_sim_init_thread</code> 来初始化每个线程的函数状态。调用函数 <code>shader_core_ctx::init_warp</code> 初始化 SIMT stack and warp state.</p>
<p>当每条线程完成，SIMT core 调用函数 <code>shader_core_ctx::init_warp(...)</code> 来更新 active thread block 的状态。当 block 内所有线程完成执行， 同一个函数会减少 core 上 active block 的数量，允许在下一 cycle 调度更多 block. 从 pending kernels 中选择要调度的新线程块。</p>
<h1 id="2-interconnection-network">2 Interconnection Network</h1>
<p>Interconnection Network 接口有以下几个功能。这些函数在 <code>interconnect_interface.cpp</code> 中实现。这些函数被封装在 <code>icnt_wrapper.cpp</code> 中。使用<code>icnt_wrapper.cpp</code> 的最初目的是允许其他 network 模拟器连接到 GPGPU-Sim。</p>
<ul>
<li><code>init_interconnect()</code>: 初始化网络模拟器。它的输入是互连网络的配置文件和SIMT核心团簇和内存节点的数量。</li>
<li><code>interconnect_push()</code>: 指定源节点、目的节点、指向要传输的数据包的指针和数据包大小(以字节为单位)。</li>
<li><code>interconnect_pop()</code>: 获取一个节点号作为输入，并返回一个指向在该节点等待被弹出的数据包的指针。如果没有数据包，则返回NULL。</li>
<li><code>interconnect_has_buffer()</code>: 获取作为输入要发送的节点号和数据包大小，如果源节点的输入缓冲区有足够的空间，则返回1 (true)。</li>
<li><code>advance_interconnect()</code>: 应该在每个互连时钟周期被调用。顾名思义，它在一个周期内完成网络的所有内部步骤。</li>
<li><code>interconnect_busy()</code>: 如果网络中有一个正在传输的数据包，则返回1 (true)</li>
<li><code>interconnect_stats()</code>: 打印网络统计信息。</li>
</ul>
<h1 id="5-memory-partition">5 Memory Partition</h1>
<p>l2cache.cc/h 中有 class <code>memory_partition_unit</code></p>
<p>II. L2 Cache Model</p>
<p><code>mem_fetch *mf = m_L2cache-&gt;next_access();</code> 产生等待 fill MSHR entry 的内存请求的 reply,</p>

			</div>

			<div class="tags">
				
					
						<ul class="flat">
							
							<li><a href="/tags/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3">官方文档</a></li>
							
							<li><a href="/tags/gpgpu-sim">GPGPU-Sim</a></li>
							
						</ul>
					
				
			</div></div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div>2021  © Athul |  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>

<script>feather.replace()</script>
</body>
</html>
