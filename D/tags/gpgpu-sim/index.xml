<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPGPU-Sim on Cory Code</title>
    <link>http://localhost:1313/tags/gpgpu-sim/</link>
    <description>Recent content in GPGPU-Sim on Cory Code</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© Athul</copyright>
    <lastBuildDate>Tue, 28 Sep 2021 13:39:14 +0800</lastBuildDate>
    
	<atom:link href="http://localhost:1313/tags/gpgpu-sim/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>GPGPU-Sim 运行机制</title>
      <link>http://localhost:1313/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim-%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Tue, 28 Sep 2021 13:39:14 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E7%BC%96%E7%A8%8B_gpgpu-sim-%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/</guid>
      <description>0. 前言 在 GPGPU-Sim 跑一些比较大的 benchmark, 或者想要同时跑很多组 benchmark 的时候，在自己的电脑上跑，或者在虚拟机上运行的话速度肯定达不到要求，会成为工作中瓶颈。因此了解一下如何在服务器上跑 simulation, 以及如何提高运行 benchmark 的速度。
1. GPGPU-Sim 运行机制 首先要理解 application 是如何运行在 real machine 以及 GPGPU-Sim 上的，他们的区别在哪里？这里以 CUDA 代码为例。
GPGPU-Sim_vs_Real_Machine
1.1 Real Machine CUDA application 分为 host code and device code, 使用 nvcc 编译 .cu 代码时, 会将 host code 和 device code 分开。device code 被编译为 .ptx 文件，再通过 ptxas 编译为 cubin.bin 文件。host code, libcuda.a, cubin.bin 文件由 C/C++编译器编译了解生成可执行文件。
如何运行 CUDA application? 调用 libcuda 内的接口以在 GPU 上运行 device code.</description>
    </item>
    
    <item>
      <title>搭建GPGPU-Sim实验环境</title>
      <link>http://localhost:1313/posts/%E7%BC%96%E7%A8%8B_%E6%90%AD%E5%BB%BAgpgpu-sim%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Mon, 27 Sep 2021 22:54:06 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E7%BC%96%E7%A8%8B_%E6%90%AD%E5%BB%BAgpgpu-sim%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/</guid>
      <description>0. 前言 第一个思路是
 服务器OS-&amp;gt;Docker Container-&amp;gt;Ubuntu中运行GPGPU-Sim。 Docker Container update Docker Image-&amp;gt;Docker Image-&amp;gt;XXX.tar-&amp;gt;复制到你的电脑Windows-&amp;gt;复制到你的虚拟机Ubuntu-&amp;gt;XXX.tar-&amp;gt;Docker Image-&amp;gt;Docker Container-&amp;gt;Ubuntu中运行GPGPU-Sim-&amp;gt;修改GPGPU-Sim 然后同样使用上述过程移植到服务器，运行  这样是有问题的。首先这个过程没有意义，如果这样在你自己的虚拟机里面运行Docker, 那么仍然是命令行界面，和在服务器上运行的区别在哪？
这样实现了Docker的其中一个作用
 我在服务器上能跑，在我自己的虚拟机上也能跑。实现了在不同的环境下运行，而且无需安装多余的依赖。因为本质上我用的是 Docker 中的 Ubuntu 14 但我没有实现自己的目的  我的目的是什么？
  在自己的Ubuntu上使用VScode修改模拟器，简单地编译测试性能。修改后需要跑大量benchmark, 这个时候我不能用自己的电脑跑了，我需要移植了。
  把跑benchmark需要用到的东西放在服务器上，用服务器的计算资源运行。需要用到的东西是什么？
  benchmark: 一般是一些 .cu/.cl 代码编译后生成的可执行文件
   编译成功gpgpusim以后，实际上主要是生成了一个libcudart.so。
 那么就需要这个 libcudart.so
    所以理论上来说如果我使用一台固定的服务器，好像不需要一直更新Docker?无需安装 gcc4.5.1, cuda4.2。每次把这几个文件拷贝过去即可。
  0.1 测试 在 gpgpu-sim_distribution 目录下只放置 lib 文件夹 也是可以 Run 的，说明程序运行时只会 call libcudart.so 这个文件</description>
    </item>
    
    <item>
      <title>SIMT_Core</title>
      <link>http://localhost:1313/posts/simt_core/</link>
      <pubDate>Sat, 04 Sep 2021 19:04:57 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/simt_core/</guid>
      <description>0. 前言 搞懂 SIMT Core 对于理解 GPGPU 的指令 fetch、指令发射、内存访问、数据传输等步骤非常重要，按照 GPGPU-Sim 的官方文档进行一个简单的梳理
SIMT Core 的微架构模型分为
000 放一个硬件概念对应表 1. Front End  Instruction cache access Instruction buffer logic Scoreboard Scheduling logic SIMT stack  1.1 Fetch and Decode 这里介绍整个指令 Fetch and Decode 阶段，涉及到的硬件单元主要是 Fetch, I-Cache, Decode, I-Buffer, ScoreBoard
I. Fetch Fetch 单元是一个调度器，作用
 根据 PC 的值，从 I-Cache 中取指令，即发送内存请求。 Check 是否有 warp 已经完成执行，以更新 I-Buffer 信息  对于一个 warp，如果在 I-Buffer 中没有任何 valid 指令 (valid bit 作用在 III.</description>
    </item>
    
    <item>
      <title>Ubuntu 20.04 下安装运行 GPGPU-Sim</title>
      <link>http://localhost:1313/posts/%E7%BC%96%E7%A8%8B_ubuntu-20.04-%E4%B8%8B%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C-gpgpu-sim/</link>
      <pubDate>Mon, 10 May 2021 15:17:51 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E7%BC%96%E7%A8%8B_ubuntu-20.04-%E4%B8%8B%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C-gpgpu-sim/</guid>
      <description>0. 前言 最近因为课程 Project 需要使用 GPGPU-Sim 复现一篇 paper，在之后的课题中可能也会用到这个模拟器。所以收集了相关资料以搭建 GPGPU-Sim 的环境并运行 Demo。GPGPU-Sim 的参考资料实在是不多，主要参考了官方文档、Github 中 README 文件，还有一些相关的 Blog。
本次只跑了一个非常简单的 Demo，关于 CUDA 实例可以参考 Textbook 《CUDA by Example》。里面提供了一些 CUDA 编程的源码介绍。有人在 Github 上提供了《CUDA by Example》的源代码。
不过自己搭建 GPGPU-Sim 的环境坑比较多，一定要注意 gcc/g++ 版本问题以及链接库。所以我个人还是建议如果不是长期使用，可以直接下载官方提供的 fully setup virtual machine 。在 http://gpgpu-sim.org/ 下载，然后导入 Virtual Box 使用。他们提供的虚拟机已经配置好了环境，可以直接使用 GPGPU-Sim 编译 .cu 文件然后在模拟器上运行。具体步骤可以参考 UCR 给的流程。
1. 介绍 GPGPU-sim能够在Linux系统下，提供对GPU的功能模拟和性能仿真，让你在没有装NVIDIA显卡的情况下可以编译并运行CUDA程序。当然它更重要的意义是，可以通过修改仿真参数，让开发者修改GPU内部架构，并进行性能仿真，以针对自己的项目需求进行更好的代码设计，获得更好的性能表现。
我使用的环境是
 Ubuntu 20.04 CUDA Toolkit 11.1 gcc/g++ 5 ⚠️ 注意：在 Build GPGPU-Sim 之前最好就确保使用 gcc/g++ 5 版本 当时 GPGPU-Sim 作者测试时使用的是 CUDA 4.</description>
    </item>
    
  </channel>
</rss>