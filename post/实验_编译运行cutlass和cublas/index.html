<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>编译运行 CUTLASS 和 cuBLAS - Cory Code</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="Cory"><meta name=description content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。 包括根据官方文档运行 cuBLAS 的实例，过程"><meta name=keywords content="Hugo,theme,jane"><meta name=generator content="Hugo 0.107.0"><link rel=canonical href=https://huweim.github.io/post/%E5%AE%9E%E9%AA%8C_%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Ccutlass%E5%92%8Ccublas/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="编译运行 CUTLASS 和 cuBLAS"><meta property="og:description" content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。 包括根据官方文档运行 cuBLAS 的实例，过程"><meta property="og:type" content="article"><meta property="og:url" content="https://huweim.github.io/post/%E5%AE%9E%E9%AA%8C_%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Ccutlass%E5%92%8Ccublas/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-05-09T22:17:43+08:00"><meta property="article:modified_time" content="2022-11-26T16:23:21+08:00"><meta itemprop=name content="编译运行 CUTLASS 和 cuBLAS"><meta itemprop=description content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。 包括根据官方文档运行 cuBLAS 的实例，过程"><meta itemprop=datePublished content="2022-05-09T22:17:43+08:00"><meta itemprop=dateModified content="2022-11-26T16:23:21+08:00"><meta itemprop=wordCount content="3223"><meta itemprop=keywords content="CUTLASS,CUDA,"><meta name=twitter:card content="summary"><meta name=twitter:title content="编译运行 CUTLASS 和 cuBLAS"><meta name=twitter:description content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。 包括根据官方文档运行 cuBLAS 的实例，过程"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Cory Code</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>Cory Code</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>编译运行 CUTLASS 和 cuBLAS</h1><div class=post-meta><time datetime=2022-05-09 class=post-time>2022-05-09</time><div class=post-category><a href=https://huweim.github.io/categories/%E5%AE%9E%E9%AA%8C/>实验</a></div><span class=more-meta>3223 words</span>
<span class=more-meta>7 min read</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Table of Contents</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#11-prerequisites>1.1 Prerequisites</a><ul><li><a href=#111-cmake>1.1.1 cmake</a></li><li><a href=#112-gcc>1.1.2 gcc</a></li></ul></li><li><a href=#12-build>1.2 Build</a><ul><li><a href=#121-cmake-在做什么>1.2.1 cmake 在做什么</a></li><li><a href=#122-make-在做什么>1.2.2 make 在做什么</a></li><li><a href=#123-test-in-real-gpu>1.2.3 Test in real GPU</a></li></ul></li><li><a href=#13-build-and-run-the-cutlass-profiler>1.3 Build and run the CUTLASS Profiler</a></li><li><a href=#14-build-and-run-cutlass-unit-tests>1.4 Build and run CUTLASS Unit Tests</a><ul><li><a href=#141-workspace>1.4.1 Workspace</a></li><li><a href=#142-工作站>1.4.2 工作站</a></li></ul></li><li><a href=#15-profiler-和-test-unit-的执行有什么区别>1.5 Profiler 和 Test Unit 的执行有什么区别？</a></li><li><a href=#16-gemm-运行参数>1.6 gemm 运行参数</a></li></ul><ul><li><a href=#21-cmake-编译流程>2.1 cmake 编译流程</a></li></ul><ul><li><a href=#32-functionality>3.2 Functionality</a><ul><li><a href=#322-device-level-implicit-gemm-convolution>3.2.2 Device-level Implicit GEMM convolution</a></li><li><a href=#323-warp-level-matrix-multiply-with-tensor-cores>3.2.3 Warp-level Matrix Multiply with Tensor Cores</a></li><li><a href=#324-warp-level-matrix-multiply-with-cuda-wmma-api>3.2.4 Warp-level Matrix Multiply with CUDA WMMA API</a></li></ul></li><li><a href=#33-efficient-gemm-in-cuda>3.3 Efficient GEMM in CUDA</a><ul><li><a href=#331-threadblock-level-gemm>3.3.1 Threadblock-level GEMM</a></li><li><a href=#332-warp-level-gemm>3.3.2 Warp-level GEMM</a></li><li><a href=#333-thread-level-gemm>3.3.3 Thread-level GEMM</a></li></ul></li><li><a href=#34-terminology>3.4 Terminology</a></li><li><a href=#35-cutlass-profiler->3.5 CUTLASS Profiler ⭐</a><ul><li><a href=#351-gemm>3.5.1 GEMM</a></li><li><a href=#352-conv>3.5.2 Conv</a></li></ul></li><li><a href=#36-gemm-api-components>3.6 GEMM API Components</a><ul><li><a href=#361-device-wide-gemm-api>3.6.1 Device-wide GEMM API</a></li></ul></li></ul><ul><li><a href=#41-cutlass-sim>4.1 cutlass-sim</a></li><li><a href=#42-step>4.2 Step</a></li></ul><ul><li><a href=#11-如何确定调用了-tensor-core>1.1 如何确定调用了 tensor core?</a></li></ul><ul><li><a href=#21-using-the-cublas-api>2.1 Using the cuBLAS API</a></li><li><a href=#211-general-description>2.1.1 General Description</a></li><li><a href=#212-cublas-datatypes-reference>2.1.2 cuBLAS Datatypes Reference</a><ul><li><a href=#213-cublas-level---3-function-reference>2.1.3 cuBLAS Level - 3 Function Reference</a></li><li><a href=#214-blas-like-extension>2.1.4 BLAS-like Extension</a></li></ul></li><li><a href=#22-using-the-cublaslt-api>2.2 Using the cuBLASLt API</a><ul><li><a href=#221-cublaslt-datatypes-reference>2.2.1 cuBLASLt Datatypes Reference</a></li></ul></li><li><a href=#23-using-the-cublasxt-api>2.3 Using the cuBLASXt API</a></li></ul></nav></div></div><div class=post-content><h1 id=0-前言>0. 前言</h1><p>内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。</p><p>包括根据官方文档运行 cuBLAS 的实例，过程中遇到的问题。</p><h1 id=1-环境>1. 环境</h1><h2 id=11-prerequisites>1.1 Prerequisites</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ git clone https://github.com/NVIDIA/cutlass
</span></span></code></pre></div><p>CUTLASS requires:</p><ul><li>NVIDIA CUDA Toolkit (9.2 or later required, 11.1 recommended)</li><li>CMake 3.12+</li><li>host compiler supporting C++11 or greater (g++ 7.3.0 or Microsoft Visual Studio 2015 recommended)</li><li>Python 3.6+</li></ul><p>CUTLASS may be optionally compiled and linked with</p><ul><li>cuBLAS</li><li>cuDNN v7.6 or later</li></ul><h3 id=111-cmake>1.1.1 cmake</h3><p>官方给出了建议的环境，cmake 没有安装，apt-get install 安装的是 3.12 版本，不符合要求。手动安装一下 3.20 cmake，<a href=https://gist.github.com/bmegli/4049b7394f9cfa016c24ed67e5041930>教程</a></p><p>注意有个 BUG，<code> Could NOT find OpenSSL,</code>，<code>apt-get install libssl-dev</code> 即可</p><h3 id=112-gcc>1.1.2 gcc</h3><h2 id=12-build>1.2 Build</h2><p>之后就可以 build 了。这里用 Turing 架构</p><p>Construct a build directory and run CMake.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ export CUDACXX<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CUDA_INSTALL_PATH<span style=color:#e6db74>}</span>/bin/nvcc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ mkdir build <span style=color:#f92672>&amp;&amp;</span> cd build
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span>  <span style=color:#75715e># compiles for NVIDIA Turing GPU architecture</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 在 ~/cutlass/build/tools/library/generated/ 目录下生成 conv2d and gemm 的所有抽象组合</span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>all 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 仅需要 subset of gemm kernels with FP32 accumulation and FP16 input, in Ampere and Turing</span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;75;80&#39;</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_s*gemm_f16_*_nt_align8
</span></span><span style=display:flex><span><span style=color:#75715e># 我想这个 * 应该表示正则表达式</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ make cutlass_profiler -j16
</span></span></code></pre></div><p><strong>需求</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_i88*gemm_s*_256x128_*x2_tn_align*
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_i8832gemm_s4_256x128_128x2_tn_align32
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ make cutlass_profiler -j16
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ nsys profile --stats<span style=color:#f92672>=</span>true ./turing_tensorop_gemm
</span></span></code></pre></div><h3 id=121-cmake-在做什么>1.2.1 cmake 在做什么</h3><p><code>cmake .. -DCUTLASS_NVCC_ARCHS=75 -DCUTLASS_LIBRARY_KERNELS=all </code>，在 <code>~/cutlass/build/tools/library/generated/</code> 目录下生成相应的 .cu 接口</p><h3 id=122-make-在做什么>1.2.2 make 在做什么</h3><p><code>Building CUDA object tools/library/CMakeFiles/cutlass_library_objs.dir/generated/gemm/cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16.cu.o</code></p><p>猜测是根据 cmake 中生成的接口文件，生成 <code>cutlass_profiler</code> 能够运行/调用的目标文件。</p><p><code>make cutlass_profiler -j16</code> 这一步之后才能使用 <code>./tools/profiler/cutlass_profiler --kernels=cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16</code> 来运行。</p><h3 id=123-test-in-real-gpu>1.2.3 Test in real GPU</h3><p>工作站 GPU 是 GTX980，SM_50</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_simt_sgemm_128x128_8x2_nn_align1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ make cutlass_profiler -j16
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>cutlass_simt_sgemm_128x128_8x2_nn_align1
</span></span></code></pre></div><h2 id=13-build-and-run-the-cutlass-profiler>1.3 Build and run the CUTLASS Profiler</h2><p>From the <code>build/</code> directory created above, compile the the CUTLASS Profiler. 主要是 build <code>build/tool/profiler</code> 目录。 ✔️</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ make cutlass_profiler -j12
</span></span></code></pre></div><p>Then execute the CUTLASS Profiler computing GEMM, execute the following command. ❌</p><p>这一步果然不行，cudaGetDeviceProperties() failed for given device，找不到 device</p><p>2022-05-08 14:41:46，✔️，在工作站上就可以用 gpgpu-sim 运行，很奇怪，明明都是同一个 Docker 环境，只是自己电脑没有 GPU 而已</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>sgemm --m<span style=color:#f92672>=</span><span style=color:#ae81ff>4352</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span>4096
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>=============================</span>
</span></span><span style=display:flex><span>  Problem ID: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Provider: CUTLASS
</span></span><span style=display:flex><span>   Operation: cutlass_simt_sgemm_128x128_nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> Disposition: Passed
</span></span><span style=display:flex><span>      Status: Success
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>   Arguments:  --m<span style=color:#f92672>=</span><span style=color:#ae81ff>4352</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --A<span style=color:#f92672>=</span>f32:column --B<span style=color:#f92672>=</span>f32:column --C<span style=color:#f92672>=</span>f32:column --alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --beta<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>  <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>               --split_k_slices<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --batch_count<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --op_class<span style=color:#f92672>=</span>simt --accum<span style=color:#f92672>=</span>f32 --cta_m<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span> --cta_n<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span> --cta_k<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>  <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>               --stages<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --warps_m<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --warps_n<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --warps_k<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --inst_m<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --inst_n<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --inst_k<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --min_cc<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>  <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>               --max_cc<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>       Bytes: <span style=color:#ae81ff>52428800</span>  bytes
</span></span><span style=display:flex><span>       FLOPs: <span style=color:#ae81ff>146064539648</span>  flops
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>     Runtime: 10.5424  ms
</span></span><span style=display:flex><span>      Memory: 4.63158 GiB/s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        Math: 13854.9 GFLOP/s
</span></span></code></pre></div><h2 id=14-build-and-run-cutlass-unit-tests>1.4 Build and run CUTLASS Unit Tests</h2><h3 id=141-workspace>1.4.1 Workspace</h3><p>From the <code>build/</code> directory created above, simply build the target <code>test_unit</code> to compile and run all unit tests. ❌</p><p>这一步失败，看起来是 gcc 版本的问题。换了 gcc 版本，还是直接崩掉。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ make test_unit -j
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>----------<span style=color:#f92672>]</span> Global test environment tear-down
</span></span><span style=display:flex><span><span style=color:#f92672>[==========]</span> <span style=color:#ae81ff>946</span> tests from <span style=color:#ae81ff>57</span> test cases ran. <span style=color:#f92672>(</span><span style=color:#ae81ff>10812</span> ms total<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>  PASSED  <span style=color:#f92672>]</span> <span style=color:#ae81ff>946</span> tests.
</span></span><span style=display:flex><span>$
</span></span></code></pre></div><p>指定一个 unit，会 building 目录 <code>test/unit/gemm/warp/CMakeFiles</code> 中的内容，仍然是找不到 GPU Device ID</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ make test_unit_gemm_warp -j
</span></span></code></pre></div><h3 id=142-工作站>1.4.2 工作站</h3><p><strong>工作站：</strong> 还是找不到 gpgpusim.config，这个应该找到对应的执行目录，把 config 文件复制过去即可。<code>cp ~/gpgpu-sim_distribution/configs/tested-cfgs/SM75_RTX2060/* ~/cutlass/build/test/unit/gemm/warp/CMakeFiles/test_unit_gemm_warp.dir/</code></p><p>2022-05-09 15:31:59，猜测是在 <code>/cutlass/build/test/unit/gemm/warp</code> 目录下执行，把 gpgpusim.config 文件复制过去。✔️</p><p>可以成功运行，新的问题是之前遇到的一个问题，wmma 指令的 align syntax 错误。</p><h2 id=15-profiler-和-test-unit-的执行有什么区别>1.5 Profiler 和 Test Unit 的执行有什么区别？</h2><h2 id=16-gemm-运行参数>1.6 gemm 运行参数</h2><p>cutlass_profiler 支持非常自由的运行参数，并且支持参数的批处理（用 , 间隔）。参数如下，f32 应该就是对应的 data type 设置。</p><p>2022-05-09 20:34:24 找到了官方的 <a href=https://github.com/NVIDIA/cutlass#documentation>Documentation</a>，可以看 Section 3 中的详细解释。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cutlass_profiler <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --operation<span style=color:#f92672>=</span>Gemm <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --m<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --n<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --k<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --A<span style=color:#f92672>=</span>f32:column <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --B<span style=color:#f92672>=</span>f32:column <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --C<span style=color:#f92672>=</span>f32:column <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --beta<span style=color:#f92672>=</span>0,1,2 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --profiling-iterations<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --providers<span style=color:#f92672>=</span>cutlass <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --output<span style=color:#f92672>=</span>functional-test.csv
</span></span></code></pre></div><p>尝试修改 data type，是否有 i8? 这个语句执行结束后生成了一堆 .csv 文件，包括 conv2d, conv3d, gemm, rank_k, rank_2k，难道是一次执行了这么多程序？而且没有成功跑起来 ❌</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>cutlass_tensorop_s*gemm_f16_*_nt_align8 --m<span style=color:#f92672>=</span><span style=color:#ae81ff>3456</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --A<span style=color:#f92672>=</span>i8:column --B<span style=color:#f92672>=</span>i8:column --C<span style=color:#f92672>=</span>i8:column --output<span style=color:#f92672>=</span>test.csv &gt; ~/output/tensor_op3.log.lrr &amp;
</span></span></code></pre></div><p>去掉 output 选项，data type 改成 f32</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>cutlass_tensorop_s*gemm_f16_*_nt_align8 --m<span style=color:#f92672>=</span><span style=color:#ae81ff>3456</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --A<span style=color:#f92672>=</span>f32:column --B<span style=color:#f92672>=</span>f32:column --C<span style=color:#f92672>=</span>f32:column &gt; ~/output/tensor_op3.log.lrr &amp;
</span></span></code></pre></div><h1 id=2-examples>2. examples</h1><p>使用官方 README.md 编译会因为没有 Device 而失败，那么换一个思路，尝试利用 cmake 编译运行 examples 中提供的文件。</p><h2 id=21-cmake-编译流程>2.1 cmake 编译流程</h2><ul><li>编写CMakeLists.txt</li><li>通过cmake生成Makefile</li><li>make编译</li></ul><p>cuTLASS 在 <code>example</code> 目录下提供了 CMakeLists.txt。用法</p><ul><li>进入 example 目录，新建 build 文件夹；<code>$ mkdir build; cd build</code></li><li><code>cmake ../</code>; cmake会在找到上级目录找到CMakeLists.txt，生成makefile和一些其它文件</li><li>在makefile所在目录，调用make命令，会根据makefile对程序进行编译生成。</li></ul><h1 id=3-documentation>3. Documentation</h1><h2 id=32-functionality>3.2 Functionality</h2><p>这个部分介绍了 opcode class, *<strong>data type</strong>, layout. data type 正是我们所需要的。</p><p>opcode class, including Simt, TensorOp, SpTensorOp</p><h3 id=322-device-level-implicit-gemm-convolution>3.2.2 Device-level Implicit GEMM convolution</h3><p>列出了 Device-level Implicit GEMM convolution 的 opcode class, data type, layout</p><h3 id=323-warp-level-matrix-multiply-with-tensor-cores>3.2.3 Warp-level Matrix Multiply with Tensor Cores</h3><p>TensorOp 16-by-8-by-64. 支持 int4b_t，</p><h3 id=324-warp-level-matrix-multiply-with-cuda-wmma-api>3.2.4 Warp-level Matrix Multiply with CUDA WMMA API</h3><p>WmmaTensorOp,</p><p>Instruction Shape ( 16-by-16-by-16, 8-by-32-by-16)</p><p>Warp Shapes (32x32x16, 32x64x16, 64x32x16; 32x32x16, 32x64x16, 64x32x16)</p><h2 id=33-efficient-gemm-in-cuda>3.3 Efficient GEMM in CUDA</h2><h3 id=331-threadblock-level-gemm>3.3.1 Threadblock-level GEMM</h3><p>Each threadblock computes its portion of the output GEMM by iteratively loading tiles of input matrices and computing an accumulated matrix product.</p><h3 id=332-warp-level-gemm>3.3.2 Warp-level GEMM</h3><p>Multiple warps within a threadblock fetch data from shared memory into registers and perform computations. Warp-level GEMMs may be implemented either by TensorCores issuing mma.sync or wmma instructions or by thread-level matrix computations issued to CUDA cores. For maximum performance, access to shared memory should be bank conflict free. To maximize data reuse within the warp, a large warp-level GEMM tile should be chosen.</p><p>使用到了 wmma 指令，shared memory。</p><h3 id=333-thread-level-gemm>3.3.3 Thread-level GEMM</h3><p>SGEMM, IGEMM, HGEMM, and DGEMM are computed by SIMT math instructions issued by thread-level matrix multiply procedures.</p><p>所以现在跑的是 thread-level GEMM</p><h2 id=34-terminology>3.4 Terminology</h2><p>Layout: functor mapping logical coordinates of a tensor to linear offset (as LongIndex); owns stride vectors, if any.</p><p>Operator: an object performing a computation on matrix or tensor objects. May be further refined by scope within the execution model hierarchy.</p><p>Tile: partitions of a tensor that have constant extents and layout known at compile time</p><h2 id=35-cutlass-profiler->3.5 CUTLASS Profiler ⭐</h2><p>The CUTLASS Profiler is a command-line driven test and profiling environment for CUTLASS computations defined in the CUTLASS Instance Library. The CUTLASS Profiler is capable of executing each GEMM, Sparse Gemm, Conv2d, and Conv3d kernel.</p><p><code>cutlass_profiler</code> 就是一个封装好的脚本，运行各类程序</p><p>进入到目录 <code>build/tools/profiler</code>，运行 <code>cutlass_profiler --help</code> 可以查看一些有用的信息，直接 <code>cutlass_profiler --help</code> 找不到 cutlass_profiler；用 <code>./cutlass_profiler --help</code> 就开始跑程序了，有点不知道怎么用这个 &ndash;help。</p><p>2022-05-09 20:22:30，还是用 <code>./cutlass_profiler --help</code> 就可以跑，不过神奇的是这是用 gpgpu-sim 跑得，最后会把需要的信息 print 在屏幕上。</p><h3 id=351-gemm>3.5.1 GEMM</h3><p>The CUTLASS Profiler is capable of executing GEMM and Sparse GEMM problems.</p><h4 id=3511-gemm-arguments->3.5.1.1 GEMM Arguments ⭐</h4><p>The complete set of arguments available to each operation may be viewed by specifying the operation name in addition to &ndash;help. The argument flags and their aliases usable for GEMM appear as follows.</p><p>可以通过 option <code>--help</code> 查看完整的 operation，他这里给出的例子是 <code>./tools/profiler/cutlass_profiler --operation=gemm --help</code>，所以还是得执行这个脚本吧。</p><p>To execute kernels targeting Tensor Core operations, supply the flag <code>--op_class=tensorop</code> in the command line.</p><p>实际上，op_class 也就是选择 TensorOp or SIMT</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --op_class<span style=color:#f92672>=</span>tensorop --m<span style=color:#f92672>=</span><span style=color:#ae81ff>3456</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span>
</span></span></code></pre></div><h4 id=3513-自己运行>3.5.1.3 自己运行</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>./tools/profiler/cutlass_profiler --operation<span style=color:#f92672>=</span>Gemm --op_class<span style=color:#f92672>=</span>tensorop --m<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span> --inst_m<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span> --inst_n<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span> --inst_k<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>
</span></span></code></pre></div><p><strong>如何使用 4-bit 进行计算</strong>: 对于 TensorOp, Instruction Shape 8-by-8-by-32 对应的是 A-int4b_t, B-int4b_t, C-int32_t，通过参数 <code>--inst_m</code>, <code>--inst_n</code>, <code>inst_k</code> 来决定</p><h3 id=352-conv>3.5.2 Conv</h3><p>和 gemm 也是类似的，重点还是搞懂他们的参数。</p><h2 id=36-gemm-api-components>3.6 GEMM API Components</h2><p>This document focuses on device-level, threadblock-level GEMMs, warp-level GEMMs, thread-level GEMMs, and instruction-level GEMMs.</p><h3 id=361-device-wide-gemm-api>3.6.1 Device-wide GEMM API</h3><p>The device-wide GEMM API is embodied by the following operators</p><ul><li>cutlass::gemm::device::Gemm - basic GEMM operation</li><li>cutlass::gemm::device::GemmArray - batched GEMM operation in which input matrices are read from arrays of pointers</li><li>cutlass::gemm::device::GemmBatched - batched GEMM operation in which input matrices are separated by a constant stride</li><li>cutlass::gemm::device::GemmSplitKParallel - GEMM operation that partitions the GEMM K dimension then launches a separate reduction kernel</li></ul><p>都在 <code>cutlass/include/cutlass/gemm/device/</code> 目录下，basic GEMM 对应 <code>gemm.h</code> 文件</p><h1 id=4-在-gpgpu-sim-上运行>4. 在 GPGPU-Sim 上运行</h1><h2 id=41-cutlass-sim>4.1 cutlass-sim</h2><p>尝试了 Admodt 提供的 <code>https://github.com/gpgpu-sim/cutlass-gpgpu-sim</code>，仍然是 syntax error，估计是新版本编译的 PTX 有问题。2022-05-26 15:53:30，确实如此。</p><p>不同 CUDA 版本对应不同的 PTX .version，得到的 PTX 指令是不一样的。这就是为什么 CUDA 11.4 wmma 指令会报错。</p><h2 id=42-step>4.2 Step</h2><ul><li>下载并安装 CUDA Toolkit 9.2，使用这个版本编译模拟器。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell></code></pre></div><hr><p>接下来是编译运行 cuBLAS 的过程</p><h1 id=1-nvidia-samples>1. NVIDIA Samples</h1><p><a href=https://github.com/NVIDIA/cuda-samples/>https://github.com/NVIDIA/cuda-samples/</a> 在 library 目录中有提供调用 cublas 的代码，果然官方提供的资源才是最好的。git clone 下来就可以在 A10 上编译运行。重点是理解不同 API 的含义，需要的 parameter，gemm 的 data type, shape 等等，这一点需要多看文档。</p><h2 id=11-如何确定调用了-tensor-core>1.1 如何确定调用了 tensor core?</h2><blockquote><p>Tensor cores were first introduced with Volta GPUs (compute capability>=sm_70) and significantly accelerate matrix multiplications. Starting with cuBLAS version 11.0.0, the library will automatically make use of Tensor Core capabilities wherever possible, unless they are explicitly disabled by selecting pedantic compute modes in cuBLAS (see cublasSetMathMode(), cublasMath_t).</p></blockquote><p>文档中说 cublas 会自动调用 tensor core</p><h1 id=2-documentation>2. Documentation</h1><h2 id=21-using-the-cublas-api>2.1 Using the cuBLAS API</h2><blockquote><p>cuBLAS库提供了现成的矩阵乘法算子，例如<code>cublasGemmEx</code>和<code>cublasLtMatmul</code>。其中后者是轻量级版本，API调用更灵活。</p></blockquote><p>cublasGemmEx</p><h2 id=211-general-description>2.1.1 General Description</h2><blockquote><p>应该注意的是，该库将选择启用 Tensor Core 的实现，只要它确定它将提供最佳性能。</p></blockquote><p>cuBLAS 11.0.0 之后支持任何 size 的矩阵，只是对齐的 size 能够更好地发挥 Tensor core 的性能。</p><h2 id=212-cublas-datatypes-reference>2.1.2 cuBLAS Datatypes Reference</h2><p><code>cublasDataType_t handle</code>，一个有关cuBLAS库的上下文的句柄，之后需要传递给API函数，即计算乘法的函数</p><p><code>cublasOperation_t</code>, N, 非转置；T，转置；C，共轭转置。</p><p><code>cublasGemmEx</code> 中的 <code>cublasGemmAlgo_t</code>，<code>cublasGemmAlgo_t</code> 最高支持 sm_75，sm_80 已经不支持了，所以在 sm_80 中指定了也是无效的，在 sm_80 中所有枚举都等同于 <code>CUBLAS_GEMM_DEFAULT</code> 或者 <code>CUBLAS_GEMM_DEFAULT_TENSOR_OP</code>。在更新的架构中也会 deprecated</p><p><code>cudaDataType_t</code>, 直接作为 <code>cublasGemmEx</code> 的参数，支持 int8 到 double 类型。</p><h3 id=213-cublas-level---3-function-reference>2.1.3 cuBLAS Level - 3 Function Reference</h3><p><code>cublasSgemm</code>, <code>cublasDgemm</code>, <code>cublasCgemm</code>, <code>cublasZgemm</code>, <code>cublasHgemm</code> 应该是比较初始的 API。</p><h3 id=214-blas-like-extension>2.1.4 BLAS-like Extension</h3><blockquote><p><code>cublasGemmEx()</code>. This function is an extension of cublasgemm that allows the user to individually specify the data types for each of the A, B and C matrices, the precision of computation and the GEMM algorithm to be run. Supported combinations of arguments are listed further down in this section.</p></blockquote><p>自定义 data types，自己在 int8 中就用的这个 API，支持 sm_50 以上的架构。</p><h2 id=22-using-the-cublaslt-api>2.2 Using the cuBLASLt API</h2><p>cuBLASLt, a lightweight library dedicated to GEMM</p><blockquote><p>The cuBLASLt in general does not guarantee to support all possible sizes and configurations.</p></blockquote><p>不一定支持任何 size</p><h3 id=221-cublaslt-datatypes-reference>2.2.1 cuBLASLt Datatypes Reference</h3><p><code>cublasLtMatmulTile_t</code> 提供多种 tile size</p><h2 id=23-using-the-cublasxt-api>2.3 Using the cuBLASXt API</h2><p>The cuBLASXt API of cuBLAS exposes a multi-GPU capable Host interface</p><p>cuBLASXT 似乎可以调用多个 GPU，比如有 4 A10 in QZ Server，code 限制只用两个 GPU。通过 cuBLASXT 执行 FP32 gemm，TFLOPS 应该不具备参考性了。</p><p>参考：https://github.com/sxzhang1993/Run-cutlass-with-gpgpu-sim</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Cory</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2022-11-26</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=https://huweim.github.io/tags/cutlass/>CUTLASS</a>
<a href=https://huweim.github.io/tags/cuda/>CUDA</a></div><nav class=post-nav><a class=prev href=/post/blog_hugo_%E8%AE%A9%E4%BD%A0%E7%9A%84%E5%8D%9A%E5%AE%A2%E8%A2%ABgoogle%E6%94%B6%E5%BD%95/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">Hugo_让你的博客被Google收录</span>
<span class="prev-text nav-mobile">Prev</span></a>
<a class=next href=/post/%E6%80%BB%E7%BB%93_deep_work/><span class="next-text nav-default">关于 Deep Work</span>
<span class="prev-text nav-mobile">Next</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:huwm1@shanghaitech.edu.cn rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg></a><a href=http://localhost:1313 rel="me noopener" class=iconfont title=linkedin target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="33" height="33"><path d="M872.405333 872.618667H720.768V635.008c0-56.661333-1.152-129.578667-79.018667-129.578667-79.061333.0-91.136 61.653333-91.136 125.397334v241.792H398.976V384H544.64v66.602667h1.962667c20.352-38.4 69.845333-78.933333 143.786666-78.933334 153.642667.0 182.058667 101.12 182.058667 232.746667v268.202667zM227.712 317.141333a87.978667 87.978667.0 01-88.021333-88.106666A88.064 88.064.0 11227.712 317.141333zm76.032 555.477334H151.68V384h152.064v488.618667zM948.266667.0h-872.704C33.792.0.0 33.024.0 73.770667v876.458666C0 991.018667 33.792 1024 75.562667 1024h872.576C989.866667 1024 1024 991.018667 1024 950.229333V73.770667C1024 33.024 989.866667.0 948.138667.0h.128z"/></svg></a><a href=https://github.com/huweim rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://www.zhihu.com/people/hu-wei-ming-31-86 rel="me noopener" class=iconfont title=zhihu target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M351.791182 562.469462h192.945407c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262h159.282726s-.86367-67.402109-18.578124-67.402109-279.979646.0-279.979646.0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461s24.62791 5.832845 36.941354.0c12.313443-5.832845 68.050885-25.924439 84.252893-103.69571h86.570681c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262H109.86113c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449H279.868105c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513.0.0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-.055259.185218 167.855986 193.263655s22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-.045025.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"/><path d="M584.918753 182.033893v668.840094h70.318532l28.807093 80.512708 121.875768-80.512708h153.600307L959.520453 182.033893h-374.6017zM887.150192 778.934538h-79.837326l-99.578949 65.782216-23.537066-65.782216h-24.855084L659.341766 256.673847h227.807403V778.934538z"/></svg></a><a href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2020 -
2022
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>Cory</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>