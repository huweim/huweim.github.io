<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage data-theme=light><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>编译运行 CUTLASS 和 cuBLAS - Weiming Hu
</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=color-scheme content="light dark"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=generator content="Hugo 0.140.2"><link rel=canonical href=https://huweim.github.io/post/%E5%AE%9E%E9%AA%8C_%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Ccutlass%E5%92%8Ccublas/><meta name=author content="Cory"><meta name=description content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。
包括根据官方文档运行 cuBLAS 的实例，过程中遇到的问题。
"><meta name=keywords content="CUTLASS,CUDA"><meta property="og:url" content="https://huweim.github.io/post/%E5%AE%9E%E9%AA%8C_%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Ccutlass%E5%92%8Ccublas/"><meta property="og:site_name" content="Weiming Hu"><meta property="og:title" content="编译运行 CUTLASS 和 cuBLAS"><meta property="og:description" content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。
包括根据官方文档运行 cuBLAS 的实例，过程中遇到的问题。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-05-09T22:17:43+08:00"><meta property="article:modified_time" content="2024-03-26T22:42:21+08:00"><meta property="article:tag" content="CUTLASS"><meta property="article:tag" content="CUDA"><meta itemprop=name content="编译运行 CUTLASS 和 cuBLAS"><meta itemprop=description content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。
包括根据官方文档运行 cuBLAS 的实例，过程中遇到的问题。"><meta itemprop=datePublished content="2022-05-09T22:17:43+08:00"><meta itemprop=dateModified content="2024-03-26T22:42:21+08:00"><meta itemprop=wordCount content="4549"><meta itemprop=keywords content="CUTLASS,CUDA"><meta name=twitter:card content="summary"><meta name=twitter:title content="编译运行 CUTLASS 和 cuBLAS"><meta name=twitter:description content="0. 前言 内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。
包括根据官方文档运行 cuBLAS 的实例，过程中遇到的问题。"><link rel=icon href=/favicon.ico><link rel=stylesheet href=/css/style.min.1acfe3c0bf85aa6c451ba764236bb3ab12c22cd38eee8ecc8fac33defcc7156d.css integrity="sha256-Gs/jwL+FqmxFG6dkI2uzqxLCLNOO7o7Mj6wz3vzHFW0=" media=screen crossorigin=anonymous><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--><script>(function(){var e=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",e)})()</script></head><body><div id=back-to-top></div><header class=site-header><div class=desktop-header><div class=desktop-header-logo><a href=/ class=logo>Weiming Hu</a></div><nav class=desktop-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li><li class=menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg><svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div><div class=mobile-header><div id=mobile-navbar class=mobile-navbar><div id=mobile-navbar-icon class=mobile-navbar-icon><svg aria-hidden="true" class="lucide lucide-menu hi-svg-inline icon--menu" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><line x1="4" x2="20" y1="12" y2="12"/><line x1="4" x2="20" y1="6" y2="6"/><line x1="4" x2="20" y1="18" y2="18"/></svg></div><div class=mobile-navbar-logo><a href=/ class=logo>Weiming Hu</a></div></div><div id=mobile-menu-close-modal class=mobile-menu-close-modal></div><nav id=mobile-menu class=mobile-menu><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li><li class=mobile-menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg><svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div></header><main id=main class="main pico container"><div class=content-wrapper><aside class=sidebar></aside><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>编译运行 CUTLASS 和 cuBLAS</h1><div class=post-meta-list><div class="post-meta-item post-meta-author"><svg aria-hidden="true" class="lucide lucide-user-round-pen hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M2 21a8 8 0 0110.821-7.487"/><path d="M21.378 16.626a1 1 0 00-3.004-3.004l-4.01 4.012a2 2 0 00-.506.854l-.837 2.87a.5.5.0 00.62.62l2.87-.837a2 2 0 00.854-.506z"/><circle cx="10" cy="8" r="5"/></svg>
Cory</div><div class="post-meta-item post-meta-time"><svg aria-hidden="true" class="lucide lucide-calendar-days hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M8 2v4"/><path d="M16 2v4"/><rect width="18" height="18" x="3" y="4" rx="2"/><path d="M3 10h18"/><path d="M8 14h.01"/><path d="M12 14h.01"/><path d="M16 14h.01"/><path d="M8 18h.01"/><path d="M12 18h.01"/><path d="M16 18h.01"/></svg>
<time datetime=2022-05-09>2022-05-09
</time><span class="post-meta-item post-meta-lastmod">(LastMod:
2024-03-26)</span></div><div class=post-meta__right><span class=post-meta-more>4549 words -
10 min read</span><div class="post-meta-item post-meta-category"><a href=https://huweim.github.io/categories/%E7%BC%96%E7%A8%8B/>编程</a></div></div></div></header><div class=post-content><h1 id=0-前言>0. 前言</h1><p>内容包括根据官方文档运行 CUTLASS 的实例，过程中遇到的一些问题，在 GPGPU-Sim 上运行 CUTLASS，阅读官方 doc 的笔记。</p><p>包括根据官方文档运行 cuBLAS 的实例，过程中遇到的问题。</p><h1 id=1-环境>1. 环境</h1><h2 id=10-project-的目录结构>1.0 project 的目录结构</h2><p>为什么会有这么多 .cmake 文件？应该是提供了其他功能的模板</p><ul><li>For a project with cmake, why there is a CMakeFiles dir in build dir, and there is &ldquo;Makefile2&rdquo; in CMakeFiles dir<ul><li>The <code>CMakeFiles</code> directory is generated during the CMake build process and contains all the necessary <strong>intermediate files</strong> used to build the project.</li><li><code>Makefile2</code> 文件不是用来由用户直接修改的，而是由CMake生成，并由make根据CMakeLists.txt文件中指定的指示来构建项目。</li></ul></li></ul><h2 id=11-prerequisites>1.1 Prerequisites</h2><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ git clone https://github.com/NVIDIA/cutlass</span></span></code></pre></div></div><p>CUTLASS requires:</p><ul><li>NVIDIA CUDA Toolkit (9.2 or later required, 11.1 recommended)</li><li>CMake 3.12+</li><li>host compiler supporting C++11 or greater (g++ 7.3.0 or Microsoft Visual Studio 2015 recommended)</li><li>Python 3.6+</li></ul><p>CUTLASS may be optionally compiled and linked with</p><ul><li>cuBLAS</li><li>cuDNN v7.6 or later</li></ul><h3 id=111-cmake>1.1.1 cmake</h3><p>官方给出了建议的环境，cmake 没有安装，apt-get install 安装的是 3.12 版本，不符合要求。手动安装一下 3.20 cmake，<a href=https://gist.github.com/bmegli/4049b7394f9cfa016c24ed67e5041930>教程</a></p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#75715e># get and build CMake</span>
</span></span><span style=display:flex><span>wget https://github.com/Kitware/CMake/releases/download/v3.20.0/cmake-3.20.0.tar.gz
</span></span><span style=display:flex><span>tar -zvxf cmake-3.20.0.tar.gz
</span></span><span style=display:flex><span>cd cmake-3.20.0
</span></span><span style=display:flex><span>./bootstrap
</span></span><span style=display:flex><span>make -j8
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># add path</span>
</span></span><span style=display:flex><span>export PATH<span style=color:#f92672>=</span>$PATH:$CUDA_INSTALL_PATH/bin:~/cmake-3.20.0/bin</span></span></code></pre></div></div><p>注意有个 BUG，<code> Could NOT find OpenSSL,</code>，<code>apt-get install libssl-dev</code> 即可</p><h3 id=112-gcc>1.1.2 gcc</h3><h2 id=12-build>1.2 Build</h2><p>2023-03-16 15:31:43，编译的逻辑是吧多个 cutlass 算子都链接到 cutlass_profiler 文件中。</p><p>之后就可以 build 了。这里用 Turing 架构</p><p>Construct a build directory and run CMake.</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ export CUDACXX<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CUDA_INSTALL_PATH<span style=color:#e6db74>}</span>/bin/nvcc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ mkdir build <span style=color:#f92672>&amp;&amp;</span> cd build
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span>  <span style=color:#75715e># compiles for NVIDIA Turing GPU architecture</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 在 ~/cutlass/build/tools/library/generated/ 目录下生成 conv2d and gemm 的所有抽象组合</span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>all 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 仅需要 subset of gemm kernels with FP32 accumulation and FP16 input, in Ampere and Turing</span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;75;80&#39;</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_s*gemm_f16_*_nt_align8
</span></span><span style=display:flex><span><span style=color:#75715e># 我想这个 * 应该表示正则表达式</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ make cutlass_profiler -j16</span></span></code></pre></div></div><p><strong>需求</strong></p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_i88*gemm_s*_256x128_*x2_tn_align*
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_i8832gemm_s4_256x128_128x2_tn_align32
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>75</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ make cutlass_profiler -j16
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ nsys profile --stats<span style=color:#f92672>=</span>true ./turing_tensorop_gemm</span></span></code></pre></div></div><h3 id=121-cmake-在做什么>1.2.1 cmake 在做什么</h3><p><code>cmake .. -DCUTLASS_NVCC_ARCHS=75 -DCUTLASS_LIBRARY_KERNELS=all </code>，在 <code>~/cutlass/build/tools/library/generated/</code> 目录下生成相应的 .cu 接口</p><h3 id=122-make-在做什么>1.2.2 make 在做什么</h3><p><code>Building CUDA object tools/library/CMakeFiles/cutlass_library_objs.dir/generated/gemm/cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16.cu.o</code></p><p>猜测是根据 cmake 中生成的接口文件，生成 <code>cutlass_profiler</code> 能够运行/调用的目标文件。</p><blockquote><p>2023-03-23 14:19:09，以上的猜测基本没有问题。generated 目录下的 .cu 文件应该只是给出一个配置的实例，其对应的 kernel 已经全部编译到 <code>/tools/profiler/cutlass_profiler</code> 这个 bin 文件中。</p></blockquote><p><code>make cutlass_profiler -j16</code> 之后，使用 <code>./tools/profiler/cutlass_profiler --kernels=cutlass_tensorop_i8816gemm_s8_256x128_64x2_tn_align16</code> 来运行。</p><h3 id=123-test-in-real-gpu>1.2.3 Test in real GPU</h3><p>工作站 GPU 是 GTX980，SM_50</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cmake .. -DCUTLASS_NVCC_ARCHS<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span> -DCUTLASS_LIBRARY_KERNELS<span style=color:#f92672>=</span>cutlass_simt_sgemm_128x128_8x2_nn_align1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ make cutlass_profiler -j16
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>cutlass_simt_sgemm_128x128_8x2_nn_align1</span></span></code></pre></div></div><h2 id=13-build-and-run-the-cutlass-profiler>1.3 Build and run the CUTLASS Profiler</h2><blockquote><p>2023-03-23 14:22:54，要注意的是，实际上 1.2 描述的就是 build profiler 的过程</p></blockquote><p>From the <code>build/</code> directory created above, compile the the CUTLASS Profiler. 主要是 build <code>build/tool/profiler</code> 目录。 &#x2714;&#xfe0f;</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ make cutlass_profiler -j12</span></span></code></pre></div></div><p>Then execute the CUTLASS Profiler computing GEMM, execute the following command. &#x274c;</p><p>这一步果然不行，cudaGetDeviceProperties() failed for given device，找不到 device</p><p>2022-05-08 14:41:46，&#x2714;&#xfe0f;，在工作站上就可以用 gpgpu-sim 运行，很奇怪，明明都是同一个 Docker 环境，只是自己电脑没有 GPU 而已</p><p>运行给出的输出信息如下，给出了可以自己设置的 option，也给出了性能（GFLOPS）</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>sgemm --m<span style=color:#f92672>=</span><span style=color:#ae81ff>4352</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span>4096
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>=============================</span>
</span></span><span style=display:flex><span>  Problem ID: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Provider: CUTLASS
</span></span><span style=display:flex><span>   Operation: cutlass_simt_sgemm_128x128_nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> Disposition: Passed
</span></span><span style=display:flex><span>      Status: Success
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>   Arguments:  --m<span style=color:#f92672>=</span><span style=color:#ae81ff>4352</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --A<span style=color:#f92672>=</span>f32:column --B<span style=color:#f92672>=</span>f32:column --C<span style=color:#f92672>=</span>f32:column --alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --beta<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>  <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>               --split_k_slices<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --batch_count<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --op_class<span style=color:#f92672>=</span>simt --accum<span style=color:#f92672>=</span>f32 --cta_m<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span> --cta_n<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span> --cta_k<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>  <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>               --stages<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --warps_m<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --warps_n<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> --warps_k<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --inst_m<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --inst_n<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --inst_k<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --min_cc<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>  <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>               --max_cc<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>       Bytes: <span style=color:#ae81ff>52428800</span>  bytes
</span></span><span style=display:flex><span>       FLOPs: <span style=color:#ae81ff>146064539648</span>  flops
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>     Runtime: 10.5424  ms
</span></span><span style=display:flex><span>      Memory: 4.63158 GiB/s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        Math: 13854.9 GFLOP/s</span></span></code></pre></div></div><h2 id=14-build-and-run-cutlass-unit-tests>1.4 Build and run CUTLASS Unit Tests</h2><h3 id=141-自己的-workspace>1.4.1 自己的 Workspace</h3><p>From the <code>build/</code> directory created above, simply build the target <code>test_unit</code> to compile and run all unit tests. &#x274c;</p><p>这一步失败，看起来是 gcc 版本的问题。换了 gcc 版本，还是直接崩掉。</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ make test_unit -j
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>----------<span style=color:#f92672>]</span> Global test environment tear-down
</span></span><span style=display:flex><span><span style=color:#f92672>[==========]</span> <span style=color:#ae81ff>946</span> tests from <span style=color:#ae81ff>57</span> test cases ran. <span style=color:#f92672>(</span><span style=color:#ae81ff>10812</span> ms total<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>  PASSED  <span style=color:#f92672>]</span> <span style=color:#ae81ff>946</span> tests.
</span></span><span style=display:flex><span>$</span></span></code></pre></div></div><p>指定一个 unit，会 building 目录 <code>test/unit/gemm/warp/CMakeFiles</code> 中的内容，仍然是找不到 GPU Device ID</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ make test_unit_gemm_warp -j</span></span></code></pre></div></div><h3 id=142-工作站>1.4.2 工作站</h3><p><strong>工作站：</strong> 还是找不到 gpgpusim.config，这个应该找到对应的执行目录，把 config 文件复制过去即可。<code>cp ~/gpgpu-sim_distribution/configs/tested-cfgs/SM75_RTX2060/* ~/cutlass/build/test/unit/gemm/warp/CMakeFiles/test_unit_gemm_warp.dir/</code></p><p>2022-05-09 15:31:59，猜测是在 <code>/cutlass/build/test/unit/gemm/warp</code> 目录下执行，把 gpgpusim.config 文件复制过去。&#x2714;&#xfe0f;</p><p>可以成功运行，新的问题是之前遇到的一个问题，wmma 指令的 align syntax 错误。</p><h2 id=15-profiler-和-test-unit-的执行有什么区别>1.5 Profiler 和 Test Unit 的执行有什么区别？</h2><p>2023-03-23 14:25:03，结合文档的说明和个人的理解。单元测试就是测试功能正确性，保证矩阵的计算不出错，在单元测试情况下矩阵的 size，data type 可以多样一点。
性能测试的话自己手动设置的东西就比较多，粒度更细，同时会给出性能的报告。</p><h2 id=16-gemm-运行参数>1.6 gemm 运行参数</h2><p>cutlass_profiler 支持非常自由的运行参数，并且支持参数的批处理（用 , 间隔）。参数如下，f32 应该就是对应的 data type 设置。</p><p>2022-05-09 20:34:24 找到了官方的 <a href=https://github.com/NVIDIA/cutlass#documentation>Documentation</a>，可以看 Section 3 中的详细解释。</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cutlass_profiler <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --operation<span style=color:#f92672>=</span>Gemm <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --m<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --n<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --k<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --A<span style=color:#f92672>=</span>f32:column <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --B<span style=color:#f92672>=</span>f32:column <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --C<span style=color:#f92672>=</span>f32:column <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --beta<span style=color:#f92672>=</span>0,1,2 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --profiling-iterations<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --providers<span style=color:#f92672>=</span>cutlass <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --output<span style=color:#f92672>=</span>functional-test.csv</span></span></code></pre></div></div><p>尝试修改 data type，是否有 i8? 这个语句执行结束后生成了一堆 .csv 文件，包括 conv2d, conv3d, gemm, rank_k, rank_2k，难道是一次执行了这么多程序？而且没有成功跑起来 &#x274c;</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>cutlass_tensorop_s*gemm_f16_*_nt_align8 --m<span style=color:#f92672>=</span><span style=color:#ae81ff>3456</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --A<span style=color:#f92672>=</span>i8:column --B<span style=color:#f92672>=</span>i8:column --C<span style=color:#f92672>=</span>i8:column --output<span style=color:#f92672>=</span>test.csv &gt; ~/output/tensor_op3.log.lrr &amp;</span></span></code></pre></div></div><p>去掉 output 选项，data type 改成 f32</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --kernels<span style=color:#f92672>=</span>cutlass_tensorop_s*gemm_f16_*_nt_align8 --m<span style=color:#f92672>=</span><span style=color:#ae81ff>3456</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --A<span style=color:#f92672>=</span>f32:column --B<span style=color:#f92672>=</span>f32:column --C<span style=color:#f92672>=</span>f32:column &gt; ~/output/tensor_op3.log.lrr &amp;</span></span></code></pre></div></div><h1 id=2-cutlass-examples>2. cutlass examples</h1><p>使用官方 README.md 编译会因为没有 Device 而失败，那么换一个思路，尝试利用 cmake 编译运行 examples 中提供的文件。</p><blockquote><p>2023-03-23 14:27:07，在学习了 cmake 之后，可以查看 <code>build</code> 目录中生成的 <code>Makefile</code> 文件。Makefile 文件中提供了每个 example 的 target，可以编译生成对应的 bin 文件。</p></blockquote><h2 id=21-cmake-编译流程>2.1 cmake 编译流程</h2><ul><li>编写 CMakeLists.txt</li><li>通过 cmake 生成 Makefile</li><li>make 编译</li></ul><p>cuTLASS 在 <code>example</code> 目录下提供了 CMakeLists.txt。用法</p><ul><li>进入 example 目录，新建 build 文件夹；<code>$ mkdir build; cd build</code></li><li><code>cmake ../</code>; cmake会在找到上级目录找到 CMakeLists.txt，生成 makefile 和一些其它文件</li><li>在 makefile 所在目录，调用 make 命令，会根据 makefile 对程序进行编译生成。</li></ul><blockquote><p>2023-03-23 14:28:43，这里要注意并不是进入到每个目录去单独编译，而是 <code>build</code> 根目录下已经提供了这个接口和 target，每个 example 中的 Makefile 文件可能是更加具体的实现，但是在根目录下调用即可。</p></blockquote><h1 id=3-documentation>3. Documentation</h1><p>check 官方文档</p><h2 id=32-functionality>3.2 Functionality</h2><p>这个部分介绍了 opcode class, *<strong>data type</strong>, layout. data type 正是我们所需要的。</p><p>opcode class, including Simt, TensorOp, SpTensorOp</p><h3 id=322-device-level-implicit-gemm-convolution>3.2.2 Device-level Implicit GEMM convolution</h3><p>列出了 Device-level Implicit GEMM convolution 的 opcode class, data type, layout</p><h3 id=323-warp-level-matrix-multiply-with-tensor-cores>3.2.3 Warp-level Matrix Multiply with Tensor Cores</h3><p>TensorOp 16-by-8-by-64. 支持 int4b_t，</p><h3 id=324-warp-level-matrix-multiply-with-cuda-wmma-api>3.2.4 Warp-level Matrix Multiply with CUDA WMMA API</h3><p>WmmaTensorOp,</p><p>Instruction Shape ( 16-by-16-by-16, 8-by-32-by-16)</p><p>Warp Shapes (32x32x16, 32x64x16, 64x32x16; 32x32x16, 32x64x16, 64x32x16)</p><h2 id=33-efficient-gemm-in-cuda>3.3 Efficient GEMM in CUDA</h2><h3 id=331-threadblock-level-gemm>3.3.1 Threadblock-level GEMM</h3><p>Each threadblock computes its portion of the output GEMM by iteratively loading tiles of input matrices and computing an accumulated matrix product.</p><h3 id=332-warp-level-gemm>3.3.2 Warp-level GEMM</h3><p>Multiple warps within a threadblock fetch data from shared memory into registers and perform computations. Warp-level GEMMs may be implemented either by TensorCores issuing mma.sync or wmma instructions or by thread-level matrix computations issued to CUDA cores. For maximum performance, access to shared memory should be bank conflict free. To maximize data reuse within the warp, a large warp-level GEMM tile should be chosen.</p><p>使用到了 wmma 指令，shared memory。</p><h3 id=333-thread-level-gemm>3.3.3 Thread-level GEMM</h3><p>SGEMM, IGEMM, HGEMM, and DGEMM are computed by SIMT math instructions issued by thread-level matrix multiply procedures.</p><p>所以现在跑的是 thread-level GEMM</p><h2 id=34-terminology>3.4 Terminology</h2><p>Layout: functor mapping logical coordinates of a tensor to linear offset (as LongIndex); owns stride vectors, if any.</p><p>Operator: an object performing a computation on matrix or tensor objects. May be further refined by scope within the execution model hierarchy.</p><p>Tile: partitions of a tensor that have constant extents and layout known at compile time</p><h2 id=35-align-含义>3.5 align 含义</h2><p><code>cutlass_tensorop_f16_s884gemm_f16_64x64_32x2_tn_align8.cu</code></p><p>In the case of this Cutlass file, the &ldquo;align8&rdquo; suffix indicates that the matrix data is aligned to an 8-byte boundary. This can help improve performance when the matrix multiplication algorithm accesses the matrix data.</p><h2 id=35-cutlass-profiler-star>3.5 CUTLASS Profiler &#x2b50;</h2><p>The CUTLASS Profiler is a command-line driven test and profiling environment for CUTLASS computations defined in the CUTLASS Instance Library. The CUTLASS Profiler is capable of executing each GEMM, Sparse Gemm, Conv2d, and Conv3d kernel.</p><p><code>cutlass_profiler</code> 就是一个封装好的脚本，运行各类程序</p><p>进入到目录 <code>build/tools/profiler</code>，运行 <code>cutlass_profiler --help</code> 可以查看一些有用的信息，直接 <code>cutlass_profiler --help</code> 找不到 cutlass_profiler；用 <code>./cutlass_profiler --help</code> 就开始跑程序了，有点不知道怎么用这个 &ndash;help。</p><p>2022-05-09 20:22:30，还是用 <code>./cutlass_profiler --help</code> 就可以跑，不过神奇的是这是用 gpgpu-sim 跑得，最后会把需要的信息 print 在屏幕上。</p><h3 id=351-gemm>3.5.1 GEMM</h3><p>The CUTLASS Profiler is capable of executing GEMM and Sparse GEMM problems.</p><h4 id=3511-gemm-arguments-star>3.5.1.1 GEMM Arguments &#x2b50;</h4><p>The complete set of arguments available to each operation may be viewed by specifying the operation name in addition to &ndash;help. The argument flags and their aliases usable for GEMM appear as follows.</p><p>可以通过 option <code>--help</code> 查看完整的 operation，他这里给出的例子是 <code>./tools/profiler/cutlass_profiler --operation=gemm --help</code>，所以还是得执行这个脚本吧。</p><p>To execute kernels targeting Tensor Core operations, supply the flag <code>--op_class=tensorop</code> in the command line.</p><p>实际上，op_class 也就是选择 TensorOp or SIMT</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ ./tools/profiler/cutlass_profiler --op_class<span style=color:#f92672>=</span>tensorop --m<span style=color:#f92672>=</span><span style=color:#ae81ff>3456</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>8192</span></span></span></code></pre></div></div><h4 id=3513-自己运行>3.5.1.3 自己运行</h4><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>./tools/profiler/cutlass_profiler --operation<span style=color:#f92672>=</span>Gemm --op_class<span style=color:#f92672>=</span>tensorop --m<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span> --n<span style=color:#f92672>=</span><span style=color:#ae81ff>1024</span> --k<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span> --inst_m<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span> --inst_n<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span> --inst_k<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span></span></span></code></pre></div></div><p><strong>如何使用 4-bit 进行计算</strong>: 对于 TensorOp, Instruction Shape 8-by-8-by-32 对应的是 A-int4b_t, B-int4b_t, C-int32_t，通过参数 <code>--inst_m</code>, <code>--inst_n</code>, <code>inst_k</code> 来决定</p><h3 id=352-conv>3.5.2 Conv</h3><p>和 gemm 也是类似的，重点还是搞懂他们的参数。</p><h2 id=36-gemm-api-components>3.6 GEMM API Components</h2><p>This document focuses on device-level, threadblock-level GEMMs, warp-level GEMMs, thread-level GEMMs, and instruction-level GEMMs.</p><h3 id=361-device-wide-gemm-api>3.6.1 Device-wide GEMM API</h3><p>The device-wide GEMM API is embodied by the following operators</p><ul><li>cutlass::gemm::device::Gemm - basic GEMM operation</li><li>cutlass::gemm::device::GemmArray - batched GEMM operation in which input matrices are read from arrays of pointers</li><li>cutlass::gemm::device::GemmBatched - batched GEMM operation in which input matrices are separated by a constant stride</li><li>cutlass::gemm::device::GemmSplitKParallel - GEMM operation that partitions the GEMM K dimension then launches a separate reduction kernel</li></ul><p>都在 <code>cutlass/include/cutlass/gemm/device/</code> 目录下，basic GEMM 对应 <code>gemm.h</code> 文件</p><h1 id=4-在-gpgpu-sim-上运行>4. 在 GPGPU-Sim 上运行</h1><h2 id=41-cutlass-sim>4.1 cutlass-sim</h2><p>尝试了 Admodt 提供的 <code>https://github.com/gpgpu-sim/cutlass-gpgpu-sim</code>，仍然是 syntax error，估计是新版本编译的 PTX 有问题。2022-05-26 15:53:30，确实如此。</p><p>不同 CUDA 版本对应不同的 PTX .version，得到的 PTX 指令是不一样的。这就是为什么 CUDA 11.4 wmma 指令会报错。</p><h2 id=42-step>4.2 Step</h2><ul><li>下载并安装 CUDA Toolkit 9.2，使用这个版本编译模拟器。</li></ul><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell></code></pre></div></div><h1 id=5-cutlass-in-detail>5. CUTLASS in detail</h1><p>通过 cutlass 深入理解其 makefile 以及 cmake；同时，比较深入地 trace GEMM kernel 函数，目的是对应 SASS 去看。</p><h2 id=51-makefile-and-cmake-in-detail>5.1 Makefile and cmake in detail</h2><h3 id=511-s-文件>5.1.1 .s 文件</h3><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-makefile data-lang=makefile><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>cd</span> <span style=color:#960050;background-color:#1e0010>/home/data2/Workspace/huwm/share/work/cutlass/build</span> <span style=color:#960050;background-color:#1e0010>&amp;&amp;</span> <span style=color:#66d9ef>$(</span>MAKE<span style=color:#66d9ef>)</span> <span style=color:#66d9ef>$(</span>MAKESILENT<span style=color:#66d9ef>)</span> <span style=color:#960050;background-color:#1e0010>-f</span> <span style=color:#960050;background-color:#1e0010>tools/library/CMakeFiles/cutlass_library_objs.dir/build.make</span> <span style=color:#960050;background-color:#1e0010>tools/library/CMakeFiles/cutlass_library_objs.dir/generated/trmm/cutlass_tensorop_z884trmm_128x64_8x3_tn_rs_u_un_align1.cu.s</span></span></span></code></pre></div></div><p>.s 文件就是 assembly code.</p><h3 id=512-makefile-中这个-rule-的意义>5.1.2 Makefile 中这个 rule 的意义</h3><p>这里 rule 的作用是什么</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-makefile data-lang=makefile><span style=display:flex><span><span style=color:#a6e22e>tools/profiler/CMakeFiles/cutlass_profiler.dir/rule</span><span style=color:#f92672>:</span> cmake_check_build_system
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>$(</span>CMAKE_COMMAND<span style=color:#66d9ef>)</span> -E cmake_progress_start /home/data2/Workspace/huwm/share/work/cutlass/build/CMakeFiles <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>$(</span>MAKE<span style=color:#66d9ef>)</span> <span style=color:#66d9ef>$(</span>MAKESILENT<span style=color:#66d9ef>)</span> -f CMakeFiles/Makefile2 tools/profiler/CMakeFiles/cutlass_profiler.dir/all
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>$(</span>CMAKE_COMMAND<span style=color:#66d9ef>)</span> -E cmake_progress_start /home/data2/Workspace/huwm/share/work/cutlass/build/CMakeFiles <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>.PHONY </span><span style=color:#f92672>:</span> tools/profiler/CMakeFiles/cutlass_profiler.dir/rule</span></span></code></pre></div></div><h3 id=513-d-文件>5.1.3 .d 文件</h3><blockquote><p>The .d file is a dependency file that specifies the dependencies of the source file</p></blockquote><p>列出源文件的依赖关系，是一个可读的文本文件。</p><h3 id=514-make-cutlass_profiler-and-test_unit>5.1.4 make cutlass_profiler and test_unit</h3><p>cutlass 提供了两种 target，理解为 test_unit 是用于测试程序的正确性，而 cutalss_profiler 内置了评估性能的代码。</p><h3 id=515-tiny-cuda-nn-link-所有-o-文件>5.1.5 tiny-cuda-nn link 所有 .o 文件</h3><p>都在 <code>build/CMakeFiles/tiny-cuda-nn.dir/build.make</code> 中，<code>libtiny-cuda-nn.a:</code> target，这个 target 中，列出了所有的依赖文件</p><h2 id=52-gemm-iteration>5.2 GEMM iteration</h2><p>2023-03-22 15:45:45，终于找到了 cutlass 的 real loop</p><p><code>void gemm_iters</code> in <code>cutlass/gemm/threadblock/mma_pipelined.h</code>，在这个 kernel function 中，最终会调用 <code>warp_mma()</code>，这又是一个操作符重载的对象，通过对象本身直接调用其 <code>operator</code> 函数。</p><p><code>warp_mma()</code> 调用的就是 <code>cutlass/gemm/warp/mma_tensor_op.h</code> 中的 <code>void operator()</code> 函数</p><h3 id=521-mma_pipelinedh-void-gemm_iters>5.2.1 mma_pipelined.h void gemm_iters()</h3><p>SASS 指令中的 <code>.L_5</code> 部分就是这个函数中 <code>for (int warp_mma_k = 0; warp_mma_k &lt; Base::kWarpGemmIterations; ++warp_mma_k)</code> 的循环展开。</p><hr><h1 id=cublas>cuBLAS</h1><p>接下来是编译运行 cuBLAS 的过程</p><h1 id=1-nvidia-samples>1. NVIDIA Samples</h1><p><a href=https://github.com/NVIDIA/cuda-samples/>https://github.com/NVIDIA/cuda-samples/</a> 在 library 目录中有提供调用 cublas 的代码，果然官方提供的资源才是最好的。git clone 下来就可以在 A10 上编译运行。重点是理解不同 API 的含义，需要的 parameter，gemm 的 data type, shape 等等，这一点需要多看文档。</p><h2 id=11-如何确定调用了-tensor-core>1.1 如何确定调用了 tensor core?</h2><blockquote><p>Tensor cores were first introduced with Volta GPUs (compute capability>=sm_70) and significantly accelerate matrix multiplications. Starting with cuBLAS version 11.0.0, the library will automatically make use of Tensor Core capabilities wherever possible, unless they are explicitly disabled by selecting pedantic compute modes in cuBLAS (see cublasSetMathMode(), cublasMath_t).</p></blockquote><p>文档中说 cublas 会自动调用 tensor core</p><blockquote><p>2023-03-23 14:30:21，可以通过 nsys 调用 Nsight 工具来查看具体的 kernel 信息，也可以使用 <code>cuobjdump -sass</code> 得到 SASS 指令，通过指令的信息来判断。</p></blockquote><h1 id=2-documentation>2. Documentation</h1><h2 id=21-using-the-cublas-api>2.1 Using the cuBLAS API</h2><blockquote><p>cuBLAS库提供了现成的矩阵乘法算子，例如<code>cublasGemmEx</code>和<code>cublasLtMatmul</code>。其中后者是轻量级版本，API调用更灵活。</p></blockquote><p>cublasGemmEx</p><h2 id=211-general-description>2.1.1 General Description</h2><blockquote><p>应该注意的是，该库将选择启用 Tensor Core 的实现，只要它确定它将提供最佳性能。</p></blockquote><p>cuBLAS 11.0.0 之后支持任何 size 的矩阵，只是对齐的 size 能够更好地发挥 Tensor core 的性能。</p><h2 id=212-cublas-datatypes-reference>2.1.2 cuBLAS Datatypes Reference</h2><p><code>cublasDataType_t handle</code>，一个有关cuBLAS库的上下文的句柄，之后需要传递给API函数，即计算乘法的函数</p><p><code>cublasOperation_t</code>, N, 非转置；T，转置；C，共轭转置。</p><p><code>cublasGemmEx</code> 中的 <code>cublasGemmAlgo_t</code>，<code>cublasGemmAlgo_t</code> 最高支持 sm_75，sm_80 已经不支持了，所以在 sm_80 中指定了也是无效的，在 sm_80 中所有枚举都等同于 <code>CUBLAS_GEMM_DEFAULT</code> 或者 <code>CUBLAS_GEMM_DEFAULT_TENSOR_OP</code>。在更新的架构中也会 deprecated</p><p><code>cudaDataType_t</code>, 直接作为 <code>cublasGemmEx</code> 的参数，支持 int8 到 double 类型。</p><h3 id=213-cublas-level---3-function-reference>2.1.3 cuBLAS Level - 3 Function Reference</h3><p><code>cublasSgemm</code>, <code>cublasDgemm</code>, <code>cublasCgemm</code>, <code>cublasZgemm</code>, <code>cublasHgemm</code> 应该是比较初始的 API。</p><h3 id=214-blas-like-extension>2.1.4 BLAS-like Extension</h3><blockquote><p><code>cublasGemmEx()</code>. This function is an extension of cublasgemm that allows the user to individually specify the data types for each of the A, B and C matrices, the precision of computation and the GEMM algorithm to be run. Supported combinations of arguments are listed further down in this section.</p></blockquote><p>自定义 data types，自己在 int8 中就用的这个 API，支持 sm_50 以上的架构。</p><h2 id=22-using-the-cublaslt-api>2.2 Using the cuBLASLt API</h2><p>cuBLASLt, a lightweight library dedicated to GEMM</p><blockquote><p>The cuBLASLt in general does not guarantee to support all possible sizes and configurations.</p></blockquote><p>不一定支持任何 size</p><h3 id=221-cublaslt-datatypes-reference>2.2.1 cuBLASLt Datatypes Reference</h3><p><code>cublasLtMatmulTile_t</code> 提供多种 tile size</p><h2 id=23-using-the-cublasxt-api>2.3 Using the cuBLASXt API</h2><p>The cuBLASXt API of cuBLAS exposes a multi-GPU capable Host interface</p><p>cuBLASXT 似乎可以调用多个 GPU，比如有 4 A10 in QZ Server，code 限制只用两个 GPU。通过 cuBLASXT 执行 FP32 gemm，TFLOPS 应该不具备参考性了。</p><h1 id=bug>BUG</h1><p>2022</p><h4 id=1212>12.12</h4><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>CMake Error at CMakeLists.txt:31 <span style=color:#f92672>(</span>cutlass_example_add_executable<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>  Unknown CMake command <span style=color:#e6db74>&#34;cutlass_example_add_executable&#34;</span>.</span></span></code></pre></div></div><p>原因：可能是 gcc 版本问题，官方说的是 gcc7.3+，用的是 gcc5.5。</p><p>切换到 gcc7.5.0 没有解决这个问题。</p><p>2024-03-26 17:45:54，总结一下这个问题。使用 cmake 编译 cutlass 要处在主目录下，我自己是进入到 example 的子目录去了。在主目录编译之后，在 build 中可以找到 example 的 makefile 等文件。</p><h4 id=314>3.14</h4><p>2023.3.14 继续解决这个问题。</p><p>2023-03-14 15:49:24，似乎是编译 example 的方式不对，根据一个模板，使用以下方式来编译</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#75715e># 根目录下编译整个 projec</span>
</span></span><span style=display:flex><span>$ mkdir build <span style=color:#f92672>&amp;&amp;</span> cd build
</span></span><span style=display:flex><span>$ cmake ..
</span></span><span style=display:flex><span>$ make 00_basic_gemm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 00_basic_gemm bin 会生成在 cutlass/build/examples/00_basic_gemm 目录下</span></span></span></code></pre></div></div><h1 id=reference>Reference</h1><p>参考：https://github.com/sxzhang1993/Run-cutlass-with-gpgpu-sim</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Cory</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2024-03-26</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=https://huweim.github.io/tags/cutlass/>CUTLASS</a>
<a href=https://huweim.github.io/tags/cuda/>CUDA</a></div><nav class=post-nav><a class=prev href=/post/blog_hugo_%E8%AE%A9%E4%BD%A0%E7%9A%84%E5%8D%9A%E5%AE%A2%E8%A2%ABgoogle%E6%94%B6%E5%BD%95/><i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-left hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m15 18-6-6 6-6"/></svg>
</i><span class="prev-text nav-default">Hugo_让你的博客被Google收录</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/post/%E6%80%BB%E7%BB%93_deep_work/><span class="next-text nav-default">关于 Deep Work</span>
<span class="prev-text nav-mobile">Next</span>
<i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-right hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m9 18 6-6-6-6"/></svg></i></a></nav></footer></article></div><nav class=toc id=toc><div class=toc-title>Table of Contents</div><div class="toc-content custom-scrollbar"><nav id=TableOfContents><ul><li><a href=#0-前言>0. 前言</a></li><li><a href=#1-环境>1. 环境</a><ul><li><a href=#10-project-的目录结构>1.0 project 的目录结构</a></li><li><a href=#11-prerequisites>1.1 Prerequisites</a><ul><li><a href=#111-cmake>1.1.1 cmake</a></li><li><a href=#112-gcc>1.1.2 gcc</a></li></ul></li><li><a href=#12-build>1.2 Build</a><ul><li><a href=#121-cmake-在做什么>1.2.1 cmake 在做什么</a></li><li><a href=#122-make-在做什么>1.2.2 make 在做什么</a></li><li><a href=#123-test-in-real-gpu>1.2.3 Test in real GPU</a></li></ul></li><li><a href=#13-build-and-run-the-cutlass-profiler>1.3 Build and run the CUTLASS Profiler</a></li><li><a href=#14-build-and-run-cutlass-unit-tests>1.4 Build and run CUTLASS Unit Tests</a><ul><li><a href=#141-自己的-workspace>1.4.1 自己的 Workspace</a></li><li><a href=#142-工作站>1.4.2 工作站</a></li></ul></li><li><a href=#15-profiler-和-test-unit-的执行有什么区别>1.5 Profiler 和 Test Unit 的执行有什么区别？</a></li><li><a href=#16-gemm-运行参数>1.6 gemm 运行参数</a></li></ul></li><li><a href=#2-cutlass-examples>2. cutlass examples</a><ul><li><a href=#21-cmake-编译流程>2.1 cmake 编译流程</a></li></ul></li><li><a href=#3-documentation>3. Documentation</a><ul><li><a href=#32-functionality>3.2 Functionality</a><ul><li><a href=#322-device-level-implicit-gemm-convolution>3.2.2 Device-level Implicit GEMM convolution</a></li><li><a href=#323-warp-level-matrix-multiply-with-tensor-cores>3.2.3 Warp-level Matrix Multiply with Tensor Cores</a></li><li><a href=#324-warp-level-matrix-multiply-with-cuda-wmma-api>3.2.4 Warp-level Matrix Multiply with CUDA WMMA API</a></li></ul></li><li><a href=#33-efficient-gemm-in-cuda>3.3 Efficient GEMM in CUDA</a><ul><li><a href=#331-threadblock-level-gemm>3.3.1 Threadblock-level GEMM</a></li><li><a href=#332-warp-level-gemm>3.3.2 Warp-level GEMM</a></li><li><a href=#333-thread-level-gemm>3.3.3 Thread-level GEMM</a></li></ul></li><li><a href=#34-terminology>3.4 Terminology</a></li><li><a href=#35-align-含义>3.5 align 含义</a></li><li><a href=#35-cutlass-profiler-star>3.5 CUTLASS Profiler &#x2b50;</a><ul><li><a href=#351-gemm>3.5.1 GEMM</a><ul><li><a href=#3511-gemm-arguments-star>3.5.1.1 GEMM Arguments &#x2b50;</a></li><li><a href=#3513-自己运行>3.5.1.3 自己运行</a></li></ul></li><li><a href=#352-conv>3.5.2 Conv</a></li></ul></li><li><a href=#36-gemm-api-components>3.6 GEMM API Components</a><ul><li><a href=#361-device-wide-gemm-api>3.6.1 Device-wide GEMM API</a></li></ul></li></ul></li><li><a href=#4-在-gpgpu-sim-上运行>4. 在 GPGPU-Sim 上运行</a><ul><li><a href=#41-cutlass-sim>4.1 cutlass-sim</a></li><li><a href=#42-step>4.2 Step</a></li></ul></li><li><a href=#5-cutlass-in-detail>5. CUTLASS in detail</a><ul><li><a href=#51-makefile-and-cmake-in-detail>5.1 Makefile and cmake in detail</a><ul><li><a href=#511-s-文件>5.1.1 .s 文件</a></li><li><a href=#512-makefile-中这个-rule-的意义>5.1.2 Makefile 中这个 rule 的意义</a></li><li><a href=#513-d-文件>5.1.3 .d 文件</a></li><li><a href=#514-make-cutlass_profiler-and-test_unit>5.1.4 make cutlass_profiler and test_unit</a></li><li><a href=#515-tiny-cuda-nn-link-所有-o-文件>5.1.5 tiny-cuda-nn link 所有 .o 文件</a></li></ul></li><li><a href=#52-gemm-iteration>5.2 GEMM iteration</a><ul><li><a href=#521-mma_pipelinedh-void-gemm_iters>5.2.1 mma_pipelined.h void gemm_iters()</a></li></ul></li></ul></li><li><a href=#cublas>cuBLAS</a></li><li><a href=#1-nvidia-samples>1. NVIDIA Samples</a><ul><li><a href=#11-如何确定调用了-tensor-core>1.1 如何确定调用了 tensor core?</a></li></ul></li><li><a href=#2-documentation>2. Documentation</a><ul><li><a href=#21-using-the-cublas-api>2.1 Using the cuBLAS API</a></li><li><a href=#211-general-description>2.1.1 General Description</a></li><li><a href=#212-cublas-datatypes-reference>2.1.2 cuBLAS Datatypes Reference</a><ul><li><a href=#213-cublas-level---3-function-reference>2.1.3 cuBLAS Level - 3 Function Reference</a></li><li><a href=#214-blas-like-extension>2.1.4 BLAS-like Extension</a></li></ul></li><li><a href=#22-using-the-cublaslt-api>2.2 Using the cuBLASLt API</a><ul><li><a href=#221-cublaslt-datatypes-reference>2.2.1 cuBLASLt Datatypes Reference</a></li></ul></li><li><a href=#23-using-the-cublasxt-api>2.3 Using the cuBLASXt API</a></li></ul></li><li><a href=#bug>BUG</a><ul><li><ul><li><ul><li><a href=#1212>12.12</a></li><li><a href=#314>3.14</a></li></ul></li></ul></li></ul></li><li><a href=#reference>Reference</a></li></ul></nav></div></nav></div></main><footer id=footer class=site-footer><div class=social-icon-links><a href=mailto:huwm1@shanghaitech.edu.cn rel="me noopener" class=social-icon-link title=email><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1451 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg>
</a><a href=http://localhost:1313 rel="me noopener" class=social-icon-link title=linkedin target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M872.405333 872.618667H720.768V635.008c0-56.661333-1.152-129.578667-79.018667-129.578667-79.061333.0-91.136 61.653333-91.136 125.397334v241.792H398.976V384H544.64v66.602667h1.962667c20.352-38.4 69.845333-78.933333 143.786666-78.933334 153.642667.0 182.058667 101.12 182.058667 232.746667v268.202667zM227.712 317.141333a87.978667 87.978667.0 01-88.021333-88.106666A88.064 88.064.0 11227.712 317.141333zm76.032 555.477334H151.68V384h152.064v488.618667zM948.266667.0h-872.704C33.792.0.0 33.024.0 73.770667v876.458666C0 991.018667 33.792 1024 75.562667 1024h872.576C989.866667 1024 1024 991.018667 1024 950.229333V73.770667C1024 33.024 989.866667.0 948.138667.0h.128z"/></svg>
</a><a href=https://github.com/huweim rel="me noopener" class=social-icon-link title=github target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg>
</a><a href=https://www.zhihu.com/people/hu-wei-ming-31-86 rel="me noopener" class=social-icon-link title=zhihu target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M351.791182 562.469462h192.945407c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262h159.282726s-.86367-67.402109-18.578124-67.402109-279.979646.0-279.979646.0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461s24.62791 5.832845 36.941354.0c12.313443-5.832845 68.050885-25.924439 84.252893-103.69571h86.570681c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262H109.86113c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449H279.868105c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513.0.0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-.055259.185218 167.855986 193.263655s22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-.045025.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"/><path d="M584.918753 182.033893v668.840094h70.318532l28.807093 80.512708 121.875768-80.512708h153.600307L959.520453 182.033893h-374.6017zM887.150192 778.934538h-79.837326l-99.578949 65.782216-23.537066-65.782216h-24.855084L659.341766 256.673847h227.807403V778.934538z"/></svg>
</a><a href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=social-icon-link title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a>
</span><span class=copyright-year>&copy;
2020 -
2025
<span class=heart><i class=iconfont><svg aria-hidden="true" class="lucide lucide-heart hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5.0 0016.5 3c-1.76.0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5.0 002 8.5c0 2.3 1.5 4.05 3 5.5l7 7z"/></svg>
</i></span><span class=author>Weiming Hu</span></span></div></footer><script type=text/javascript src=/js/main.eb94e793601239645bc98e36c443aef1b210646ccb43e2217ea949a0212e0ed1.js integrity="sha256-65Tnk2ASOWRbyY42xEOu8bIQZGzLQ+IhfqlJoCEuDtE=" crossorigin=anonymous></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>