<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>CUDA_driver, nvcc, cuda, cudatoolkit,cudnn浅析 - Cory</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="Cory"><meta name=description content="0. 前言 文章转载自知乎答主 marsggbo，当做笔记记录一下这些 CUDA 中经常接触的内容。 在使用深度学习框架的过程中一定会经常碰到这些东西，虽然an"><meta name=keywords content="Hugo,theme,jane"><meta name=generator content="Hugo 0.110.0"><link rel=canonical href=https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_cuda_driver-nvcc-cuda-cudatoolkitcudnn%E6%B5%85%E6%9E%90/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css integrity="sha256-+ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media=screen crossorigin=anonymous><meta property="og:title" content="CUDA_driver, nvcc, cuda, cudatoolkit,cudnn浅析"><meta property="og:description" content="0. 前言 文章转载自知乎答主 marsggbo，当做笔记记录一下这些 CUDA 中经常接触的内容。 在使用深度学习框架的过程中一定会经常碰到这些东西，虽然an"><meta property="og:type" content="article"><meta property="og:url" content="https://huweim.github.io/post/%E7%BC%96%E7%A8%8B_cuda_driver-nvcc-cuda-cudatoolkitcudnn%E6%B5%85%E6%9E%90/"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-07-25T11:00:17+08:00"><meta property="article:modified_time" content="2022-11-26T16:17:41+08:00"><meta itemprop=name content="CUDA_driver, nvcc, cuda, cudatoolkit,cudnn浅析"><meta itemprop=description content="0. 前言 文章转载自知乎答主 marsggbo，当做笔记记录一下这些 CUDA 中经常接触的内容。 在使用深度学习框架的过程中一定会经常碰到这些东西，虽然an"><meta itemprop=datePublished content="2021-07-25T11:00:17+08:00"><meta itemprop=dateModified content="2022-11-26T16:17:41+08:00"><meta itemprop=wordCount content="6479"><meta itemprop=keywords content="浅尝辄止,"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA_driver, nvcc, cuda, cudatoolkit,cudnn浅析"><meta name=twitter:description content="0. 前言 文章转载自知乎答主 marsggbo，当做笔记记录一下这些 CUDA 中经常接触的内容。 在使用深度学习框架的过程中一定会经常碰到这些东西，虽然an"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Cory</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>Cory</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>CUDA_driver, nvcc, cuda, cudatoolkit,cudnn浅析</h1><div class=post-meta><time datetime=2021-07-25 class=post-time>2021-07-25</time><div class=post-category><a href=https://huweim.github.io/categories/cuda/>CUDA</a></div><span class=more-meta>6479 words</span>
<span class=more-meta>13 min read</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Table of Contents</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#11-cuda>1.1 CUDA</a></li><li><a href=#12-cudnn>1.2 cudnn</a></li><li><a href=#12-cuda-toolkit>1.2 CUDA Toolkit</a><ul><li><a href=#121-compiler>1.2.1 Compiler</a></li><li><a href=#122-tools>1.2.2 Tools</a></li><li><a href=#123-libraries>1.2.3 Libraries</a></li><li><a href=#124-cuda-samples>1.2.4 CUDA Samples</a></li><li><a href=#125-cuda-driver>1.2.5 CUDA Driver</a></li></ul></li></ul><ul><li><a href=#21-nvcc>2.1 <code>nvcc</code></a></li><li><a href=#22-nvidia-smi>2.2 <code>nvidia-smi</code></a></li><li><a href=#23-nvcc和nvidia-smi显示的cuda版本不同>2.3 <code>nvcc</code>和<code>nvidia-smi</code>显示的CUDA版本不同？</a></li></ul><ul><li><a href=#31-复杂性>3.1 复杂性</a></li><li><a href=#32-控制>3.2 控制</a></li><li><a href=#33-上下文管理>3.3 上下文管理</a></li></ul><ul><li><a href=#41-path>4.1 PATH</a></li><li><a href=#42-library_path和ld_library_path>4.2 LIBRARY_PATH和LD_LIBRARY_PATH</a></li></ul><ul><li><a href=#51-cuda-的下载与安装方法选择>5.1 cuda 的下载与安装方法选择</a></li><li><a href=#52-cuda-安装>5.2 cuda 安装</a></li><li><a href=#53-多个-cuda-版本之间进行切换>5.3 多个 cuda 版本之间进行切换</a></li></ul></nav></div></div><div class=post-content><h1 id=0-前言>0. 前言</h1><p>文章转载自知乎答主 <a href=https://www.zhihu.com/people/hexin_marsggbo>marsggbo</a>，当做笔记记录一下这些 CUDA 中经常接触的内容。</p><p>在使用深度学习框架的过程中一定会经常碰到这些东西，虽然anaconda有时会帮助我们自动地解决这些设置，但是有些特殊的库却还是需要我们手动配置环境，但是我对标题上的这些名词其实并不十分清楚，所以老是被网上的教程绕得云里雾里，所以觉得有必要写下一篇文章当做笔记供之后参考。</p><h1 id=0-gpu型号含义>0. GPU型号含义</h1><blockquote><p>参考<a href="https://link.zhihu.com/?target=https%3A//chenrudan.github.io/blog/2015/12/20/introductionofgpuhardware.html">【GPU编程系列之一】从深度学习选择什么样的gpu来谈谈gpu的硬件架构</a></p></blockquote><ul><li><p><strong>显卡</strong>： 简单理解这个就是我们前面说的<strong>GPU</strong>，尤其指NVIDIA公司生产的GPU系列，因为后面介绍的cuda,cudnn都是NVIDIA公司针对自身的GPU独家设计的。</p></li><li><p><strong>显卡驱动</strong>：很明显就是字面意思，通常指<strong>NVIDIA Driver</strong>，其实它就是一个驱动软件，而前面的<strong>显卡</strong>就是硬件。</p></li><li><p>gpu架构：Tesla、Fermi、Kepler、Maxwell、Pascal</p></li><li><p>芯片型号：GT200、GK210、GM104、GF104等</p></li><li><p>显卡系列：GeForce、Quadro、Tesla</p></li><li><p>GeForce显卡型号：G/GS、GT、GTS、GTX</p></li></ul><p>gpu架构指的是硬件的设计方式，例如流处理器簇中有多少个core、是否有L1 or L2缓存、是否有双精度计算单元等等。每一代的架构是一种思想，如何去更好完成并行的思想</p><p>芯片就是对上述gpu架构思想的实现，例如芯片型号GT200中第二个字母代表是哪一代架构，有时会有100和200代的芯片，它们基本设计思路是跟这一代的架构一致，只是在细节上做了一些改变，例如GK210比GK110的寄存器就多一倍。有时候一张显卡里面可能有两张芯片，Tesla k80用了两块GK210芯片。这里第一代的gpu架构的命名也是Tesla，但现在基本已经没有这种设计的卡了，下文如果提到了会用Tesla架构和Tesla系列来进行区分。</p><p>而显卡系列在本质上并没有什么区别，只是NVIDIA希望区分成三种选择，</p><ul><li>GeFore用于家庭娱乐</li><li>Quadro用于工作站</li><li>Tesla系列用于服务器。</li></ul><p>Tesla的k型号卡为了高性能科学计算而设计，比较突出的优点是双精度浮点运算能力高并且支持ECC内存，但是双精度能力好在深度学习训练上并没有什么卵用，所以Tesla系列又推出了M型号来做专门的训练深度学习网络的显卡。需要注意的是Tesla系列没有显示输出接口，它专注于数据计算而不是图形显示。</p><p>最后一个GeForce的显卡型号是不同的硬件定制，越往后性能越好，时钟频率越高显存越大，即G/GS&lt;GT&lt;GTS&lt;GTX。</p><h1 id=1-cuda名称含义>1. CUDA名称含义</h1><h2 id=11-cuda>1.1 CUDA</h2><p>看了很多答案，有人说CUDA就是一门编程语言，像C,C++,python 一样，也有人说CUDA是API。CUDA英文全称是Compute Unified Device Architecture，是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。按照<a href="https://link.zhihu.com/?target=https%3A//blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/">官方</a>的说法是，<strong>CUDA是一个并行计算平台和编程模型，能够使得使用GPU进行通用计算变得简单和优雅</strong>。</p><h2 id=12-cudnn>1.2 cudnn</h2><p>这个其实就是一个专门为深度学习计算设计的软件库，里面提供了很多专门的计算函数，如卷积等。从上图也可以看到，还有很多其他的软件库和中间件，包括实现c++ STL的thrust、实现gpu版本blas的cublas、实现快速傅里叶变换的cuFFT、实现稀疏矩阵运算操作的cuSparse以及实现深度学习网络加速的cuDNN等等，具体细节可参阅<a href="https://link.zhihu.com/?target=https%3A//developer.nvidia.com/gpu-accelerated-libraries">GPU-Accelerated Libraries</a></p><h2 id=12-cuda-toolkit>1.2 CUDA Toolkit</h2><blockquote><p>参考<a href="https://link.zhihu.com/?target=https%3A//docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html%23major-components">CUDA Toolkit</a></p></blockquote><p>CUDA Toolkit由以下组件组成：</p><h3 id=121-compiler>1.2.1 Compiler</h3><p>CUDA-C和CUDA-C++编译器<code>NVCC</code>位于<code>bin/</code>目录中。它建立在<code>NVVM</code>优化器之上，而<code>NVVM</code>优化器本身构建在<code>LLVM</code>编译器基础结构之上。因此开发人员可以使用<code>nvm/</code>目录下的Compiler SDK来直接针对NVVM进行开发。</p><h3 id=122-tools>1.2.2 Tools</h3><p>提供一些像<code>profiler</code>,<code>debuggers</code>等工具，这些工具可以从<code>bin/</code>目录中获取</p><h3 id=123-libraries>1.2.3 Libraries</h3><p>下面列出的部分科学库和实用程序库可以在<code>lib/</code>目录中使用(Windows上的DLL位于<code>bin/</code>中)，它们的接口在<code>include/</code>目录中可获取。</p><ul><li><strong>cudart</strong>: CUDA Runtime</li><li><strong>cudadevrt</strong>: CUDA device runtime</li><li><strong>cupti</strong>: CUDA profiling tools interface</li><li><strong>nvml</strong>: NVIDIA management library</li><li><strong>nvrtc</strong>: CUDA runtime compilation</li><li><strong>cublas</strong>: BLAS (Basic Linear Algebra Subprograms，基础线性代数程序集)</li><li><strong>cublas_device</strong>: BLAS kernel interface</li><li>&mldr;</li></ul><h3 id=124-cuda-samples>1.2.4 CUDA Samples</h3><p>演示如何使用各种CUDA和library API的代码示例。可在Linux和Mac上的<code>samples/</code>目录中获得，Windows上的路径是<code>C：\ProgramData\NVIDIA Corporation\CUDA Samples</code>中。在Linux和Mac上，<code>samples/</code>目录是只读的，如果要对它们进行修改，则必须将这些示例复制到另一个位置。</p><h3 id=125-cuda-driver>1.2.5 CUDA Driver</h3><p>运行CUDA应用程序需要系统至少有一个<strong>具有CUDA功能的GPU</strong>和<strong>与CUDA工具包兼容的驱动程序</strong>。每个版本的CUDA工具包都对应一个最低版本的CUDA Driver，也就是说如果你安装的CUDA Driver版本比官方推荐的还低，那么很可能会无法正常运行。CUDA Driver是向后兼容的，这意味着根据CUDA的特定版本编译的应用程序将继续在后续发布的Driver上也能继续工作。通常为了方便，在安装CUDA Toolkit的时候会默认安装CUDA Driver。在开发阶段可以选择默认安装Driver，但是对于像Tesla GPU这样的商用情况时，建议在<a href="https://link.zhihu.com/?target=http%3A//www.nvidia.com/drivers">官方</a>安装最新版本的Driver。 目前(2019年10月)的CUDA Toolkit和CUDA Driver版本的对应情况如下：</p><h1 id=2-nvccnvidia-smi>2. <code>nvcc</code>&<code>nvidia-smi</code></h1><h2 id=21-nvcc>2.1 <code>nvcc</code></h2><p>这个在前面已经介绍了，<code>nvcc</code>其实就是CUDA的编译器,可以从CUDA Toolkit的<code>/bin</code>目录中获取,类似于<code>gcc</code>就是c语言的编译器。由于程序是要经过编译器编程成可执行的二进制文件，而cuda程序有两种代码，一种是运行在cpu上的host代码，一种是运行在gpu上的device代码，所以<code>nvcc</code>编译器要保证两部分代码能够编译成二进制文件在不同的机器上执行。nvcc涉及到的文件后缀及相关意义如下表</p><h2 id=22-nvidia-smi>2.2 <code>nvidia-smi</code></h2><p><code>nvidia-smi</code>全程是NVIDIA System Management Interface ，它是一个基于前面介绍过的<code>NVIDIA Management Library(NVML)</code>构建的命令行实用工具，旨在帮助管理和监控NVIDIA GPU设备。</p><h2 id=23-nvcc和nvidia-smi显示的cuda版本不同>2.3 <code>nvcc</code>和<code>nvidia-smi</code>显示的CUDA版本不同？</h2><p>在我们实验室的服务器上<code>nvcc --version</code>显示的结果如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>nvcc: NVIDIA (R) Cuda compiler driver
</span></span><span style=display:flex><span>Copyright (c) <span style=color:#ae81ff>2005</span><span style=color:#f92672>-</span><span style=color:#ae81ff>2018</span> NVIDIA Corporation
</span></span><span style=display:flex><span>Built on Tue_Jun_12_23:<span style=color:#ae81ff>07</span>:<span style=color:#ae81ff>04</span>_CDT_2018
</span></span><span style=display:flex><span>Cuda compilation tools, release <span style=color:#ae81ff>9.2</span>, V9<span style=color:#ae81ff>.2.148</span>
</span></span></code></pre></div><p>而<code>nvidia-smi</code>显示结果如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>+-----------------------------------------------------------------------------+</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span> NVIDIA<span style=color:#f92672>-</span>SMI <span style=color:#ae81ff>410.104</span>      Driver Version: <span style=color:#ae81ff>410.104</span>      CUDA Version: <span style=color:#ae81ff>10.0</span>     <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|-------------------------------+----------------------+----------------------+</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span> GPU  Name        Persistence<span style=color:#f92672>-</span>M<span style=color:#f92672>|</span> Bus<span style=color:#f92672>-</span>Id        Disp<span style=color:#f92672>.</span>A <span style=color:#f92672>|</span> Volatile Uncorr<span style=color:#f92672>.</span> ECC <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span> Fan  Temp  Perf  Pwr:Usage<span style=color:#f92672>/</span>Cap<span style=color:#f92672>|</span>         Memory<span style=color:#f92672>-</span>Usage <span style=color:#f92672>|</span> GPU<span style=color:#f92672>-</span>Util  Compute M<span style=color:#f92672>.</span> <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|===============================+======================+======================|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span>   <span style=color:#ae81ff>0</span>  Tesla V100<span style=color:#f92672>-</span>PCIE<span style=color:#f92672>...</span>  On   <span style=color:#f92672>|</span> <span style=color:#ae81ff>00000000</span>:<span style=color:#ae81ff>01</span>:<span style=color:#ae81ff>00.0</span> Off <span style=color:#f92672>|</span>                  Off <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span> N<span style=color:#f92672>/</span>A   <span style=color:#ae81ff>28</span>C    P0    <span style=color:#ae81ff>26</span>W <span style=color:#f92672>/</span> <span style=color:#ae81ff>250</span>W <span style=color:#f92672>|</span>      <span style=color:#ae81ff>0</span>MiB <span style=color:#f92672>/</span> <span style=color:#ae81ff>16130</span>MiB <span style=color:#f92672>|</span>      <span style=color:#ae81ff>0</span><span style=color:#f92672>%</span>      Default <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>+-------------------------------+----------------------+----------------------+</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span>   <span style=color:#ae81ff>1</span>  Tesla P100<span style=color:#f92672>-</span>PCIE<span style=color:#f92672>...</span>  On   <span style=color:#f92672>|</span> <span style=color:#ae81ff>00000000</span>:<span style=color:#ae81ff>02</span>:<span style=color:#ae81ff>00.0</span> Off <span style=color:#f92672>|</span>                  Off <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span> N<span style=color:#f92672>/</span>A   <span style=color:#ae81ff>24</span>C    P0    <span style=color:#ae81ff>30</span>W <span style=color:#f92672>/</span> <span style=color:#ae81ff>250</span>W <span style=color:#f92672>|</span>      <span style=color:#ae81ff>0</span>MiB <span style=color:#f92672>/</span> <span style=color:#ae81ff>16280</span>MiB <span style=color:#f92672>|</span>      <span style=color:#ae81ff>0</span><span style=color:#f92672>%</span>      Default <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>+-------------------------------+----------------------+----------------------+</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>+-----------------------------------------------------------------------------+</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span> Processes:                                                       GPU Memory <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span>  GPU       PID   Type   Process name                             Usage      <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|=============================================================================|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>|</span>  No running processes found                                                 <span style=color:#f92672>|</span>
</span></span><span style=display:flex><span><span style=color:#f92672>+-----------------------------------------------------------------------------+</span>
</span></span></code></pre></div><p>可以看到<code>nvcc</code>的CUDA 版本是9.2，而<code>nvidia-smi</code>的CUDA版本是10.0。很奇怪的是有时候绝大多数情况代码也能整成跑起来，<a href="https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/53422407/different-cuda-versions-shown-by-nvcc-and-nvidia-smi">stackoverflow</a>上的一个解释如下：</p><p>CUDA有两个主要的API：<strong>runtime(运行时) API</strong>和<strong>driver API</strong>。这两个API都有对应的CUDA版本（如9.2和10.0等）。</p><ul><li>用于支持<strong>driver API</strong>的必要文件(如<code>libcuda.so</code>)是由<strong>GPU driver installer</strong>安装的。<code>nvidia-smi</code>就属于这一类API。</li><li>用于支持<strong>runtime API</strong>的必要文件(如<code>libcudart.so</code>以及<code>nvcc</code>)是由<strong>CUDA Toolkit installer</strong>安装的。（CUDA Toolkit Installer有时可能会集成了GPU driver Installer）。<code>nvcc</code>是与CUDA Toolkit一起安装的CUDA compiler-driver tool，它只知道它自身构建时的CUDA runtime版本。它不知道安装了什么版本的GPU driver，甚至不知道是否安装了GPU driver。</li></ul><p>综上，如果driver API和runtime API的CUDA版本不一致可能是因为你使用的是单独的GPU driver installer，而不是CUDA Toolkit installer里的GPU driver installer。</p><h1 id=3-runtime和driver-api区别>3. runtime和driver API区别</h1><p>下图很清楚的展示前面提到的各种概念之间的关系，其中runtime和driver API在很多情况非常相似，也就是说用起来的效果是等价的，但是你不能混合使用这两个API，因为二者是互斥的。也就是说在开发过程中，你只能选择其中一种API。</p><p>简单理解二者的区别就是：runtime是更高级的封装，开发人员用起来更方便，而driver API更接近底层，速度可能会更快。</p><p>两种API详细的<a href="https://link.zhihu.com/?target=https%3A//docs.nvidia.com/cuda/cuda-runtime-api/driver-vs-runtime-api.html">区别</a>如下：</p><h2 id=31-复杂性>3.1 复杂性</h2><ul><li>runtime API通过提供隐式初始化、上下文管理和模块管理来简化设备代码管理。这使得代码更简单，但也缺乏驱动程序API所具有的控制级别。</li><li>相比之下，driver API提供了更细粒度的控制，特别是在上下文和模块加载方面。实现内核启动要复杂得多，因为执行配置和内核参数必须用显式函数调用指定。</li></ul><h2 id=32-控制>3.2 控制</h2><ul><li>对于runtime API，其在运行时，所有内核都在初始化期间自动加载，并在程序运行期间保持加载状态。</li><li>而使用driver API，可以只加载当前需要的模块，甚至动态地重新加载模块。driver API也是语言独立的，因为它只处理<code>cubin</code>对象。</li></ul><h2 id=33-上下文管理>3.3 上下文管理</h2><p>上下文管理可以通过driver API完成，但是在runtime API中不公开。相反，runtime API自己决定为线程使用哪个上下文:</p><ul><li>如果一个上下文通过driver API成为调用线程的当前上下文，runtime将使用它</li><li>如果没有这样的上下文，它将使用“主上下文(primary context)”。</li></ul><p>主上下文会根据需要创建，每个设备每个进程一个上下文，并进行引用计数，然后在没有更多的引用时销毁它们。在一个进程中，所有runtime API的用户都将共享主上下文，除非上下文已成为每个线程的当前上下文。runtime使用的上下文，即当前上下文或主上下文，可以用<code>cudaDeviceSynchronize()</code>同步，也可以用<code>cudaDeviceReset()</code>销毁。 但是，将runtime API与主上下文一起使用会有tradeoff。例如，对于那些需要给较大的软件包写插件的开发者来说者会带来不少麻烦，因为如果所有的插件都在同一个进程中运行，它们将共享一个上下文，但可能无法相互通信。也就是说，如果其中一个在完成所有CUDA工作后调用<code>cudaDeviceReset()</code>，其他插件将失败，因为它们使用的上下文在它们不知情的情况下被破坏。为了避免这个问题，CUDA clients可以使用driver API来创建和设置当前上下文，然后使用runtime API来处理它。但是，上下文可能会消耗大量的资源，比如设备内存、额外的主机线程和设备上上下文切换的性能成本。当将driver API与基于runtime API(如cuBLAS或cuFFT)构建的库一起使用时，这种runtime-driver上下文共享非常重要。</p><h1 id=4-linux中path-library_path-ld_library_path的区别>4. Linux中PATH、 LIBRARY_PATH、 LD_LIBRARY_PATH的区别</h1><blockquote><p>参考<a href="https://link.zhihu.com/?target=https%3A//www.imooc.com/article/43747">Linux中PATH、 LIBRARY_PATH、 LD_LIBRARY_PATH的区别</a></p></blockquote><h2 id=41-path>4.1 PATH</h2><p>PATH是可执行文件路径，是三个中我们最常接触到的，因为我们命令行中的每句能运行的命令，如ls、top、ps等，都是系统通过PATH找到了这个命令执行文件的所在位置，再run这个命令（可执行文件）。 比如说，在用户的目录<code>~/mycode/</code>下有一个bin文件夹，里面放了有可执行的二进制文件、shell脚本等。如果想要在任意目录下都能运行上述bin文件夹的可执行文件，那么只需要把这个bin的路径添加到PATH即可，方法如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># vim ~/.bashrc</span>
</span></span><span style=display:flex><span>PATH<span style=color:#f92672>=</span>$PATH:~/mycode/bin
</span></span></code></pre></div><h2 id=42-library_path和ld_library_path>4.2 LIBRARY_PATH和LD_LIBRARY_PATH</h2><p>这两个路径可以放在一起讨论，</p><ul><li><code>LIBRARY_PATH</code>是<strong>程序编译期间</strong>查找动态链接库时指定查找共享库的路径</li><li><code>LD_LIBRARY_PATH</code>是<strong>程序加载运行期间</strong>查找动态链接库时指定除了系统默认路径之外的其他路径</li></ul><p>两者的共同点是库，库是这两个路径和PATH路径的区别，PATH是可执行文件。</p><p>两者的差异点是使用时间不一样。一个是编译期，对应的是开发阶段，如gcc编译；一个是加载运行期，对应的是程序已交付的使用阶段。</p><p>配置方法也是类似：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>export  LD_LIBRARY_PATH<span style=color:#f92672>=</span>LD_LIBRARY_PATH:XXXX
</span></span></code></pre></div><h1 id=5-多版本cuda切换>5 多版本CUDA切换</h1><blockquote><p>参考<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/Maple2014/article/details/78574275">安装多版本cuda，多版本之间切换</a></p></blockquote><p>基于前面几个小节的介绍，现在再来介绍如何管理多版本CUDA就会好懂很多了。</p><p>PS：自己在安装使用 GPGPU-Sim 中也记录了 CUDA 的安装过程</p><h2 id=51-cuda-的下载与安装方法选择>5.1 cuda 的下载与安装方法选择</h2><p>到 <a href="https://link.zhihu.com/?target=https%3A//developer.nvidia.com/cuda-downloads">CUDA Toolkit Download</a> 下载所需版本，以 cuda_9.0.176_384.81_linux.run为例：</p><p>建议选择使用 <code>.run</code> 文件安装，因为使用 <code>.deb</code>可能会将已经安装的较新的显卡驱动替换。</p><h2 id=52-cuda-安装>5.2 cuda 安装</h2><p>进入到放置 <code>cuda_9.0.176_384.81_linux.run</code> 的目录：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo chmod +x cuda_9.0.176_384.81_linux.run <span style=color:#75715e># 为 cuda_9.0.176_384.81_linux.run 添加可执行权限</span>
</span></span><span style=display:flex><span>./cuda_9.0.176_384.81_linux.run <span style=color:#75715e># 安装 cuda_9.0.176_384.81_linux.run</span>
</span></span></code></pre></div><p>在安装过程中截取其中比较重要的几个选择：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Do you accept the previously read EULA?
</span></span><span style=display:flex><span>accept/decline/quit: accept
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Install NVIDIA Accelerated Graphics Driver <span style=color:#66d9ef>for</span> Linux-x86_64 384.81?
</span></span><span style=display:flex><span><span style=color:#f92672>(</span>y<span style=color:#f92672>)</span>es/<span style=color:#f92672>(</span>n<span style=color:#f92672>)</span>o/<span style=color:#f92672>(</span>q<span style=color:#f92672>)</span>uit: n <span style=color:#75715e># 如果在这之前已经安装好更高版本的显卡驱动就不需要再重复安装，如果需要重复安装就选择 yes,此外还需要关闭图形界面。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Install the CUDA 9.0 Toolkit?
</span></span><span style=display:flex><span><span style=color:#f92672>(</span>y<span style=color:#f92672>)</span>es/<span style=color:#f92672>(</span>n<span style=color:#f92672>)</span>o/<span style=color:#f92672>(</span>q<span style=color:#f92672>)</span>uit: y
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Enter Toolkit Location
</span></span><span style=display:flex><span> <span style=color:#f92672>[</span> default is /usr/local/cuda-9.0 <span style=color:#f92672>]</span>: <span style=color:#75715e># 一般选择默认即可，也可以选择安装在其他目录，在需要用的时候指向该目录或者使用软连接 link 到 /usr/local/cuda。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/usr/local/cuda-9.0 is not writable.
</span></span><span style=display:flex><span>Do you wish to run the installation with <span style=color:#e6db74>&#39;sudo&#39;</span>?
</span></span><span style=display:flex><span><span style=color:#f92672>(</span>y<span style=color:#f92672>)</span>es/<span style=color:#f92672>(</span>n<span style=color:#f92672>)</span>o: y
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Please enter your password: 
</span></span><span style=display:flex><span>Do you want to install a symbolic link at /usr/local/cuda? <span style=color:#75715e># 是否将安装目录通过软连接的方式 link 到 /usr/local/cuda，yes or no 都可以，取决于你是否使用 /usr/local/cuda 为默认的 cuda 目录。</span>
</span></span><span style=display:flex><span><span style=color:#f92672>(</span>y<span style=color:#f92672>)</span>es/<span style=color:#f92672>(</span>n<span style=color:#f92672>)</span>o/<span style=color:#f92672>(</span>q<span style=color:#f92672>)</span>uit: n
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Install the CUDA 9.0 Samples?
</span></span><span style=display:flex><span><span style=color:#f92672>(</span>y<span style=color:#f92672>)</span>es/<span style=color:#f92672>(</span>n<span style=color:#f92672>)</span>o/<span style=color:#f92672>(</span>q<span style=color:#f92672>)</span>uit: n
</span></span></code></pre></div><p>前面选择的一些汇总：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Driver:   Not Selected
</span></span><span style=display:flex><span>Toolkit:  Installed in /usr/local/cuda-9.0
</span></span><span style=display:flex><span>Samples:  Not Selected
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Please make sure that
</span></span><span style=display:flex><span> -   PATH includes /usr/local/cuda-9.0/bin
</span></span><span style=display:flex><span> -   LD_LIBRARY_PATH includes /usr/local/cuda-9.0/lib64, or, add /usr/local/cuda-9.0/lib64 to /etc/ld.so.conf and run ldconfig as root
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-9.0/doc/pdf <span style=color:#66d9ef>for</span> detailed information on setting up CUDA.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 384.00 is required <span style=color:#66d9ef>for</span> CUDA 9.0 functionality to work.
</span></span><span style=display:flex><span>To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file:
</span></span><span style=display:flex><span>    sudo &lt;CudaInstaller&gt;.run -silent -driver
</span></span></code></pre></div><p>安装完成后可以在 /usr/local 目录下看到：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cuda-8.0 <span style=color:#75715e># 笔者之前安装的cuda-8.0</span>
</span></span><span style=display:flex><span>cuda-9.0 <span style=color:#75715e># 刚刚安装的cuda-9.0</span>
</span></span><span style=display:flex><span>cuda <span style=color:#75715e># cuda-8.0 的软连接</span>
</span></span></code></pre></div><h2 id=53-多个-cuda-版本之间进行切换>5.3 多个 cuda 版本之间进行切换</h2><p>将<code>~/.bashrc</code> 或　<code>~/.zshrc</code> 下与cuda相关的路径都改为　<code>/usr/local/cuda/</code>　而不使用　<code>/usr/local/cuda-8.0/</code> 或<code>/usr/local/cuda-9.0/</code>。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#在切换cuda版本时</span>
</span></span><span style=display:flex><span>rm -rf /usr/local/cuda#删除之前创建的软链接
</span></span><span style=display:flex><span>sudo ln -s /usr/local/cuda-8.0/ /usr/local/cuda/
</span></span><span style=display:flex><span>nvcc --version <span style=color:#75715e>#查看当前 cuda 版本</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>nvcc: NVIDIA <span style=color:#f92672>(</span>R<span style=color:#f92672>)</span> Cuda compiler driver
</span></span><span style=display:flex><span>Copyright <span style=color:#f92672>(</span>c<span style=color:#f92672>)</span> 2005-2016 NVIDIA Corporation
</span></span><span style=display:flex><span>Built on Mon_Jan_23_12:24:11_CST_2017
</span></span><span style=display:flex><span>Cuda compilation tools, release 8.0, V8.0.62
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#cuda8.0 切换到 cuda9.0 </span>
</span></span><span style=display:flex><span>rm -rf /usr/local/cuda
</span></span><span style=display:flex><span>sudo ln -s /usr/local/cuda-9.0/ /usr/local/cuda/
</span></span><span style=display:flex><span>nvcc --version
</span></span></code></pre></div><h1 id=6-conda安装的cuda-toolkit和nvidia的cuda-toolkit到底什么区别>6. Conda安装的CUDA Toolkit和NVIDIA的CUDA Toolkit到底什么区别？</h1><p>上面说了那么多可能看得云里雾里，下面做一个小的总结（参考下文）。</p><p><a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/yhjoker/p/10972795.html">Pytorch 使用不同版本的 cudawww.cnblogs.com<img src=https://pic2.zhimg.com/v2-0b8ae563079a01e227a42426433ce9b5_180x120.jpg alt=图标></a></p><p><strong>Nvidia</strong> 官方提供的 CUDA Toolkit 是一个<strong>完整</strong>的工具安装包，其中提供了 Nvidia <strong>驱动程序</strong>、<strong>开发 CUDA 程序</strong>相关的开发工具包等可供安装的选项。使用 Nvidia 官网提供的 CUDA Toolkit 可以安装开发 CUDA 程序所需的工具，包括 CUDA 程序的编译器、IDE、调试器等，CUDA 程序所对应的各式库文件以及它们的头文件。</p><p>但对于 Pytorch 之类的深度学习框架而言，其在大多数需要使用 GPU 的情况中只需要使用 CUDA 的动态链接库支持程序的运行( <strong>Pytorch 本身与 CUDA 相关的部分是提前编译好的</strong> )，就像常见的可执行程序一样，不需要重新进行编译过程，只需要其所依赖的动态链接库存在即可正常运行。</p><p><strong>Anaconda</strong> 在安装 Pytorch 等会使用到 CUDA 的框架时，会自动为用户安装 cudatoolkit，其主要包含应用程序在使用 CUDA 相关的功能时所依赖的<strong>动态链接库，不会安装驱动程序</strong>。在安装了 cudatoolkit 后，只要系统上存在与当前的 cudatoolkit 所兼容的 Nvidia 驱动，则已经编译好的 CUDA 相关的程序就可以直接运行，而不需要安装完整的 Nvidia 官方提供的 CUDA Toolkit .</p><p>总的来说，你可以把Anaconda安装的 Toolkit 看成是一个组装好的汽车，型号是10.0，恰巧你又安装了10.0版本的NVIDIA的CUDA驱动程序，那么你就有了10.0的钥匙，那么你就可以直接开豪车了。 反之，如果你只有9.0的钥匙，那你此时有两个解决办法，一是用Anaconda安装9.0版本的Pytorch，另一个是另外配一把10.0的钥匙。如何切换不同钥匙的方法在上文已经介绍了。</p><h1 id=reference>Reference</h1><p><a href=https://zhuanlan.zhihu.com/p/91334380>https://zhuanlan.zhihu.com/p/91334380</a></p></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Cory</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2022-11-26</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=https://huweim.github.io/tags/%E6%B5%85%E5%B0%9D%E8%BE%84%E6%AD%A2/>浅尝辄止</a></div><nav class=post-nav><a class=prev href=/post/%E8%AF%BE%E7%A8%8B_ca2_lab0/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">Ca2_lab0</span>
<span class="prev-text nav-mobile">Prev</span></a>
<a class=next href=/post/blog_hugo_about%E9%A1%B5%E9%9D%A2%E5%88%B6%E4%BD%9C/><span class="next-text nav-default">Hugo About页面制作</span>
<span class="prev-text nav-mobile">Next</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:huwm1@shanghaitech.edu.cn rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg></a><a href=http://localhost:1313 rel="me noopener" class=iconfont title=linkedin target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="33" height="33"><path d="M872.405333 872.618667H720.768V635.008c0-56.661333-1.152-129.578667-79.018667-129.578667-79.061333.0-91.136 61.653333-91.136 125.397334v241.792H398.976V384H544.64v66.602667h1.962667c20.352-38.4 69.845333-78.933333 143.786666-78.933334 153.642667.0 182.058667 101.12 182.058667 232.746667v268.202667zM227.712 317.141333a87.978667 87.978667.0 01-88.021333-88.106666A88.064 88.064.0 11227.712 317.141333zm76.032 555.477334H151.68V384h152.064v488.618667zM948.266667.0h-872.704C33.792.0.0 33.024.0 73.770667v876.458666C0 991.018667 33.792 1024 75.562667 1024h872.576C989.866667 1024 1024 991.018667 1024 950.229333V73.770667C1024 33.024 989.866667.0 948.138667.0h.128z"/></svg></a><a href=https://github.com/huweim rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://www.zhihu.com/people/hu-wei-ming-31-86 rel="me noopener" class=iconfont title=zhihu target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M351.791182 562.469462h192.945407c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262h159.282726s-.86367-67.402109-18.578124-67.402109-279.979646.0-279.979646.0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461s24.62791 5.832845 36.941354.0c12.313443-5.832845 68.050885-25.924439 84.252893-103.69571h86.570681c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262H109.86113c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449H279.868105c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513.0.0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-.055259.185218 167.855986 193.263655s22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-.045025.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"/><path d="M584.918753 182.033893v668.840094h70.318532l28.807093 80.512708 121.875768-80.512708h153.600307L959.520453 182.033893h-374.6017zM887.150192 778.934538h-79.837326l-99.578949 65.782216-23.537066-65.782216h-24.855084L659.341766 256.673847h227.807403V778.934538z"/></svg></a><a href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2020 -
2023
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>Cory</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>