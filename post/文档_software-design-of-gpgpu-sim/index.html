<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage data-theme=light><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Software Design of GPGPU-Sim - Weiming Hu
</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=color-scheme content="light dark"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=generator content="Hugo 0.140.2"><link rel=canonical href=https://huweim.github.io/post/%E6%96%87%E6%A1%A3_software-design-of-gpgpu-sim/><meta name=author content="Cory"><meta name=description content="4 Software Design of GPGPU-Sim
所有标题都可以升一级，整个文档全是 manual 的第 4 章
1. File list and brief description cuda-sim - The functional simulator that executes PTX kernels generated by NVCC or OpenCL compiler gpgpu-sim - The performance simulator that simulates the timing behavior of a GPU (or other many core accelerator architectures) intersim - The interconnection network simulator adopted from Bill Dally&rsquo;s BookSim 1.1 Overall/Utilities abstract_hardware_model.h abstract_hardware_model.cc Provide a set of classes that interface between functional and timing simulator. shader.h shader.cc SIMT core timing model. It calls cudu-sim for functional simulation of a particular thread and cuda-sim would return with performance-sensitive information for the thread. visualizer.h visualizer.cc Output dynamic statistics for the visualizer 1.3 gpgpu-sim 几个需要注意的列出来，gluing 时钟频率，注意有单独的 gpu-cache.cc 和 l2cache.cc
"><meta name=keywords content="GPGPU-Sim,文档"><meta property="og:url" content="https://huweim.github.io/post/%E6%96%87%E6%A1%A3_software-design-of-gpgpu-sim/"><meta property="og:site_name" content="Weiming Hu"><meta property="og:title" content="Software Design of GPGPU-Sim"><meta property="og:description" content="4 Software Design of GPGPU-Sim
所有标题都可以升一级，整个文档全是 manual 的第 4 章
1. File list and brief description cuda-sim - The functional simulator that executes PTX kernels generated by NVCC or OpenCL compiler gpgpu-sim - The performance simulator that simulates the timing behavior of a GPU (or other many core accelerator architectures) intersim - The interconnection network simulator adopted from Bill Dally’s BookSim 1.1 Overall/Utilities abstract_hardware_model.h abstract_hardware_model.cc Provide a set of classes that interface between functional and timing simulator. shader.h shader.cc SIMT core timing model. It calls cudu-sim for functional simulation of a particular thread and cuda-sim would return with performance-sensitive information for the thread. visualizer.h visualizer.cc Output dynamic statistics for the visualizer 1.3 gpgpu-sim 几个需要注意的列出来，gluing 时钟频率，注意有单独的 gpu-cache.cc 和 l2cache.cc"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-11-14T20:35:44+08:00"><meta property="article:modified_time" content="2025-12-01T03:37:02+00:00"><meta property="article:tag" content="GPGPU-Sim"><meta property="article:tag" content="文档"><meta itemprop=name content="Software Design of GPGPU-Sim"><meta itemprop=description content="4 Software Design of GPGPU-Sim
所有标题都可以升一级，整个文档全是 manual 的第 4 章
1. File list and brief description cuda-sim - The functional simulator that executes PTX kernels generated by NVCC or OpenCL compiler gpgpu-sim - The performance simulator that simulates the timing behavior of a GPU (or other many core accelerator architectures) intersim - The interconnection network simulator adopted from Bill Dally’s BookSim 1.1 Overall/Utilities abstract_hardware_model.h abstract_hardware_model.cc Provide a set of classes that interface between functional and timing simulator. shader.h shader.cc SIMT core timing model. It calls cudu-sim for functional simulation of a particular thread and cuda-sim would return with performance-sensitive information for the thread. visualizer.h visualizer.cc Output dynamic statistics for the visualizer 1.3 gpgpu-sim 几个需要注意的列出来，gluing 时钟频率，注意有单独的 gpu-cache.cc 和 l2cache.cc"><meta itemprop=datePublished content="2021-11-14T20:35:44+08:00"><meta itemprop=dateModified content="2025-12-01T03:37:02+00:00"><meta itemprop=wordCount content="6080"><meta itemprop=keywords content="GPGPU-Sim,文档"><meta name=twitter:card content="summary"><meta name=twitter:title content="Software Design of GPGPU-Sim"><meta name=twitter:description content="4 Software Design of GPGPU-Sim
所有标题都可以升一级，整个文档全是 manual 的第 4 章
1. File list and brief description cuda-sim - The functional simulator that executes PTX kernels generated by NVCC or OpenCL compiler gpgpu-sim - The performance simulator that simulates the timing behavior of a GPU (or other many core accelerator architectures) intersim - The interconnection network simulator adopted from Bill Dally’s BookSim 1.1 Overall/Utilities abstract_hardware_model.h abstract_hardware_model.cc Provide a set of classes that interface between functional and timing simulator. shader.h shader.cc SIMT core timing model. It calls cudu-sim for functional simulation of a particular thread and cuda-sim would return with performance-sensitive information for the thread. visualizer.h visualizer.cc Output dynamic statistics for the visualizer 1.3 gpgpu-sim 几个需要注意的列出来，gluing 时钟频率，注意有单独的 gpu-cache.cc 和 l2cache.cc"><link rel=icon href=/favicon.ico><link rel=stylesheet href=/css/style.min.1acfe3c0bf85aa6c451ba764236bb3ab12c22cd38eee8ecc8fac33defcc7156d.css integrity="sha256-Gs/jwL+FqmxFG6dkI2uzqxLCLNOO7o7Mj6wz3vzHFW0=" media=screen crossorigin=anonymous><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--><script>(function(){var e=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",e)})()</script></head><body><div id=back-to-top></div><header class=site-header><div class=desktop-header><div class=desktop-header-logo><a href=/ class=logo>Weiming Hu</a></div><nav class=desktop-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li><li class=menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg><svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=menu-item><a class=menu-item-link href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div><div class=mobile-header><div id=mobile-navbar class=mobile-navbar><div id=mobile-navbar-icon class=mobile-navbar-icon><svg aria-hidden="true" class="lucide lucide-menu hi-svg-inline icon--menu" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><line x1="4" x2="20" y1="12" y2="12"/><line x1="4" x2="20" y1="6" y2="6"/><line x1="4" x2="20" y1="18" y2="18"/></svg></div><div class=mobile-navbar-logo><a href=/ class=logo>Weiming Hu</a></div></div><div id=mobile-menu-close-modal class=mobile-menu-close-modal></div><nav id=mobile-menu class=mobile-menu><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/post>All posts</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/archives>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/tags>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/about/>About</a></li><li class=mobile-menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg><svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=mobile-menu-item><a class=menu-item-link href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div></header><main id=main class="main pico container"><div class=content-wrapper><aside class=sidebar></aside><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Software Design of GPGPU-Sim</h1><div class=post-meta-list><div class="post-meta-item post-meta-author"><svg aria-hidden="true" class="lucide lucide-user-round-pen hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M2 21a8 8 0 0110.821-7.487"/><path d="M21.378 16.626a1 1 0 00-3.004-3.004l-4.01 4.012a2 2 0 00-.506.854l-.837 2.87a.5.5.0 00.62.62l2.87-.837a2 2 0 00.854-.506z"/><circle cx="10" cy="8" r="5"/></svg>
Cory</div><div class="post-meta-item post-meta-time"><svg aria-hidden="true" class="lucide lucide-calendar-days hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M8 2v4"/><path d="M16 2v4"/><rect width="18" height="18" x="3" y="4" rx="2"/><path d="M3 10h18"/><path d="M8 14h.01"/><path d="M12 14h.01"/><path d="M16 14h.01"/><path d="M8 18h.01"/><path d="M12 18h.01"/><path d="M16 18h.01"/></svg>
<time datetime=2021-11-14>2021-11-14
</time><span class="post-meta-item post-meta-lastmod">(LastMod:
2025-12-01)</span></div><div class=post-meta__right><span class=post-meta-more>6080 words -
13 min read</span><div class="post-meta-item post-meta-category"><a href=https://huweim.github.io/categories/%E7%9F%A5%E8%AF%86/>知识</a></div></div></div></header><div class=post-content><p>4 Software Design of GPGPU-Sim</p><p>所有标题都可以升一级，整个文档全是 manual 的第 4 章</p><h1 id=1-file-list-and-brief-description>1. File list and brief description</h1><ul><li>cuda-sim - The functional simulator that executes PTX kernels generated by NVCC or OpenCL compiler</li><li>gpgpu-sim - The performance simulator that simulates the timing behavior of a GPU (or other many core accelerator architectures)</li><li>intersim - The interconnection network simulator adopted from Bill Dally&rsquo;s BookSim</li></ul><h2 id=11-overallutilities>1.1 Overall/Utilities</h2><table><thead><tr><th>abstract_hardware_model.h abstract_hardware_model.cc</th><th>Provide a set of classes that interface between functional and timing simulator.</th></tr></thead><tbody><tr><td>shader.h shader.cc</td><td>SIMT core timing model. It calls cudu-sim for functional simulation of a particular thread and cuda-sim would return with performance-sensitive information for the thread.</td></tr><tr><td>visualizer.h visualizer.cc</td><td>Output dynamic statistics for the visualizer</td></tr></tbody></table><h2 id=13-gpgpu-sim>1.3 gpgpu-sim</h2><p>几个需要注意的列出来，gluing 时钟频率，注意有单独的 gpu-cache.cc 和 l2cache.cc</p><table><thead><tr><th>gpu-sim.h gpu-sim.cc</th><th>Gluing different timing models in GPGPU-Sim into one. It contains implementations to support multiple clock domains and implements the thread block dispatcher.</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><h1 id=3-abstract-hardware-model>3. Abstract Hardware Model</h1><p>The files abstract_hardware_model{.h,.cc} provide a set of classes that interface between functional and timing simulator.</p><p>只列了一部分，查表的话去官方文档更方便，注意有单独的 cache operator type</p><p>kernel function 的信息也存在里面了</p><table><thead><tr><th style=text-align:center>Enum Name</th><th style=text-align:center>Description</th></tr></thead><tbody><tr><td style=text-align:center>_memory_space_t</td><td style=text-align:center>Memory space type (register, local, shared, global, &mldr;)</td></tr><tr><td style=text-align:center>uarch_op_t</td><td style=text-align:center>Type of operation (ALU_OP, SFU_OP, LOAD_OP, STORE_OP, &mldr;)</td></tr><tr><td style=text-align:center>_memory_op_t</td><td style=text-align:center>Defines whether instruction accesses (load or store) memory.</td></tr><tr><td style=text-align:center>mem_access_type</td><td style=text-align:center>Different types of accesses in the timing simulator to different types of memories.</td></tr><tr><td style=text-align:center>cache_operator_type</td><td style=text-align:center>Different types of <strong>L1 data cache access</strong> behavior provided by PTX</td></tr><tr><td style=text-align:center><strong>Class Name</strong></td><td style=text-align:center><strong>Description</strong></td></tr><tr><td style=text-align:center>class kernel_info_t</td><td style=text-align:center>Holds information of a kernel. It contains information like kernel function(function_info), <strong>grid and block size</strong> and list of <strong>active threads</strong> inside that kernel (ptx_thread_info).</td></tr><tr><td style=text-align:center>class core_t</td><td style=text-align:center>Abstract base class of a core for both functional and performance model. shader_core_ctx (the class that implements a SIMT core in timing model) is derived from this class.</td></tr><tr><td style=text-align:center>class memory_space_t</td><td style=text-align:center>Information of a memory space like type of memory and number of banks for this memory space.</td></tr><tr><td style=text-align:center>class mem_access_t</td><td style=text-align:center>Contains information of each <strong>memory access</strong> in the timing simulator. This class has information about type of memory access, requested address, size of data and active masks of threads inside warp accessing the memory.This class is used as one of parameters of mem_fetch class, which basically instantiated for each memory access. This class is for interfacing between two different level of memory and passing through interconnects.</td></tr><tr><td style=text-align:center>struct dram_callback_t</td><td style=text-align:center>This class is the one who is responsible for atomic operations. The function pointer is set during functional simulation(atom_impl()) to atom_callback(&mldr;). During timing simulation this function pointer is being called when in l2cache memory controller pop memory partition unit to interconnect. This function is supposed to compute result of atomic operation and saving it in memory.</td></tr><tr><td style=text-align:center>class inst_t</td><td style=text-align:center>Base class of all instruction classes. This class contains information about type and size of instruction, address of instruction, inputs and outputs, latency and memory scope (memory_space_t) of the instruction.</td></tr><tr><td style=text-align:center>class warp_inst_t</td><td style=text-align:center>Data of instructions need during timing simulation. Each instruction (ptx_instruction) which is inherited from warp_inst_t contains data for timing and functional simulation. ptx_instruction is filled during functional simulation. After this level program needs only timing information so it casts ptx_instruction to warp_inst_t (some data is being loosed) for timing simulation. warp_inst_t inherited from inst_t. It holds <strong>warp_id, active thread mask</strong> inside the warp, list of <strong>memory accesses (mem_access_t)</strong> and information of threads inside that warp (per_thread_info)</td></tr></tbody></table><h1 id=4-gpgpu-sim---performance-simulation-engine>4. GPGPU-sim - Performance Simulation Engine</h1><h2 id=41-performance-model-software-objects>4.1 Performance Model Software Objects</h2><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span>ldst_unit <span style=color:#f92672>*</span>m_ldst_unit;</span></span></code></pre></div></div><p>前面的 m 可能表示这个类型的变量</p><h3 id=411-simt-core-cluster-class>4.1.1 SIMT Core Cluster Class</h3><p>SIMT Core Cluster 通过类 <code>simt_core_cluster</code> 建模。这个类在 <code>m_core</code> 中包含一组 SIMT core 对象。<code>simt_core_cluster::core_cycle()</code> 方法只是按顺序 循环调用 (cycles) 每个 SIMT core.</p><p><code>simt_core_cluster::icnt_cycle()</code> 方法将内存请求从 interconnection network push 到 SIMT Core Cluster&rsquo;s response FIFO. 它也将 FIFO 中的请求出队，送到合适的 core&rsquo;s instruction cache or LDST unit. 这些与前面描述的硬件块密切对应。</p><h3 id=412-simt-core-class-star>4.1.2 SIMT Core Class &#x2b50;</h3><p>SIMT Core 中的微架构在 shader.h/cc 的类 shader_core_ctx 中实现</p><ul><li>shd_warp_t objects 的集合用于建模每个 warp 在 core 中的状态</li><li>simt_stack object, 处理每个 warp 的分支</li><li>set of scheduler_unit obj, 选择 set 中 warp 的一条 or 多条指令发射执行</li><li>Scoreboard obj 处理 data hazard</li><li>opndcoll_rfu_t obj, model operand collector</li><li>set of <code>simd_function_unit</code> obj 实现 ALU pipeline</li><li><code>ldst_unit</code> 实现 memory pipeline</li><li><code>shader_memroy_interface</code> 将 SIMT Core 连接到相应的 SIMT Core Cluster</li></ul><p>每个 core cycle, 调用 <code>shader_core_ctx::cycle()</code> 来模拟 SIMT Core 的一个 cycle。cycle function 以按从下往上的顺序 (也就是从 writeback() 到 fetch()) 调用下列函数</p><ul><li>fetch()</li><li>decode()</li><li>issue()</li><li>read_operand()</li><li>execute()</li><li>writeback()</li></ul><p>多个流水线阶段通过一组指向 <code>warp_inst_t</code> 的流水线寄存器链接 (除了 Fetch and Decode, 它们通过 <code>ifetch_buffer_t</code> 连接)</p><blockquote><p>也就是 Fetch 和 Decode 函数中的变量 m_inst_fetch_buffer</p></blockquote><p>当访问特定于 SIMT core 的配置选项时，每个 <code>shader_core_ctx</code> 对象引用一个公共 <code>shader_core_config</code> 对象。所有 <code>shader_core_ctx</code> 对象也链接到 <code>shader_core_stats</code> 对象的一个普通实例，该对象跟踪所有 SIMT core 的一组性能测量值。</p><h4 id=4121-fetch-and-decode-software-model>4.1.2.1 Fetch and Decode Software Model</h4><p>I-Buffer 在 <code>shd_warp_t</code> 类中作为数组实现，每个 <code>shd_warp_t</code> 有集合 m_ibuffer，默认大小为 2</p><blockquote><p>可以修改 IBUFFER_SIZE 来调整每个 warp 的 I-Buffer slot 大小</p></blockquote><p><code>shd_warp_t</code> 也有标志位决定 warp 的 eligibility 以备发射。解码的指令存在 ibuffer_entry，作为指针指向 <code>warp_inst_t</code> object, <code>warp_inst_t</code> 保留指令使用的操作类型和操作数的信息</p><p><strong>Fetch</strong></p><p>如果 decode stage 没有 stall, 即 <code>m_inst_fetch_buffer</code> 没有有效指令，那么 fetch unit 就可以工作 (<code>shader_core_ctx::m_inst_fetch_buffer</code> 作为 fetch 和 decode stage 之间的 pipeline register)</p><blockquote><p>也就是 fetch() 函数中的 !m_inst_fetch_buffer.m_valid 时进入最外层 if 语句</p></blockquote><p>外层循环用于实现轮询调度器，最新调度的 warp id 存在 <code>m_last_warp_fetched</code>。</p><p>在 fetch() 函数中，进入最外层 if 语句，以及第2层中的 else 语句后，</p><ul><li>第3层中的第1个 if 语句检查 warp 是否已经完成执行</li><li>第3层中的第2个 if 语句完成实际的从指令 cache 中取数据 (hit)，或者生成内存访问 (miss) 的操作。<ul><li>第2个 if 语句主要是检查当前 warp 对应的 entry 是否已经存储了有效的指令<ul><li>条件语句中的 <code>m_warp[warp_id]->ibuffer_empty()</code></li></ul></li></ul></li></ul><p><strong>Decode</strong></p><p>decode stage 简单地检查 <code>shader_core_ctx::m_inst_fetch_buffer</code>，然后开始解码指令，当前配置是一个周期解码2条指令，并将其存入对应的 I-Buffer entry (也就是 <code>m_ibuffer </code>)</p><h4 id=4122-schedule-and-issue-software-model>4.1.2.2 Schedule and Issue Software Model</h4><p>每个 core 中，有数量可配置的 scheduler unit. 在函数 <code>shader_core_ctx::issue()</code> 中，会使用一个 for loop 遍历这些 scheduler unit，每个 scheduler unit 都调用 <code>scheduler_unit::cycle()</code> 函数</p><ul><li>在 <code>scheduler_unit::cycle()</code> 函数中，通过调用 <code>shader_core_ctx::issue_warp()</code> 将指令发送到执行流水线</li><li><strong>在 <code>shader_core_ctx::issue_warp()</code> 函数中</strong>，指令通过调用 <code>shader_core_ctx::func_exec_inst()</code> 来执行，调用 <code>updateSIMTStack()</code> 中的 <code>simt_stack::update()</code> 来更新 SIMT Stack。指令也会因为 <code>warp_t:set_membar()</code> 以及 <code>set_t::warp_reaches_barrier</code> 而等待/释放</li></ul><p>另一方面，寄存器信息由 <code>Scoreboard::reserveRegisters()</code> 保存。<code>scheduler_unit::m_sp_out, scheduler_unit::m_sfu_out, scheduler_unit::m_mem_out</code> 分别指向 SP, SFU, Mem 流水线的 issue stage and execution stage 之间的第一个 pipeline register。这也是为什么在每条指令发射之前都要检查这些单元</p><h4 id=4123-simt-stack-software-model>4.1.2.3 SIMT Stack Software Model</h4><p>每个scheduler unit 有一个 SIMT stacks. 每个 SIMT stack 对应一个 warp</p><blockquote><p>所以 SIMT Stack 可以作为 warp scheduler unit 中的硬件实现，为一个 warp 服务</p></blockquote><p>在 <code>scheduler_unit::cycle()</code> 函数中，被调度的 warp 对应的 SIMT Stack 中的栈顶 entry 决定被发射的指令。栈顶 entry 的 PC value 通常与该 warp 对应 I-Buffer 下一条指令的 PC value 一致 (一致说明没有出现分支)。否则出现 control hazard, 它们如果不匹配，I-Buffer 中的指令会被 flush.</p><blockquote><p>也就是说这是一个简单的分支跳转检测机制。SIMT Stack 的栈顶存放的是下一条指令，也就是 next PC value. 无跳转情况下 I-Buffer 中的下一条指令的 PC value 应该和 SIMT Stack 栈顶的 next PC value 一致。</p><p>如果不一致说明出现了跳转，那么在 I-Buffer 中的下一条指令的 PC value 是无效的，需要刷掉 I-Buffer</p></blockquote><p>&#x2753; ​SIMT Stack 在类 <code>simt_stack</code> 中实现。SIMT Stack 在每次发射后通过函数 <code>simt_stack::update(...)</code> 更新。函数 <code>simt_stack::update(...)</code> (in abstarct_hardware_model.cc) 实现了在发散点和聚合点所需的算法。Functional execution (参见4.5，这个部分讲述了指令的执行) 是在更新 SIMT stack 之前的发射阶段执行的。这允许发射阶段拥有每个线程的 next PC 的信息，因此，可以根据需要更新 SIMT stack.</p><blockquote><p>Functional execution 是什么？可能要看了4.5才知道</p></blockquote><h4 id=4124-scoreboard-software-model>4.1.2.4 Scoreboard Software Model</h4><p>scoreboard unit 在 <code>shader_core_ctx</code> 作为成员对象被实例化，通过引用 (指针) 传递到 <code>scheduler_unit </code>。</p><blockquote><p>理解为 scoreboard 作为 core 的一个硬件单元</p></blockquote><p>它存储了 shader core id (<code>m_sid</code>) 和一个通过 warp id 索引的寄存器表 (<code>reg_table</code>)。寄存器表存储了每个 warp 保留的寄存器的数量。 函数 <code>Scoreboard::reserveRegisters(...), Scoreboard::releaseRegisters(...) and Scoreboard::checkCollision(...)</code> 分别用于保留寄存器，释放寄存器，在 warp 发射前检查冲突。</p><h4 id=4125-operand-collector-software-model>4.1.2.5 Operand Collector Software Model</h4><p>Operand Collector 建模在主流水线的一个阶段，由函数 <code>shader_core_ctx::cycle()</code> 调用执行。这个阶段由函数 <code>shader_core_ctx::read_operands()</code> 表示。关于 ALU Pipeline 的更多细节在下一节 1.2.6</p><p>类 <code>opndcoll_rfu_t </code>基于寄存器文件单元建模了 operand collector. 包括 collector unit 集合，仲裁器，dispatch 单元的抽象。</p><p><code>opndcoll_rfu_t::allocate_cu(...)</code> 用于将 <code>warp_inst_t </code>分配到给定 operand collector 集合中的空闲 operand collector. 它也将所有源操作数的读请求添加到仲裁器中相应的 bank 队列</p><p>然而，<code>opndcoll_rfu_t::allocate_reads(...)</code> 处理没有冲突的读请求，也就是不同寄存器 bank 中并且没有进入同一个 operand collector 的读请求将从仲裁器队列中出队。写请求总是优先于读请求。</p><p>函数 <code>opndcoll_rfu_t::dispatch_ready_cu()</code> 会 dispatch ready operand collectors 的操作数寄存器到执行阶段</p><p>函数 <code>opndcoll_rfu_t::writeback( const warp_inst_t &amp;inst )</code> 在内存流水线的写回阶段被调用。用于分配写请求。</p><p>上述内容总结了建模 operand collector 的主要函数的重点，更多的细节在源代码中的 <code>shader.cc/h</code> 中的类 <code>opndcoll_rfu_t</code></p><h4 id=4126-alu-pipeline-software-model>4.1.2.6 ALU Pipeline Software Model</h4><p>SP 单元和 SFU 单元的时间模型主要在 <code>shader.h</code> 中的类 <code>pipelined_simd_unit</code> 中实现。建模这两个单元的特定类 (<code>sp_unit</code> and <code>sfu</code>) 派生自这个类 (<code>pipelined_simd_unit</code>)，其中包含被重写的成员函数 <code>can_issue()</code> ，用于指定单元可执行的指令类型。</p><blockquote><p>比如源代码中，类 <code>sfu</code> 可以执行执行类型 <code>SFU_OP, ALU_SFU_OP, DP_OP</code></p></blockquote><p>SP 单元通过流水线寄存器 <code>OC_EX_SP</code> 连接 operand collector, SFU 单元通过流水线寄存器 <code>OC_EX_SFU</code> 连接 operand collector. 两个单元通过流水线寄存器 <code>WB_EX</code> 共享写回阶段。为了避免两个单元在写回阶段冲突而停滞，每一条进入任一单元的指令都必须在结果总线(<code>m_result_bus</code>)中分配一个 slot，然后才会被发送到指定单元 (细节在 <code>shader_core_ctx::execute()</code>)</p><blockquote><p>OC -> operand collector</p></blockquote><p>下图说明了 <code>pipelined_simd_unit</code> 如何建模不同类型指令的吞吐量和延迟</p><p>在每个 <code>pipelined_simd_unit</code>, 成员函数 <code>issue(warp_inst_t*&)</code> 将给定的流水线寄存器的内容移动到 <code>m_dispatch_reg</code>. 指令在 <code>m_dispatch_reg</code> 中等待 <code>initiation_interval</code> cycles. 同时，没有其他指令被发射到这个单元，所以这个等待建模了指令的吞吐量。在等待后，指令派遣 (dispatch) 到内部流水线寄存器 <code>m_pipeline_reg</code> 以建模延迟 (可以得到指令等待了多久才被派遣到 <code>m_pipeline_reg</code>)。派遣位置是确定的，这样花费在 <code>m_dispatch_reg</code> 中的时间也被计入延迟。每个周期，指令将通过流水线寄存器前进，最终进入 <code>m_result_port</code>，这是 SP and SFU 单元的公共回写阶段的共享流水线寄存器 (<code>WB_EX</code>)。</p><p>每种指令类型的吞吐量和延迟在 <code>cuda-sim.cc</code> 中的<code>ptx_instruction::set_opcode_and_latency()</code> 中指定。这个函数在预解码期间被调用。</p><blockquote><p>指令吞吐量，一个 cycle 内处理指令的条数，也就是 ipc?</p><p>延迟也就是指令等待的时间</p><p>指令执行吞吐一般指的是每个时钟周期内可以执行的指令数目，不同指令的吞吐会有所不同。通常GPU的指令吞吐用每个SM每周期可以执行多少指令来计量。对于多数算术逻辑指令而言，指令执行吞吐只与SM内的单元有关，整个GPU的吞吐就是每个SM的吞吐乘以SM的数目。</p><p>主要受以下因素影响</p><ul><li><strong>功能单元</strong>的数目</li><li>指令<strong>Dispatch Port</strong>和<strong>Dispatch Unit</strong>的吞吐。<ul><li>一个 warp 的指令要发射，首先要 eligible, 也就是没有等待 cache miss, 通过了 scoreboard 等待。</li><li>其次要被 warp scheduler 选中，由 Dispatch Unit 发送到相应的 Dispatch Port. Kepler、Maxwell和Pascal是一个Warp Scheduler有两个Dispatch Unit，所以每cycle最多可以发射两个指令，也就是双发射。而Turing、Ampere每个Warp Scheduler只有一个Dispatch Unit，没有双发射，那每个周期就最多只能发一个指令。但是Kepler、Maxwell和Pascal都是一个Scheduler带32个单元（这里指full-throughput的单元），每周期都可以发新的warp。而Turing、Ampere是一个Scheduler带16个单元，每个指令要发两cycle，从而空出另一个cycle给别的指令用。</li><li><strong>最后要求Dispatch Port或其他资源不被占用</strong>，port被占的原因可能是前一个指令的执行吞吐小于发射吞吐，导致要Dispatch多次，比如Turing的两个FFMA至少要stall 2cycle，LDG之类的指令至少是4cycle。更详细的介绍大家可以参考之前的专栏文章。</li></ul></li><li><strong>GPR读写吞吐</strong>。绝大部分的指令都要涉及GPR的读写，由于Register File每个bank每个cycle的吞吐是有限的（一般是32bit），如果一个指令读取的GPR过多或是GPR之间有bank conflict，都会导致指令吞吐受影响。GPR的吞吐设计是影响指令发射的重要原因之一，有的时候甚至占主导地位，功能单元的数目配置会根据它和指令集功能的设计来定。比如NV常用的配置是4个Bank，每个bank每个周期可以输出一个32bit的GPR。这样FFMA这种指令就是3输入1输出，在没有bank conflict的时候可以一个cycle读完。其他如DFMA、HFMA2指令也会根据实际的输入输出需求，进行功能单元的配置。</li><li>很多指令有<strong>replay</strong>的逻辑（<a href="https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/35566178/how-to-explain-instruction-replay-in-cuda">参考Greg Smith在StackOverflow上的一个回答</a>）。这就意味着有的指令一次发射可能不够。这并不是之前提过的由于功能单元少而连续占用多轮dispath port，而是指令处理的逻辑上有需要分批或是多次处理的部分。比如constant memory做立即数时的cache miss，memory load时的地址分散，shared memory的bank conflict，atomic的地址conflict，甚至是普通的cache miss或是TLB的miss之类。根据上面Greg的介绍，Maxwell之前，这些replay都是在warp scheduler里做的，maxwell开始将它们下放到了各级功能单元，从而节约最上层的发射吞吐。不过，只要有replay，相应dispath port的占用应该是必然的，这样同类指令的总发射和执行吞吐自然也就会受影响。<ul><li>L1 cache miss 也有进行 replay 的逻辑</li></ul></li></ul></blockquote><h4 id=4127-memory-stage-software-model>4.1.2.7 Memory Stage Software Model</h4><p><code>shader.cc</code> 中的类 <code>ldst_unit</code> 实现了 shader 流水线的内存阶段。这个类实例化了所有 in-shader 内存的操作: texture (<code>m_L1T</code>), constant (<code>m_L1C</code>) and data (<code>m_L1D</code>). <code>ldst_unit::cycle()</code> implements the guts of the unit&rsquo;s operation and is pumped <code>m_config->mem_warp_parts</code> times pre core cycle. 完全对齐的内存访问 (fully coalesced memory access) 可以在一个 shader cycle 内被处理。<code>ldst_unit::cycle()</code> 处理来自 interconnect 的内存响应 (存在 <code>m_response_fifo</code>), 填充 cache 并将存储标记为完成。这个函数还 cycles the caches 以便它们可以将未命中数据的请求发送给 interconnect.</p><p>每种 L1 内存类型的 cache 访问分别在 <code>shared_cycle(), constant_cycle(), texture_cycle()</code> and <code>memory_cycle()</code> 中完成。</p><ul><li><code>memory_cycle()</code> 用于访问 L1 data cache.</li></ul><p>每个函数会调用 <code>process_memory_access_queue()</code>, 这是一个通用函数，它从指令内部访问队列中提取访问并将这个请求发送到 cache 中。如果访问不能再这个 cycle 中被处理 (即没有未命中，也没有命中 (也就是之前介绍中提到的第三个状态 reserved fail)，这可能发生在系统队列满的时候，或是所有 cache line reserved 但还没有 fill)，那么会在下个 cycle 再次试图访问。</p><p>值得注意的是，并不是所有的指令都到达单元的写回阶段。在所有请求的 cache block 命中时，所有的 ST 指令和 LD 指令都将在 <code>cycle</code> 函数中退出流水线。这是因为它们不需要等待来自 interconnect 的响应，并且可以 by-pass 写回逻辑，该逻辑保存指令所请求的 cache line 和那些已经返回的 cache line。</p><h4 id=4128-cache-software-model>4.1.2.8 Cache Software Model</h4><p><code>gpu-cache.h</code> 实现了 <code>ldst_unit</code> 用到的所有 cache. constant cache and data cache 都包含一个成员对象 <code>tag_array</code>，用于实现保留和替换的逻辑。函数 <code>probe()</code> 检查 cache block 地址而不影响相关数据的 LRU 位置, 函数 <code>access()</code> 旨在建模影响 LRU 位置的查找，生成未命中和访问的统计信息。MSHR 用类 <code>msgr_table</code> 建模，它建模了一个全相联 table, 合并有限数量的请求。请求通过 <code>next_access()</code> 函数从MSHR释放。</p><p>类 <code>read_only_cache</code> 被 constant cache 使用，并作为类 <code>data_cache</code> 的基类。这个层次结构可能有点令人困惑，因为 R/W data cache 是从 <code>read_only_cache</code> 扩展的 (理解为 R/W data cache 就是在只读 cache 类基础上加了一些功能来实现，从代码角度很好理解这句话)。原因是它们共享很多相同功能的函数，除了函数 <code>access</code> 需要写 <code>data_cacje</code> 这一点有所区别。L2 cache 也是通过类 <code>data_cache</code> 实现。</p><blockquote><p>这一点从 C 语言中类的角度去理解就好</p></blockquote><p>类 <code>tex_cache</code> 实现 texture cache. 它没有使用 <code>tag_array</code> 或是 <code>mshr_table</code>，因为它的操作和传统 cache 不太一样</p><h4 id=4129-thread-block--cta--work-group-scheduling>4.1.2.9 Thread Block / CTA / Work Group Scheduling</h4><p>Thread Block 向 SIMT cores 的调度在 <code>shader_core_ctx::issue_block2core(...)</code> 中实现。一个 core 中可以并行调度的最大 block 数量由函数 <code>shader_core_config::max_cta(...)</code> 计算。这个函数基于程序中定义的 ThreadPerBlock (CUDA 编程中由程序员定义), 以及每个线程的寄存器使用情况、共享内存使用情况以及每个 core 的最大线程块数量的配置限制来计算上述 <strong>可以并行调度的最大 block 数量</strong>。具体地说，计算可以分配给 SIMT core 的 block 数量，上面的每个标准都是限制因素。其中的最小值是可以分配给 SIMT core 的最大 block 数量。</p><blockquote><p>各种资源中的短板决定了最多可以有多少个 block 并行。CUDA 编程的知识</p></blockquote><p>在函数 <code>shader_core_ctx::issue_block2core(...)</code> 中，block size 首先被填充为 warp size 的倍数。然后决定一个空闲硬件 thread id 的范围。通过调用函数 <code>ptx_sim_init_thread</code> 来初始化每个线程的函数状态。调用函数 <code>shader_core_ctx::init_warp</code> 初始化 SIMT stack and warp state.</p><p>当每条线程完成，SIMT core 调用函数 <code>shader_core_ctx::init_warp(...)</code> 来更新 active thread block 的状态。当 block 内所有线程完成执行， 同一个函数会减少 core 上 active block 的数量，允许在下一 cycle 调度更多 block. 从 pending kernels 中选择要调度的新线程块。</p><h3 id=4413-interconnection-network>4.4.1.3 Interconnection Network</h3><p>Interconnection Network 接口有以下几个功能。这些函数在 <code>interconnect_interface.cpp</code> 中实现。这些函数被封装在 <code>icnt_wrapper.cpp</code> 中。使用<code>icnt_wrapper.cpp</code> 的最初目的是允许其他 network 模拟器连接到 GPGPU-Sim。</p><ul><li><code>init_interconnect()</code>: 初始化网络模拟器。它的输入是互连网络的配置文件和SIMT核心团簇和内存节点的数量。</li><li><code>interconnect_push()</code>: 指定源节点、目的节点、指向要传输的数据包的指针和数据包大小(以字节为单位)。</li><li><code>interconnect_pop()</code>: 获取一个节点号作为输入，并返回一个指向在该节点等待被弹出的数据包的指针。如果没有数据包，则返回NULL。</li><li><code>interconnect_has_buffer()</code>: 获取作为输入要发送的节点号和数据包大小，如果源节点的输入缓冲区有足够的空间，则返回1 (true)。</li><li><code>advance_interconnect()</code>: 应该在每个互连时钟周期被调用。顾名思义，它在一个周期内完成网络的所有内部步骤。</li><li><code>interconnect_busy()</code>: 如果网络中有一个正在传输的数据包，则返回1 (true)</li><li><code>interconnect_stats()</code>: 打印网络统计信息。</li></ul><h3 id=415-memory-partition>4.1.5 Memory Partition</h3><p>l2cache.cc/h 中有 class <code>memory_partition_unit</code></p><p>II. L2 Cache Model</p><p><code>mem_fetch *mf = m_L2cache->next_access();</code> 产生等待 fill MSHR entry 的内存请求的 reply,</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Cory</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2025-12-01</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=https://huweim.github.io/tags/gpgpu-sim/>GPGPU-Sim</a>
<a href=https://huweim.github.io/tags/%E6%96%87%E6%A1%A3/>文档</a></div><nav class=post-nav><a class=prev href=/post/%E6%80%BB%E7%BB%93_gpgpu-sim%E4%B8%AD%E7%9A%84cta--warp-scheduling/><i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-left hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m15 18-6-6 6-6"/></svg>
</i><span class="prev-text nav-default">GPGPU-Sim中的CTA & warp scheduling</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/post/%E5%AE%9E%E9%AA%8C_gpu_benchmark%E8%AF%B4%E6%98%8E%E8%BD%AC/><span class="next-text nav-default">GPU_benchmark说明（转）</span>
<span class="prev-text nav-mobile">Next</span>
<i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-right hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m9 18 6-6-6-6"/></svg></i></a></nav></footer></article></div><nav class=toc id=toc><div class=toc-title>Table of Contents</div><div class="toc-content custom-scrollbar"><nav id=TableOfContents><ul><li><a href=#1-file-list-and-brief-description>1. File list and brief description</a><ul><li><a href=#11-overallutilities>1.1 Overall/Utilities</a></li><li><a href=#13-gpgpu-sim>1.3 gpgpu-sim</a></li></ul></li><li><a href=#3-abstract-hardware-model>3. Abstract Hardware Model</a></li><li><a href=#4-gpgpu-sim---performance-simulation-engine>4. GPGPU-sim - Performance Simulation Engine</a><ul><li><a href=#41-performance-model-software-objects>4.1 Performance Model Software Objects</a><ul><li><a href=#411-simt-core-cluster-class>4.1.1 SIMT Core Cluster Class</a></li><li><a href=#412-simt-core-class-star>4.1.2 SIMT Core Class &#x2b50;</a><ul><li><a href=#4121-fetch-and-decode-software-model>4.1.2.1 Fetch and Decode Software Model</a></li><li><a href=#4122-schedule-and-issue-software-model>4.1.2.2 Schedule and Issue Software Model</a></li><li><a href=#4123-simt-stack-software-model>4.1.2.3 SIMT Stack Software Model</a></li><li><a href=#4124-scoreboard-software-model>4.1.2.4 Scoreboard Software Model</a></li><li><a href=#4125-operand-collector-software-model>4.1.2.5 Operand Collector Software Model</a></li><li><a href=#4126-alu-pipeline-software-model>4.1.2.6 ALU Pipeline Software Model</a></li><li><a href=#4127-memory-stage-software-model>4.1.2.7 Memory Stage Software Model</a></li><li><a href=#4128-cache-software-model>4.1.2.8 Cache Software Model</a></li><li><a href=#4129-thread-block--cta--work-group-scheduling>4.1.2.9 Thread Block / CTA / Work Group Scheduling</a></li></ul></li><li><a href=#4413-interconnection-network>4.4.1.3 Interconnection Network</a></li><li><a href=#415-memory-partition>4.1.5 Memory Partition</a></li></ul></li></ul></li></ul></nav></div></nav></div></main><footer id=footer class=site-footer><div class=social-icon-links><a href=mailto:huwm1@shanghaitech.edu.cn rel="me noopener" class=social-icon-link title=email><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1451 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg>
</a><a href=http://localhost:1313 rel="me noopener" class=social-icon-link title=linkedin target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M872.405333 872.618667H720.768V635.008c0-56.661333-1.152-129.578667-79.018667-129.578667-79.061333.0-91.136 61.653333-91.136 125.397334v241.792H398.976V384H544.64v66.602667h1.962667c20.352-38.4 69.845333-78.933333 143.786666-78.933334 153.642667.0 182.058667 101.12 182.058667 232.746667v268.202667zM227.712 317.141333a87.978667 87.978667.0 01-88.021333-88.106666A88.064 88.064.0 11227.712 317.141333zm76.032 555.477334H151.68V384h152.064v488.618667zM948.266667.0h-872.704C33.792.0.0 33.024.0 73.770667v876.458666C0 991.018667 33.792 1024 75.562667 1024h872.576C989.866667 1024 1024 991.018667 1024 950.229333V73.770667C1024 33.024 989.866667.0 948.138667.0h.128z"/></svg>
</a><a href=https://github.com/huweim rel="me noopener" class=social-icon-link title=github target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg>
</a><a href=https://www.zhihu.com/people/hu-wei-ming-31-86 rel="me noopener" class=social-icon-link title=zhihu target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentcolor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M351.791182 562.469462h192.945407c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262h159.282726s-.86367-67.402109-18.578124-67.402109-279.979646.0-279.979646.0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461s24.62791 5.832845 36.941354.0c12.313443-5.832845 68.050885-25.924439 84.252893-103.69571h86.570681c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262H109.86113c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449H279.868105c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513.0.0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-.055259.185218 167.855986 193.263655s22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-.045025.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"/><path d="M584.918753 182.033893v668.840094h70.318532l28.807093 80.512708 121.875768-80.512708h153.600307L959.520453 182.033893h-374.6017zM887.150192 778.934538h-79.837326l-99.578949 65.782216-23.537066-65.782216h-24.855084L659.341766 256.673847h227.807403V778.934538z"/></svg>
</a><a href=https://huweim.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=social-icon-link title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a>
</span><span class=copyright-year>&copy;
2020 -
2025
<span class=heart><i class=iconfont><svg aria-hidden="true" class="lucide lucide-heart hi-svg-inline" fill="none" height="1em" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5.0 0016.5 3c-1.76.0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5.0 002 8.5c0 2.3 1.5 4.05 3 5.5l7 7z"/></svg>
</i></span><span class=author>Weiming Hu</span></span></div></footer><script type=text/javascript src=/js/main.eb94e793601239645bc98e36c443aef1b210646ccb43e2217ea949a0212e0ed1.js integrity="sha256-65Tnk2ASOWRbyY42xEOu8bIQZGzLQ+IhfqlJoCEuDtE=" crossorigin=anonymous></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>